<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Linear Regression | MEM52220 - Applied Econometrics</title>
  <meta name="description" content="This manual constitutues the classroom material of the applied econometrics course at Tallinn University of Technology" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Linear Regression | MEM52220 - Applied Econometrics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This manual constitutues the classroom material of the applied econometrics course at Tallinn University of Technology" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Linear Regression | MEM52220 - Applied Econometrics" />
  
  <meta name="twitter:description" content="This manual constitutues the classroom material of the applied econometrics course at Tallinn University of Technology" />
  

<meta name="author" content="Nicolas Reigl" />


<meta name="date" content="2019-07-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html">
<link rel="next" href="binarymodels.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MEM5220 - Applied Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation-of-r-and-rstudio"><i class="fa fa-check"></i>Installation of R and RStudio</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#resources"><i class="fa fa-check"></i>Resources</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#attribution"><i class="fa fa-check"></i>Attribution</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-information-and-conventions"><i class="fa fa-check"></i>Software information and conventions</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="linearregression.html"><a href="linearregression.html"><i class="fa fa-check"></i><b>1</b> Linear Regression</a><ul>
<li class="chapter" data-level="1.1" data-path="linearregression.html"><a href="linearregression.html#simple-linear-regression"><i class="fa fa-check"></i><b>1.1</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="1.1.1" data-path="linearregression.html"><a href="linearregression.html#regression-through-the-origin-and-regression-on-a-constant"><i class="fa fa-check"></i><b>1.1.1</b> Regression through the Origin and Regression on a Constant</a></li>
<li class="chapter" data-level="1.1.2" data-path="linearregression.html"><a href="linearregression.html#simulating-slr"><i class="fa fa-check"></i><b>1.1.2</b> Simulating SLR</a></li>
<li class="chapter" data-level="1.1.3" data-path="linearregression.html"><a href="linearregression.html#nonlinearities"><i class="fa fa-check"></i><b>1.1.3</b> Nonlinearities</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="linearregression.html"><a href="linearregression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>1.2</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="1.2.1" data-path="linearregression.html"><a href="linearregression.html#ceteris-paribus-interpretation-and-omitted-variable-bias"><i class="fa fa-check"></i><b>1.2.1</b> Ceteris Paribus Interpretation and Omitted Variable bias</a></li>
<li class="chapter" data-level="1.2.2" data-path="linearregression.html"><a href="linearregression.html#standard-errors-multicollinearity-and-vif"><i class="fa fa-check"></i><b>1.2.2</b> Standard errors, Multicollinearity and VIF</a></li>
<li class="chapter" data-level="1.2.3" data-path="linearregression.html"><a href="linearregression.html#reporting-regression-results"><i class="fa fa-check"></i><b>1.2.3</b> Reporting Regression Results</a></li>
<li class="chapter" data-level="1.2.4" data-path="linearregression.html"><a href="linearregression.html#model-formulae"><i class="fa fa-check"></i><b>1.2.4</b> Model Formulae</a></li>
<li class="chapter" data-level="1.2.5" data-path="linearregression.html"><a href="linearregression.html#mlr-prediction"><i class="fa fa-check"></i><b>1.2.5</b> MLR Prediction</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="linearregression.html"><a href="linearregression.html#mlr-analysis-with-qualitative-regressors"><i class="fa fa-check"></i><b>1.3</b> MLR Analysis with Qualitative Regressors</a><ul>
<li class="chapter" data-level="1.3.1" data-path="linearregression.html"><a href="linearregression.html#dummy-variabes"><i class="fa fa-check"></i><b>1.3.1</b> Dummy variabes</a></li>
<li class="chapter" data-level="1.3.2" data-path="linearregression.html"><a href="linearregression.html#logical-variables"><i class="fa fa-check"></i><b>1.3.2</b> Logical variables</a></li>
<li class="chapter" data-level="1.3.3" data-path="linearregression.html"><a href="linearregression.html#factor-variables"><i class="fa fa-check"></i><b>1.3.3</b> Factor variables</a></li>
<li class="chapter" data-level="1.3.4" data-path="linearregression.html"><a href="linearregression.html#interactions-and-differences-in-regression-functions-across-groups"><i class="fa fa-check"></i><b>1.3.4</b> Interactions and differences in regression functions across groups</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="linearregression.html"><a href="linearregression.html#heteroskedasticity"><i class="fa fa-check"></i><b>1.4</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="1.4.1" data-path="linearregression.html"><a href="linearregression.html#spotting-heteroskedasticity-in-scatter-plots"><i class="fa fa-check"></i><b>1.4.1</b> Spotting Heteroskedasticity in Scatter Plots</a></li>
<li class="chapter" data-level="1.4.2" data-path="linearregression.html"><a href="linearregression.html#heteroskedasticity-tests"><i class="fa fa-check"></i><b>1.4.2</b> Heteroskedasticity Tests</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="linearregression.html"><a href="linearregression.html#weighted-least-squares"><i class="fa fa-check"></i><b>1.5</b> Weighted least squares</a></li>
<li class="chapter" data-level="1.6" data-path="linearregression.html"><a href="linearregression.html#model-specification-and-parameter-heterogeneity"><i class="fa fa-check"></i><b>1.6</b> Model specification and Parameter Heterogeneity</a><ul>
<li class="chapter" data-level="1.6.1" data-path="linearregression.html"><a href="linearregression.html#functional-form-misspecifcation"><i class="fa fa-check"></i><b>1.6.1</b> Functional Form Misspecifcation</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="linearregression.html"><a href="linearregression.html#least-absolute-deviations-lad-estimation"><i class="fa fa-check"></i><b>1.7</b> Least absolute Deviations (LAD) Estimation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="binarymodels.html"><a href="binarymodels.html"><i class="fa fa-check"></i><b>2</b> Qualitative and LDV Models</a><ul>
<li class="chapter" data-level="2.1" data-path="binarymodels.html"><a href="binarymodels.html#linear-probability-models"><i class="fa fa-check"></i><b>2.1</b> Linear probability models</a></li>
<li class="chapter" data-level="2.2" data-path="binarymodels.html"><a href="binarymodels.html#logit-and-probit-models-estimation"><i class="fa fa-check"></i><b>2.2</b> Logit and Probit Models: Estimation</a><ul>
<li class="chapter" data-level="2.2.1" data-path="binarymodels.html"><a href="binarymodels.html#multinomial-logit"><i class="fa fa-check"></i><b>2.2.1</b> Multinomial Logit</a></li>
<li class="chapter" data-level="2.2.2" data-path="binarymodels.html"><a href="binarymodels.html#the-conditional-logit-model"><i class="fa fa-check"></i><b>2.2.2</b> The Conditional Logit Model</a></li>
<li class="chapter" data-level="2.2.3" data-path="binarymodels.html"><a href="binarymodels.html#ordered-choice-models"><i class="fa fa-check"></i><b>2.2.3</b> Ordered Choice Models</a></li>
<li class="chapter" data-level="2.2.4" data-path="binarymodels.html"><a href="binarymodels.html#probit-model"><i class="fa fa-check"></i><b>2.2.4</b> Probit model</a></li>
<li class="chapter" data-level="2.2.5" data-path="binarymodels.html"><a href="binarymodels.html#inference"><i class="fa fa-check"></i><b>2.2.5</b> Inference</a></li>
<li class="chapter" data-level="2.2.6" data-path="binarymodels.html"><a href="binarymodels.html#predictions"><i class="fa fa-check"></i><b>2.2.6</b> Predictions</a></li>
<li class="chapter" data-level="2.2.7" data-path="binarymodels.html"><a href="binarymodels.html#marginal-partial-effects"><i class="fa fa-check"></i><b>2.2.7</b> Marginal (partial) effects</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="binarymodels.html"><a href="binarymodels.html#count-data-the-poisson-regression-model"><i class="fa fa-check"></i><b>2.3</b> Count data: The Poisson Regression Model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="binarymodels.html"><a href="binarymodels.html#corner-solution-response-the-tobit-model"><i class="fa fa-check"></i><b>2.3.1</b> Corner Solution Response: The Tobit Model</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="binarymodels.html"><a href="binarymodels.html#censored-and-truncated-regression-models"><i class="fa fa-check"></i><b>2.4</b> Censored and Truncated Regression Models</a><ul>
<li class="chapter" data-level="2.4.1" data-path="binarymodels.html"><a href="binarymodels.html#the-heckman-or-sample-selection-model"><i class="fa fa-check"></i><b>2.4.1</b> The Heckman, or Sample Selection Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="timeseries.html"><a href="timeseries.html"><i class="fa fa-check"></i><b>3</b> Time Series</a><ul>
<li class="chapter" data-level="3.1" data-path="timeseries.html"><a href="timeseries.html#seasonal-decomposition-of-time-series"><i class="fa fa-check"></i><b>3.1</b> Seasonal decomposition of time Series</a></li>
<li class="chapter" data-level="3.2" data-path="timeseries.html"><a href="timeseries.html#differences-and-lags"><i class="fa fa-check"></i><b>3.2</b> Differences and lags</a></li>
<li class="chapter" data-level="3.3" data-path="timeseries.html"><a href="timeseries.html#exponential-smoothing-and-forecasting"><i class="fa fa-check"></i><b>3.3</b> Exponential smoothing and forecasting</a></li>
<li class="chapter" data-level="3.4" data-path="timeseries.html"><a href="timeseries.html#finite-distributed-lags-model"><i class="fa fa-check"></i><b>3.4</b> Finite Distributed Lags Model</a></li>
<li class="chapter" data-level="3.5" data-path="timeseries.html"><a href="timeseries.html#arima-models"><i class="fa fa-check"></i><b>3.5</b> ARIMA models</a><ul>
<li class="chapter" data-level="3.5.1" data-path="timeseries.html"><a href="timeseries.html#simulation-of-arima-models"><i class="fa fa-check"></i><b>3.5.1</b> Simulation of ARIMA models</a></li>
<li class="chapter" data-level="3.5.2" data-path="timeseries.html"><a href="timeseries.html#acf-and-pacf"><i class="fa fa-check"></i><b>3.5.2</b> ACF and PACF</a></li>
<li class="chapter" data-level="3.5.3" data-path="timeseries.html"><a href="timeseries.html#estimation-of-arima-models"><i class="fa fa-check"></i><b>3.5.3</b> Estimation of ARIMA models</a></li>
<li class="chapter" data-level="3.5.4" data-path="timeseries.html"><a href="timeseries.html#choosing-between-models"><i class="fa fa-check"></i><b>3.5.4</b> Choosing between models</a></li>
<li class="chapter" data-level="3.5.5" data-path="timeseries.html"><a href="timeseries.html#automatic-esimation"><i class="fa fa-check"></i><b>3.5.5</b> Automatic esimation</a></li>
<li class="chapter" data-level="3.5.6" data-path="timeseries.html"><a href="timeseries.html#testing-for-unit-root"><i class="fa fa-check"></i><b>3.5.6</b> Testing for unit root</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MEM52220 - Applied Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linearregression" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Linear Regression</h1>
<p>To load the dataset and necessary functions:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="linearregression.html#cb3-1"></a><span class="co"># This function 1. checks if the packages are installed. 2. It installs the packages if they were not in the list of installed packages. 3. It loads the packages into the workspace</span></span>
<span id="cb3-2"><a href="linearregression.html#cb3-2"></a><span class="co"># devtools::install_github(&quot;ccolonescu/PoEdata&quot;)</span></span>
<span id="cb3-3"><a href="linearregression.html#cb3-3"></a>PACKAGES&lt;-<span class="kw">c</span>(<span class="st">&quot;PoEdata&quot;</span>, <span class="co"># R data sets for &quot;Principles of Econometrics&quot; by Hill, Griffiths, an d Lim, 4e, Wiley. https://github.com/ccolonescu/PoEdata</span></span>
<span id="cb3-4"><a href="linearregression.html#cb3-4"></a>            <span class="st">&quot;wooldridge&quot;</span>,  <span class="co"># Wooldrige Datasets</span></span>
<span id="cb3-5"><a href="linearregression.html#cb3-5"></a>            <span class="st">&quot;tidyverse&quot;</span>,  <span class="co"># for data manipulation and ggplots</span></span>
<span id="cb3-6"><a href="linearregression.html#cb3-6"></a>            <span class="st">&quot;broom&quot;</span>,  <span class="co"># Tidy regression output</span></span>
<span id="cb3-7"><a href="linearregression.html#cb3-7"></a>            <span class="st">&quot;ggpubr&quot;</span>,  <span class="co"># Multiple ggplots on a page. Note that, the installation of ggpubr will automatically install the gridExtra and the cowplot package; so you don’t need to re-install them. </span></span>
<span id="cb3-8"><a href="linearregression.html#cb3-8"></a>            <span class="st">&quot;ggfortify&quot;</span>, <span class="co"># Simple ggplot recipe for lm objects) </span></span>
<span id="cb3-9"><a href="linearregression.html#cb3-9"></a>            <span class="st">&quot;plot3D&quot;</span>,  <span class="co">#  3D graphs</span></span>
<span id="cb3-10"><a href="linearregression.html#cb3-10"></a>            <span class="st">&quot;car&quot;</span>, <span class="co"># Companion to applied regression</span></span>
<span id="cb3-11"><a href="linearregression.html#cb3-11"></a>            <span class="st">&quot;knitr&quot;</span>, <span class="co"># knit functions</span></span>
<span id="cb3-12"><a href="linearregression.html#cb3-12"></a>            <span class="co"># &quot;kableExtra&quot;, # extended knit functions for objects exported from other packages</span></span>
<span id="cb3-13"><a href="linearregression.html#cb3-13"></a>            <span class="st">&quot;huxtable&quot;</span>, <span class="co">#  Regression tables, broom compatible</span></span>
<span id="cb3-14"><a href="linearregression.html#cb3-14"></a>            <span class="st">&quot;mice&quot;</span>,  <span class="co"># multiple imputation</span></span>
<span id="cb3-15"><a href="linearregression.html#cb3-15"></a>            <span class="st">&quot;VIM&quot;</span>, <span class="co"># visualizing missing data</span></span>
<span id="cb3-16"><a href="linearregression.html#cb3-16"></a>            <span class="st">&quot;stargazer&quot;</span>, <span class="co"># Regression tables</span></span>
<span id="cb3-17"><a href="linearregression.html#cb3-17"></a>            <span class="st">&quot;AER&quot;</span>, <span class="co">#  Functions, data sets, examples, demos, and vignettes for the book Christian Kleiber and Achim Zeileis (2008)</span></span>
<span id="cb3-18"><a href="linearregression.html#cb3-18"></a>            <span class="st">&quot;MASS&quot;</span>,  <span class="co">#  Functions and datasets to support Venables and Ripley,  &quot;Modern Applied Statistics with S&quot;</span></span>
<span id="cb3-19"><a href="linearregression.html#cb3-19"></a>            <span class="st">&quot;mvtnorm&quot;</span>, <span class="co"># Multivariate Normal and t Distributions </span></span>
<span id="cb3-20"><a href="linearregression.html#cb3-20"></a>            <span class="st">&quot;summarytools&quot;</span>, <span class="co"># Report regression summary tables</span></span>
<span id="cb3-21"><a href="linearregression.html#cb3-21"></a>            <span class="st">&quot;scales&quot;</span>, <span class="co"># scale helper functions such as percent </span></span>
<span id="cb3-22"><a href="linearregression.html#cb3-22"></a>            <span class="st">&quot;OutliersO3&quot;</span>, <span class="co"># Outlier comparison method</span></span>
<span id="cb3-23"><a href="linearregression.html#cb3-23"></a>            <span class="st">&quot;robustbase&quot;</span>, <span class="co"># Basic robust statistics</span></span>
<span id="cb3-24"><a href="linearregression.html#cb3-24"></a>            <span class="st">&quot;quantreg&quot;</span>, <span class="co"># Quantile regression</span></span>
<span id="cb3-25"><a href="linearregression.html#cb3-25"></a>            <span class="st">&quot;modelr&quot;</span>, <span class="co"># model simulation/ boostraping the modern way</span></span>
<span id="cb3-26"><a href="linearregression.html#cb3-26"></a>            <span class="st">&quot;magrittr&quot;</span>) <span class="co">#  pipes</span></span>
<span id="cb3-27"><a href="linearregression.html#cb3-27"></a>inst&lt;-<span class="kw">match</span>(PACKAGES, <span class="kw">.packages</span>(<span class="dt">all=</span><span class="ot">TRUE</span>))</span>
<span id="cb3-28"><a href="linearregression.html#cb3-28"></a>need&lt;-<span class="kw">which</span>(<span class="kw">is.na</span>(inst))</span>
<span id="cb3-29"><a href="linearregression.html#cb3-29"></a><span class="cf">if</span> (<span class="kw">length</span>(need)<span class="op">&gt;</span><span class="dv">0</span>) <span class="kw">install.packages</span>(PACKAGES[need], <span class="dt">repos =</span> <span class="st">&quot;http://cran.us.r-project.org&quot;</span>)</span>
<span id="cb3-30"><a href="linearregression.html#cb3-30"></a><span class="kw">lapply</span>(PACKAGES, require, <span class="dt">character.only=</span>T)</span></code></pre></div>
<pre><code>## Warning in fun(libname, pkgname): couldn&#39;t connect to display &quot;:0&quot;</code></pre>
<div id="simple-linear-regression" class="section level2">
<h2><span class="header-section-number">1.1</span> Simple Linear Regression</h2>
<p>We start off with a simple OLS Regression. We will work with multiple data sources:</p>
<ul>
<li>Data from <span class="citation">Wooldridge (<a href="#ref-wooldridge2015introductory" role="doc-biblioref">2015</a>)</span> : Introductory Econometrics: A Modern Approach.</li>
<li>R data sets for “Principles of Econometrics” by <span class="citation">Hill et al. (<a href="#ref-hill2008principles" role="doc-biblioref">2008</a>)</span></li>
<li>Build in examples such as the <code>airquality</code> dataset</li>
</ul>
<p>Classic examples of quantities modeled with simple linear regression:</p>
<ul>
<li>College GPA <span class="math inline">\(\sim\)</span> SAT scores <span class="math inline">\(\beta &gt; 0\)</span></li>
<li>Change in GDP <span class="math inline">\(\sim\)</span> change in unemployment <span class="math inline">\(\beta &lt; 0\)</span></li>
<li>House price <span class="math inline">\(\sim\)</span> number of bedrooms <span class="math inline">\(\beta &gt; 0\)</span></li>
<li>Species heart weight <span class="math inline">\(\sim\)</span> species body weight <span class="math inline">\(\beta &gt; 0\)</span></li>
<li>Fatalities per year <span class="math inline">\(\sim\)</span> speed limit <span class="math inline">\(\beta &lt; 0\)</span></li>
</ul>
<p>Notice that these simple linear regressions are simplifications of
more complex relationships between the variables in question.</p>
<p>In this exercise we use the dataset <em>ceosal1</em>. Let us analyse the dataset first</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="linearregression.html#cb5-1"></a><span class="kw">data</span>(<span class="st">&quot;ceosal1&quot;</span>)</span>
<span id="cb5-2"><a href="linearregression.html#cb5-2"></a><span class="kw">help</span>(<span class="st">&quot;ceosal1&quot;</span>)</span>
<span id="cb5-3"><a href="linearregression.html#cb5-3"></a>?ceosal1</span></code></pre></div>
<p>As we see from the R documentation the <em>ceosal1</em> dataset contain of a random sample of data reported in the May 6, 1991 issue of Businessweek.</p>
<p>To get a first look at the data you can use the <code>View()</code> function inside R Studio.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="linearregression.html#cb6-1"></a><span class="kw">View</span>(ceosal1) <span class="co"># For the compilation we omit the full View()</span></span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-6">Table 1.1: </span>A table of the first eight columns and ten rows of the ceosal1 data.</caption>
<thead>
<tr class="header">
<th align="right">salary</th>
<th align="right">pcsalary</th>
<th align="right">sales</th>
<th align="right">roe</th>
<th align="right">pcroe</th>
<th align="right">ros</th>
<th align="right">indus</th>
<th align="right">finance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1095</td>
<td align="right">20</td>
<td align="right">27595.0</td>
<td align="right">14.1</td>
<td align="right">106.4</td>
<td align="right">191</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1001</td>
<td align="right">32</td>
<td align="right">9958.0</td>
<td align="right">10.9</td>
<td align="right">-30.6</td>
<td align="right">13</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1122</td>
<td align="right">9</td>
<td align="right">6125.9</td>
<td align="right">23.5</td>
<td align="right">-16.3</td>
<td align="right">14</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">578</td>
<td align="right">-9</td>
<td align="right">16246.0</td>
<td align="right">5.9</td>
<td align="right">-25.7</td>
<td align="right">-21</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1368</td>
<td align="right">7</td>
<td align="right">21783.2</td>
<td align="right">13.8</td>
<td align="right">-3.0</td>
<td align="right">56</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1145</td>
<td align="right">5</td>
<td align="right">6021.4</td>
<td align="right">20.0</td>
<td align="right">1.0</td>
<td align="right">55</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1078</td>
<td align="right">10</td>
<td align="right">2266.7</td>
<td align="right">16.4</td>
<td align="right">-5.9</td>
<td align="right">62</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1094</td>
<td align="right">7</td>
<td align="right">2966.8</td>
<td align="right">16.3</td>
<td align="right">-1.6</td>
<td align="right">44</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1237</td>
<td align="right">16</td>
<td align="right">4570.2</td>
<td align="right">10.5</td>
<td align="right">-70.2</td>
<td align="right">37</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">833</td>
<td align="right">5</td>
<td align="right">2830.0</td>
<td align="right">26.3</td>
<td align="right">-23.9</td>
<td align="right">37</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>We could also take a look at the variable names, the dimension of the data frame, and some sample observations with <code>str()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="linearregression.html#cb7-1"></a><span class="kw">str</span>(ceosal1)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    209 obs. of  12 variables:
##  $ salary  : int  1095 1001 1122 578 1368 1145 1078 1094 1237 833 ...
##  $ pcsalary: int  20 32 9 -9 7 5 10 7 16 5 ...
##  $ sales   : num  27595 9958 6126 16246 21783 ...
##  $ roe     : num  14.1 10.9 23.5 5.9 13.8 ...
##  $ pcroe   : num  106.4 -30.6 -16.3 -25.7 -3 ...
##  $ ros     : int  191 13 14 -21 56 55 62 44 37 37 ...
##  $ indus   : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ finance : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ consprod: int  0 0 0 0 0 0 0 0 0 0 ...
##  $ utility : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ lsalary : num  7 6.91 7.02 6.36 7.22 ...
##  $ lsales  : num  10.23 9.21 8.72 9.7 9.99 ...
##  - attr(*, &quot;time.stamp&quot;)= chr &quot;25 Jun 2011 23:03&quot;</code></pre>
<p>As we have seen before in the general R tutorial, there are a number of additional functions to access some of this information directly.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="linearregression.html#cb9-1"></a><span class="kw">dim</span>(ceosal1)</span></code></pre></div>
<pre><code>## [1] 209  12</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="linearregression.html#cb11-1"></a><span class="kw">nrow</span>(ceosal1)</span></code></pre></div>
<pre><code>## [1] 209</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="linearregression.html#cb13-1"></a><span class="kw">ncol</span>(ceosal1)</span></code></pre></div>
<pre><code>## [1] 12</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="linearregression.html#cb15-1"></a><span class="kw">summary</span>(ceosal1)</span></code></pre></div>
<pre><code>##      salary         pcsalary          sales              roe       
##  Min.   :  223   Min.   :-61.00   Min.   :  175.2   Min.   : 0.50  
##  1st Qu.:  736   1st Qu.: -1.00   1st Qu.: 2210.3   1st Qu.:12.40  
##  Median : 1039   Median :  9.00   Median : 3705.2   Median :15.50  
##  Mean   : 1281   Mean   : 13.28   Mean   : 6923.8   Mean   :17.18  
##  3rd Qu.: 1407   3rd Qu.: 20.00   3rd Qu.: 7177.0   3rd Qu.:20.00  
##  Max.   :14822   Max.   :212.00   Max.   :97649.9   Max.   :56.30  
##      pcroe            ros            indus           finance      
##  Min.   :-98.9   Min.   :-58.0   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:-21.2   1st Qu.: 21.0   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median : -3.0   Median : 52.0   Median :0.0000   Median :0.0000  
##  Mean   : 10.8   Mean   : 61.8   Mean   :0.3206   Mean   :0.2201  
##  3rd Qu.: 19.5   3rd Qu.: 81.0   3rd Qu.:1.0000   3rd Qu.:0.0000  
##  Max.   :977.0   Max.   :418.0   Max.   :1.0000   Max.   :1.0000  
##     consprod         utility          lsalary          lsales      
##  Min.   :0.0000   Min.   :0.0000   Min.   :5.407   Min.   : 5.166  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:6.601   1st Qu.: 7.701  
##  Median :0.0000   Median :0.0000   Median :6.946   Median : 8.217  
##  Mean   :0.2871   Mean   :0.1722   Mean   :6.950   Mean   : 8.292  
##  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:7.249   3rd Qu.: 8.879  
##  Max.   :1.0000   Max.   :1.0000   Max.   :9.604   Max.   :11.489</code></pre>
<p>The interesting task here is to determine how far a high the CEO salary is, for a given return on equity.</p>
<hr />
<p><strong>Your turn</strong></p>
<p>What sign would be expect of <span class="math inline">\(\beta\)</span> (the slope)?</p>
<p>A: Without seeing the data <strong>my</strong> prior is that <span class="math inline">\(\beta &gt; 0\)</span>.</p>
<hr />
<p><strong>Note</strong></p>
<p>A simple linear model as assumes that the mean of each <span class="math inline">\(y_{i}\)</span> conditioned on <span class="math inline">\(x_{i}\)</span>
is a linear function of <span class="math inline">\(x_{i}\)</span>. But notice that simple linear regressions are simplifications of more complex relationships between the variables in question <span class="citation">Dalpiaz (<a href="#ref-dalpiaz2016" role="doc-biblioref">2016</a>)</span>.</p>
<hr />
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="linearregression.html#cb17-1"></a><span class="co"># Use ggplot style</span></span>
<span id="cb17-2"><a href="linearregression.html#cb17-2"></a><span class="kw">ggplot</span>(ceosal1, <span class="kw">aes</span>(<span class="dt">x =</span> roe, <span class="dt">y =</span> salary)) <span class="op">+</span></span>
<span id="cb17-3"><a href="linearregression.html#cb17-3"></a><span class="st">  </span><span class="kw">geom_point</span>()</span></code></pre></div>
<div class="figure"><span id="fig:ceosal1"></span>
<img src="MEM5220_R_files/figure-html/ceosal1-1.png" alt="Relationship between ROE and Salary" width="672" />
<p class="caption">
Figure 1.1: Relationship between ROE and Salary
</p>
</div>
<p>Consider a simple regression model</p>
<p><span class="math inline">\(salary = \beta_0 + \beta_1roe + u\)</span></p>
<p>In the general form the linear regression model can be written as:</p>
<p><span class="math display" id="eq:simplelinearregressionmodel">\[\begin{equation}
y = \beta_{0} + \beta_{1}x + u
\tag{1.1}
\end{equation}\]</span></p>
<p>We are concerned with the population parameter <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>. The ordinary least squares (OLS) estimators are:</p>
<p><span class="math display" id="eq:populationparameterBeta0">\[\begin{equation}
\hat{\beta}_{0} = \bar{y} - \hat{\beta}_{1}\bar{x}
\tag{1.2}
\end{equation}\]</span></p>
<p>The ordinary least squares (OLS) estimators are</p>
<p><span class="math display" id="eq:populationparameterBeta1">\[\begin{equation}
\hat{\beta}_{1} = \frac{Cov(x,y)}{Var(x)}
\tag{1.3}
\end{equation}\]</span></p>
<p>Ingredients for the OLS formulas</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="linearregression.html#cb18-1"></a><span class="kw">attach</span>(ceosal1)</span>
<span id="cb18-2"><a href="linearregression.html#cb18-2"></a><span class="kw">cov</span>(roe, salary)</span></code></pre></div>
<pre><code>## [1] 1342.538</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="linearregression.html#cb20-1"></a><span class="kw">var</span>(roe)</span></code></pre></div>
<pre><code>## [1] 72.56499</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="linearregression.html#cb22-1"></a><span class="kw">mean</span>(salary)</span></code></pre></div>
<pre><code>## [1] 1281.12</code></pre>
<p>Manual calculation of the OLS coefficients</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="linearregression.html#cb24-1"></a>b1hat &lt;-<span class="st"> </span><span class="kw">cov</span>(roe,salary)<span class="op">/</span><span class="kw">var</span>(roe)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="linearregression.html#cb25-1"></a>b0hat &lt;-<span class="st"> </span><span class="kw">mean</span>(salary) <span class="op">-</span><span class="st"> </span>b1hat <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(roe)</span></code></pre></div>
<p>Or use the <code>lm()</code> function</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="linearregression.html#cb26-1"></a><span class="kw">lm</span>(salary <span class="op">~</span><span class="st"> </span>roe, <span class="dt">data=</span>ceosal1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = salary ~ roe, data = ceosal1)
## 
## Coefficients:
## (Intercept)          roe  
##       963.2         18.5</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="linearregression.html#cb28-1"></a>lm1_ceosal1 &lt;-<span class="st"> </span><span class="kw">lm</span>(salary <span class="op">~</span><span class="st"> </span>roe, <span class="dt">data=</span>ceosal1) </span>
<span id="cb28-2"><a href="linearregression.html#cb28-2"></a><span class="kw">summary</span>(lm1_ceosal1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = salary ~ roe, data = ceosal1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1160.2  -526.0  -254.0   138.8 13499.9 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   963.19     213.24   4.517 1.05e-05 ***
## roe            18.50      11.12   1.663   0.0978 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1367 on 207 degrees of freedom
## Multiple R-squared:  0.01319,    Adjusted R-squared:  0.008421 
## F-statistic: 2.767 on 1 and 207 DF,  p-value: 0.09777</code></pre>
<p>Plot the linear regression fit the <em>base</em> r way.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="linearregression.html#cb30-1"></a><span class="kw">plot</span>(salary<span class="op">~</span><span class="st"> </span>roe, <span class="dt">data =</span> ceosal1,</span>
<span id="cb30-2"><a href="linearregression.html#cb30-2"></a>     <span class="dt">xlab =</span> <span class="st">&quot;Return on equity&quot;</span>,</span>
<span id="cb30-3"><a href="linearregression.html#cb30-3"></a>     <span class="dt">ylab =</span> <span class="st">&quot;Salary&quot;</span>,</span>
<span id="cb30-4"><a href="linearregression.html#cb30-4"></a>     <span class="dt">main =</span> <span class="st">&quot;Salary vs return on equity&quot;</span>,</span>
<span id="cb30-5"><a href="linearregression.html#cb30-5"></a>     <span class="dt">pch  =</span> <span class="dv">20</span>,</span>
<span id="cb30-6"><a href="linearregression.html#cb30-6"></a>     <span class="dt">cex  =</span> <span class="dv">2</span>,</span>
<span id="cb30-7"><a href="linearregression.html#cb30-7"></a>     <span class="dt">col  =</span> <span class="st">&quot;grey&quot;</span>)</span>
<span id="cb30-8"><a href="linearregression.html#cb30-8"></a><span class="kw">abline</span>(lm1_ceosal1, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">col =</span> <span class="st">&quot;darkorange&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig1"></span>
<img src="MEM5220_R_files/figure-html/fig1-1.png" alt="OLS regression base Rstyle" width="80%" />
<p class="caption">
Figure 1.2: OLS regression base Rstyle
</p>
</div>
<p>Or use ggplot</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="linearregression.html#cb31-1"></a><span class="kw">ggplot</span>(ceosal1, <span class="kw">aes</span>(<span class="dt">x =</span> roe, <span class="dt">y =</span> salary)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb31-2"><a href="linearregression.html#cb31-2"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb31-3"><a href="linearregression.html#cb31-3"></a><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig2"></span>
<img src="MEM5220_R_files/figure-html/fig2-1.png" alt="OLS regression ggplot2 style" width="80%" />
<p class="caption">
Figure 1.3: OLS regression ggplot2 style
</p>
</div>
<p>Determine the names of the elements of the list using the <code>names()</code> command.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="linearregression.html#cb32-1"></a><span class="kw">names</span>(lm1_ceosal1)</span></code></pre></div>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;</code></pre>
<p>Extract one element, for example the residuals from the list object</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="linearregression.html#cb34-1"></a><span class="kw">head</span>(lm1_ceosal1<span class="op">$</span>residuals) <span class="co"># head() just prints out the first 6 residual values</span></span></code></pre></div>
<pre><code>##         1         2         3         4         5         6 
## -129.0581 -163.8543 -275.9692 -494.3483  149.4923 -188.2151</code></pre>
<p>Another way to access stored information in <em>lm1_ceosal1</em> are the <code>coef()</code>, <code>resid()</code>, and <code>fitted()</code> functions. These return the coefficients, residuals, and fitted values, respectively.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="linearregression.html#cb36-1"></a><span class="kw">coef</span>(lm1_ceosal1)</span></code></pre></div>
<pre><code>## (Intercept)         roe 
##   963.19134    18.50119</code></pre>
<p>The function <code>summary()</code> is useful in many situations. We see that when it is called on our model, it returns a good deal of information.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="linearregression.html#cb38-1"></a><span class="kw">summary</span>(lm1_ceosal1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = salary ~ roe, data = ceosal1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1160.2  -526.0  -254.0   138.8 13499.9 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   963.19     213.24   4.517 1.05e-05 ***
## roe            18.50      11.12   1.663   0.0978 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1367 on 207 degrees of freedom
## Multiple R-squared:  0.01319,    Adjusted R-squared:  0.008421 
## F-statistic: 2.767 on 1 and 207 DF,  p-value: 0.09777</code></pre>
<p>The <code>summary()</code> command also returns a list, and we can again use <code>names()</code> to learn what about the elements of this list.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="linearregression.html#cb40-1"></a><span class="kw">names</span>(<span class="kw">summary</span>(lm1_ceosal1))</span></code></pre></div>
<pre><code>##  [1] &quot;call&quot;          &quot;terms&quot;         &quot;residuals&quot;     &quot;coefficients&quot; 
##  [5] &quot;aliased&quot;       &quot;sigma&quot;         &quot;df&quot;            &quot;r.squared&quot;    
##  [9] &quot;adj.r.squared&quot; &quot;fstatistic&quot;    &quot;cov.unscaled&quot;</code></pre>
<p>So, for example, if we wanted to directly access the value of <span class="math inline">\(R^2\)</span>, instead of copy and pasting it out of the printed statement from <code>summary()</code>, we could do so.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="linearregression.html#cb42-1"></a><span class="kw">summary</span>(lm1_ceosal1)<span class="op">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.01318862</code></pre>
<hr />
<p><strong>Your turn</strong></p>
<p>Recall that the explained sum of squares (SSE) is</p>
<p><span class="math display" id="eq:SSE">\[\begin{equation}
SSE = \sum_{i=1}^{n}(\hat{y}_{i} - \bar{y})^2 = (n-1) \times Var(\hat{y})
\tag{1.4}
\end{equation}\]</span></p>
<p>and the residual sum of squares (SSR) is</p>
<p><span class="math display" id="eq:SSR">\[\begin{equation}
R^2 = \frac{Var(\hat{y})}{Var(y)} = 1 - \frac{Var(\hat{u})}{Var(y)} 
\tag{1.5}
\end{equation}\]</span></p>
<p>One can see that the correlation between observed and fitted values is a square root of <span class="math inline">\(R^2\)</span>.</p>
<p>Calculate <span class="math inline">\(R^2\)</span> manually:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="linearregression.html#cb44-1"></a><span class="kw">var</span>(<span class="kw">fitted</span>(lm1_ceosal1))<span class="op">/</span><span class="kw">var</span>(ceosal1<span class="op">$</span>salary)</span></code></pre></div>
<pre><code>## [1] 0.01318862</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="linearregression.html#cb46-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">var</span>(<span class="kw">residuals</span>(lm1_ceosal1))<span class="op">/</span><span class="kw">var</span>(ceosal1<span class="op">$</span>salary)</span></code></pre></div>
<pre><code>## [1] 0.01318862</code></pre>
<hr />
<p>Another useful function is the <code>predict()</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="linearregression.html#cb48-1"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb48-2"><a href="linearregression.html#cb48-2"></a><span class="co"># unique(ceosal1$roe)</span></span>
<span id="cb48-3"><a href="linearregression.html#cb48-3"></a>roe_sample &lt;-<span class="kw">sample</span>(ceosal1<span class="op">$</span>roe, <span class="dv">1</span>)</span>
<span id="cb48-4"><a href="linearregression.html#cb48-4"></a>roe_sample</span></code></pre></div>
<pre><code>## [1] 19.6</code></pre>
<p>Let’s make a prediction for salary when the return on equity is 19.6000004.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="linearregression.html#cb50-1"></a>b0hat_sample &lt;-<span class="st"> </span><span class="kw">mean</span>(salary) <span class="op">-</span><span class="st"> </span>b1hat <span class="op">*</span><span class="st"> </span>roe_sample </span></code></pre></div>
<p>We are not restricted to observed values of the explanatory variable. Instead we can supply also our own predictor values</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="linearregression.html#cb51-1"></a><span class="kw">predict</span>(lm1_ceosal1, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">roe =</span> <span class="dv">30</span>))</span></code></pre></div>
<pre><code>##        1 
## 1518.227</code></pre>
<p>The above code reads “predict the salary when the return on equity is 30 using the <em>lm1_ceosal1</em> model.”</p>
<hr />
<details>
<summary><strong>Overthinking</strong></summary>
<p>
<div id="regression-through-the-origin-and-regression-on-a-constant" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Regression through the Origin and Regression on a Constant</h3>
<p>Regression without intercept (through origin)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="linearregression.html#cb53-1"></a>lm2 &lt;-<span class="st"> </span><span class="kw">lm</span>(salary <span class="op">~</span><span class="st">  </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>roe, <span class="dt">data =</span> ceosal1)</span></code></pre></div>
<p>Regression without slope</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="linearregression.html#cb54-1"></a>lm3 &lt;-<span class="st"> </span><span class="kw">lm</span>(salary <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> ceosal1)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="linearregression.html#cb55-1"></a><span class="kw">plot</span>(salary<span class="op">~</span><span class="st"> </span>roe, <span class="dt">data =</span> ceosal1,</span>
<span id="cb55-2"><a href="linearregression.html#cb55-2"></a>     <span class="dt">xlab =</span> <span class="st">&quot;Return on equity&quot;</span>,</span>
<span id="cb55-3"><a href="linearregression.html#cb55-3"></a>     <span class="dt">ylab =</span> <span class="st">&quot;Salary&quot;</span>,</span>
<span id="cb55-4"><a href="linearregression.html#cb55-4"></a>     <span class="dt">main =</span> <span class="st">&quot;Salary vs return on equity&quot;</span>,</span>
<span id="cb55-5"><a href="linearregression.html#cb55-5"></a>     <span class="dt">pch  =</span> <span class="dv">20</span>,</span>
<span id="cb55-6"><a href="linearregression.html#cb55-6"></a>     <span class="dt">cex  =</span> <span class="dv">2</span>,</span>
<span id="cb55-7"><a href="linearregression.html#cb55-7"></a>     <span class="dt">col  =</span> <span class="st">&quot;grey&quot;</span>)</span>
<span id="cb55-8"><a href="linearregression.html#cb55-8"></a><span class="kw">abline</span>(lm1_ceosal1, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;darkorange&quot;</span>)</span>
<span id="cb55-9"><a href="linearregression.html#cb55-9"></a><span class="kw">abline</span>(lm2,<span class="dt">lwd =</span> <span class="dv">3</span>,  <span class="dt">lty =</span> <span class="dv">2</span>,   <span class="dt">col =</span> <span class="st">&quot;darkblue&quot;</span>)</span>
<span id="cb55-10"><a href="linearregression.html#cb55-10"></a><span class="kw">abline</span>(lm3, <span class="dt">lwd =</span> <span class="dv">3</span>,  <span class="dt">lty =</span> <span class="dv">3</span>,   <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb55-11"><a href="linearregression.html#cb55-11"></a><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, </span>
<span id="cb55-12"><a href="linearregression.html#cb55-12"></a>       <span class="kw">c</span>(<span class="st">&quot;full&quot;</span>, </span>
<span id="cb55-13"><a href="linearregression.html#cb55-13"></a>         <span class="st">&quot;through origin&quot;</span>, </span>
<span id="cb55-14"><a href="linearregression.html#cb55-14"></a>         <span class="st">&quot;constant only&quot;</span>), </span>
<span id="cb55-15"><a href="linearregression.html#cb55-15"></a>       <span class="dt">lwd =</span><span class="dv">2</span>, </span>
<span id="cb55-16"><a href="linearregression.html#cb55-16"></a>       <span class="dt">lty =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig3"></span>
<img src="MEM5220_R_files/figure-html/fig3-1.png" alt="Regression through the Origin and on a Constant" width="80%" />
<p class="caption">
Figure 1.4: Regression through the Origin and on a Constant
</p>
</div>
<p>In models without the intercept the <span class="math inline">\(R^2\)</span> loses its interpretatation. The reason is that the <span class="math inline">\(R^2\)</span> is the ratio of explained variance to total variance <strong>only</strong> if the intercept is included.</p>
<hr />
</p>
</details>
<p><strong>Overthinking</strong></p>
</div>
<div id="simulating-slr" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Simulating SLR</h3>
<div id="expected-values-variance-and-standard-errors" class="section level5">
<h5><span class="header-section-number">1.1.2.0.1</span> Expected Values, Variance, and Standard Errors</h5>
<p>The <strong>Gauss–Markov theorem</strong> tells us that when estimating the parameters of the simple linear regression model <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>, the <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> which we derived are the best linear unbiased estimates, or BLUE for short. (The actual conditions for the Gauss–Markov theorem are more relaxed than the SLR model.)</p>
<p>In short those assumptions are:</p>
<ul>
<li>SLR.1 Linear population regression function <span class="math inline">\(y = \beta_0 + \beta_{1} \times x + u\)</span></li>
<li>SLR.2 Random sampling of x and y from the population<br />
</li>
<li>SLR.3 Variation in the sample values: <span class="math inline">\(x_{1}, \dots , x_{n}\)</span></li>
<li>SLR.4 Zero conditional mean: <span class="math inline">\(\mathbf{E}(u|x) = 0\)</span></li>
<li>SLR.5 Homeskedasticity: <span class="math inline">\(Var(u|x) = \sigma^2\)</span></li>
</ul>
<p>Recall that under <strong>SLR.1 - SLR.4</strong> the OLS parameter estimators are unbiased. Under <strong>SLR.1 - SLR.4</strong> the OLS parameter estimators have a specific sampling variance.</p>
<p>Simulating a model is an important concept. In practice you will almost never have a true model, and you will use data to attempt to recover information about the unknown true model. With simulation, we decide the true model and simulate data from it. Then, we apply a method to the data, in this case least squares. Now, since we know the true model, we can assess how well it did.</p>
<p>Simulation also helps to grasp the concepts of estimators, estimates, unbiasedness, the sampling variance of the estimators, and the consequences of violated assumptions.</p>
<p>Sample size</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="linearregression.html#cb56-1"></a>n &lt;-<span class="st"> </span><span class="dv">200</span></span></code></pre></div>
<p>True parameters</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="linearregression.html#cb57-1"></a>b0&lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb57-2"><a href="linearregression.html#cb57-2"></a>b1 &lt;-<span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb57-3"><a href="linearregression.html#cb57-3"></a>sigma &lt;-<span class="st"> </span><span class="dv">2</span> <span class="co"># standard deviation of the error term u </span></span>
<span id="cb57-4"><a href="linearregression.html#cb57-4"></a>x1 &lt;-<span class="st"> </span><span class="dv">5</span></span></code></pre></div>
<p>Determine the distribution of the independent variable</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="linearregression.html#cb58-1"></a>yhat1 &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1 <span class="op">*</span><span class="st"> </span>x1 <span class="co">#  Note that we do not include the error term </span></span></code></pre></div>
<p>Plot a Gaussian distribution of the dependent variable based on the parameters</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="linearregression.html#cb59-1"></a><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean =</span> yhat1, <span class="dt">sd =</span> sigma), <span class="dv">-5</span>, <span class="dv">15</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb59-2"><a href="linearregression.html#cb59-2"></a><span class="kw">abline</span>(<span class="dt">v =</span> yhat1, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</span>
<span id="cb59-3"><a href="linearregression.html#cb59-3"></a><span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;f(y|x = 5)&quot;</span>), <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<p><img src="MEM5220_R_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>This represent the theoretical (true) probability distribution of <span class="math inline">\(y\)</span>, given <span class="math inline">\(x\)</span></p>
<p>We can calculate the variance of <span class="math inline">\(b_{1}\)</span> and plot the corresponding density function.</p>
<p><span class="math display" id="eq:variancebeta">\[\begin{equation}
var(b_2) = \frac{\sigma^2}{\sum{}{}(x_1 - \bar{x})^2}
\tag{1.6}
\end{equation}\]</span></p>
<p>Assume that <span class="math inline">\(x_{2}\)</span> represents a second possible predictor of <span class="math inline">\(y\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="linearregression.html#cb60-1"></a>x2 &lt;-<span class="st"> </span><span class="dv">18</span></span>
<span id="cb60-2"><a href="linearregression.html#cb60-2"></a></span>
<span id="cb60-3"><a href="linearregression.html#cb60-3"></a>x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(x1, n<span class="op">/</span><span class="dv">2</span>), <span class="kw">rep</span>(x2, n<span class="op">/</span><span class="dv">2</span>))</span>
<span id="cb60-4"><a href="linearregression.html#cb60-4"></a>xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(x)</span>
<span id="cb60-5"><a href="linearregression.html#cb60-5"></a></span>
<span id="cb60-6"><a href="linearregression.html#cb60-6"></a>sumxbar &lt;-<span class="st"> </span><span class="kw">sum</span>((x<span class="op">-</span>xbar)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb60-7"><a href="linearregression.html#cb60-7"></a>varb &lt;-<span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>sumxbar</span>
<span id="cb60-8"><a href="linearregression.html#cb60-8"></a>sdb &lt;-<span class="kw">sqrt</span>(varb)</span>
<span id="cb60-9"><a href="linearregression.html#cb60-9"></a>leftlim &lt;-<span class="st"> </span>b1<span class="dv">-3</span><span class="op">*</span>sdb</span>
<span id="cb60-10"><a href="linearregression.html#cb60-10"></a>rightlim &lt;-<span class="st"> </span>b1<span class="op">+</span><span class="dv">3</span><span class="op">*</span>sdb</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="linearregression.html#cb61-1"></a><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean =</span> b1, <span class="dt">sd =</span> sdb), leftlim, rightlim)</span>
<span id="cb61-2"><a href="linearregression.html#cb61-2"></a><span class="kw">abline</span>(<span class="dt">v =</span> b1, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig4"></span>
<img src="MEM5220_R_files/figure-html/fig4-1.png" alt="The theoretical (true) probability density function of b1" width="80%" />
<p class="caption">
Figure 1.5: The theoretical (true) probability density function of b1
</p>
</div>
<p>Draw sample of size <span class="math inline">\(n\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="linearregression.html#cb62-1"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">4</span>, sigma)</span>
<span id="cb62-2"><a href="linearregression.html#cb62-2"></a><span class="co"># Another way is to assume that the values for x are fixed and know</span></span>
<span id="cb62-3"><a href="linearregression.html#cb62-3"></a><span class="co"># x= seq(from = 0, to = 10, length.out = n)</span></span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="linearregression.html#cb63-1"></a>u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, sigma)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="linearregression.html#cb64-1"></a>y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1 <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>u</span></code></pre></div>
<p>Estimate parameter by OLS</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="linearregression.html#cb65-1"></a>olsreg &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span>x )</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="linearregression.html#cb66-1"></a>simulation.df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x,y)</span>
<span id="cb66-2"><a href="linearregression.html#cb66-2"></a>population.df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(b0, b1)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="linearregression.html#cb67-1"></a><span class="kw">plot</span>(simulation.df, </span>
<span id="cb67-2"><a href="linearregression.html#cb67-2"></a>     <span class="dt">xlab =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb67-3"><a href="linearregression.html#cb67-3"></a>     <span class="dt">ylab =</span> <span class="st">&quot;y&quot;</span>,</span>
<span id="cb67-4"><a href="linearregression.html#cb67-4"></a>     <span class="co"># main = &quot;Simulate least squares regression&quot;,</span></span>
<span id="cb67-5"><a href="linearregression.html#cb67-5"></a>     <span class="dt">pch  =</span> <span class="dv">20</span>,</span>
<span id="cb67-6"><a href="linearregression.html#cb67-6"></a>     <span class="dt">cex  =</span> <span class="dv">2</span>,</span>
<span id="cb67-7"><a href="linearregression.html#cb67-7"></a>     <span class="dt">col  =</span> <span class="st">&quot;grey&quot;</span>)</span>
<span id="cb67-8"><a href="linearregression.html#cb67-8"></a><span class="kw">abline</span>(olsreg, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;darkorange&quot;</span>)</span>
<span id="cb67-9"><a href="linearregression.html#cb67-9"></a><span class="kw">abline</span>(b0, b1,  <span class="dt">lwd =</span> <span class="dv">3</span>,  <span class="dt">lty =</span> <span class="dv">2</span>,   <span class="dt">col =</span> <span class="st">&quot;darkblue&quot;</span>)</span>
<span id="cb67-10"><a href="linearregression.html#cb67-10"></a><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, </span>
<span id="cb67-11"><a href="linearregression.html#cb67-11"></a>       <span class="kw">c</span>(<span class="st">&quot;OLS regression function&quot;</span>, </span>
<span id="cb67-12"><a href="linearregression.html#cb67-12"></a>         <span class="st">&quot;Population regression function&quot;</span>), </span>
<span id="cb67-13"><a href="linearregression.html#cb67-13"></a>       <span class="dt">lwd =</span><span class="dv">2</span>, </span>
<span id="cb67-14"><a href="linearregression.html#cb67-14"></a>       <span class="dt">lty =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig5"></span>
<img src="MEM5220_R_files/figure-html/fig5-1.png" alt="Simulated Sample and OLS Regression Line" width="80%" />
<p class="caption">
Figure 1.6: Simulated Sample and OLS Regression Line
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="linearregression.html#cb68-1"></a>lable1 &lt;-<span class="st"> &quot;OLS regression function&quot;</span></span>
<span id="cb68-2"><a href="linearregression.html#cb68-2"></a><span class="kw">ggplot</span>(simulation.df, <span class="kw">aes</span>(<span class="dt">x =</span> x,  <span class="dt">y =</span> y)) <span class="op">+</span></span>
<span id="cb68-3"><a href="linearregression.html#cb68-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb68-4"><a href="linearregression.html#cb68-4"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept=</span>b0,<span class="dt">slope=</span>b1,<span class="dt">colour=</span><span class="st">&quot;Population regression function&quot;</span>), <span class="dt">linetype =</span><span class="st">&quot;dashed&quot;</span>, <span class="dt">show.legend  =</span> <span class="ot">TRUE</span>)<span class="op">+</span></span>
<span id="cb68-5"><a href="linearregression.html#cb68-5"></a><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="kw">aes</span>(<span class="dt">colour =</span><span class="st">&quot;OLS regression function&quot;</span>), <span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>,<span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">show.legend =</span><span class="ot">TRUE</span>)<span class="op">+</span></span>
<span id="cb68-6"><a href="linearregression.html#cb68-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Regression functions&quot;</span> </span>
<span id="cb68-7"><a href="linearregression.html#cb68-7"></a>       <span class="co"># , title = &quot;Simulate least squares regression&quot;</span></span>
<span id="cb68-8"><a href="linearregression.html#cb68-8"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig6"></span>
<img src="MEM5220_R_files/figure-html/fig6-1.png" alt="Simulated Sample and OLS Regression Line (gpplot Style)" width="80%" />
<p class="caption">
Figure 1.7: Simulated Sample and OLS Regression Line (gpplot Style)
</p>
</div>
<p>Since the expected values and variances of our estimators are defined over separate random samples from the same population, it makes sense to repeat our simulation exercise over many simulated samples.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="linearregression.html#cb69-1"></a><span class="co"># Set the random seed</span></span>
<span id="cb69-2"><a href="linearregression.html#cb69-2"></a><span class="kw">set.seed</span>(<span class="dv">1234567</span>)</span>
<span id="cb69-3"><a href="linearregression.html#cb69-3"></a></span>
<span id="cb69-4"><a href="linearregression.html#cb69-4"></a><span class="co"># set sample size and number of simulations</span></span>
<span id="cb69-5"><a href="linearregression.html#cb69-5"></a>n&lt;-<span class="dv">1000</span>; r&lt;-<span class="dv">10000</span></span>
<span id="cb69-6"><a href="linearregression.html#cb69-6"></a></span>
<span id="cb69-7"><a href="linearregression.html#cb69-7"></a><span class="co"># set true parameters: betas and sd of u</span></span>
<span id="cb69-8"><a href="linearregression.html#cb69-8"></a>b0&lt;-<span class="fl">1.0</span>; b1&lt;-<span class="fl">0.5</span>; sigma&lt;-<span class="dv">2</span></span>
<span id="cb69-9"><a href="linearregression.html#cb69-9"></a></span>
<span id="cb69-10"><a href="linearregression.html#cb69-10"></a><span class="co"># initialize b0hat and b1hat to store results later:</span></span>
<span id="cb69-11"><a href="linearregression.html#cb69-11"></a>b0hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)</span>
<span id="cb69-12"><a href="linearregression.html#cb69-12"></a>b1hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)</span>
<span id="cb69-13"><a href="linearregression.html#cb69-13"></a></span>
<span id="cb69-14"><a href="linearregression.html#cb69-14"></a><span class="co"># Draw a sample of x, fixed over replications:</span></span>
<span id="cb69-15"><a href="linearregression.html#cb69-15"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">4</span>,<span class="dv">1</span>)</span>
<span id="cb69-16"><a href="linearregression.html#cb69-16"></a></span>
<span id="cb69-17"><a href="linearregression.html#cb69-17"></a><span class="co"># repeat r times:</span></span>
<span id="cb69-18"><a href="linearregression.html#cb69-18"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>r) {</span>
<span id="cb69-19"><a href="linearregression.html#cb69-19"></a>  <span class="co"># Draw a sample of y:</span></span>
<span id="cb69-20"><a href="linearregression.html#cb69-20"></a>  u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">0</span>,sigma)</span>
<span id="cb69-21"><a href="linearregression.html#cb69-21"></a>  y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>u</span>
<span id="cb69-22"><a href="linearregression.html#cb69-22"></a>  </span>
<span id="cb69-23"><a href="linearregression.html#cb69-23"></a>  <span class="co"># estimate parameters by OLS and store them in the vectors</span></span>
<span id="cb69-24"><a href="linearregression.html#cb69-24"></a>  bhat &lt;-<span class="st"> </span><span class="kw">coefficients</span>( <span class="kw">lm</span>(y<span class="op">~</span>x) )</span>
<span id="cb69-25"><a href="linearregression.html#cb69-25"></a>  b0hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;(Intercept)&quot;</span>]</span>
<span id="cb69-26"><a href="linearregression.html#cb69-26"></a>  b1hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;x&quot;</span>]</span>
<span id="cb69-27"><a href="linearregression.html#cb69-27"></a>}</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="linearregression.html#cb70-1"></a><span class="co"># MC estimate of the expected values:</span></span>
<span id="cb70-2"><a href="linearregression.html#cb70-2"></a><span class="kw">mean</span>(b0hat)</span></code></pre></div>
<pre><code>## [1] 0.9985388</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="linearregression.html#cb72-1"></a><span class="kw">mean</span>(b1hat)</span></code></pre></div>
<pre><code>## [1] 0.5000466</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="linearregression.html#cb74-1"></a><span class="co"># MC estimate of the variances:</span></span>
<span id="cb74-2"><a href="linearregression.html#cb74-2"></a><span class="kw">var</span>(b0hat)</span></code></pre></div>
<pre><code>## [1] 0.0690833</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="linearregression.html#cb76-1"></a><span class="kw">var</span>(b1hat)</span></code></pre></div>
<pre><code>## [1] 0.004069063</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="linearregression.html#cb78-1"></a><span class="co"># Initialize empty plot</span></span>
<span id="cb78-2"><a href="linearregression.html#cb78-2"></a><span class="kw">plot</span>( <span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">8</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">6</span>), <span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y&quot;</span>)</span>
<span id="cb78-3"><a href="linearregression.html#cb78-3"></a><span class="co"># add OLS regression lines</span></span>
<span id="cb78-4"><a href="linearregression.html#cb78-4"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="kw">abline</span>(b0hat[j],b1hat[j],<span class="dt">col=</span><span class="st">&quot;gray&quot;</span>)</span>
<span id="cb78-5"><a href="linearregression.html#cb78-5"></a><span class="co"># add population regression line</span></span>
<span id="cb78-6"><a href="linearregression.html#cb78-6"></a><span class="kw">abline</span>(b0,b1,<span class="dt">lwd=</span><span class="dv">2</span>)</span>
<span id="cb78-7"><a href="linearregression.html#cb78-7"></a><span class="co"># add legend</span></span>
<span id="cb78-8"><a href="linearregression.html#cb78-8"></a><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;Population&quot;</span>,<span class="st">&quot;OLS regressions&quot;</span>),</span>
<span id="cb78-9"><a href="linearregression.html#cb78-9"></a>       <span class="dt">lwd=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>),<span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;gray&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig7"></span>
<img src="MEM5220_R_files/figure-html/fig7-1.png" alt="Population and Simulated OLS Regression Lines" width="80%" />
<p class="caption">
Figure 1.8: Population and Simulated OLS Regression Lines
</p>
</div>
<p>Even though the loop solution is transparent, let us take a look at a different, more <em>modern</em> approach.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="linearregression.html#cb79-1"></a><span class="co"># define a function the returns the alpha -- its point estimate, standard error, etc. -- from the OLS</span></span>
<span id="cb79-2"><a href="linearregression.html#cb79-2"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">4</span>,<span class="dv">1</span>) <span class="co"># </span><span class="al">NOTE</span><span class="co"> 1: Although a normal distribution is usually defined by its mean and variance, &#39;rnorm()&#39; requires the standard deviation as input for the second moment.</span></span>
<span id="cb79-3"><a href="linearregression.html#cb79-3"></a><span class="co"># </span><span class="al">NOTE</span><span class="co"> 2: We use the same values for x in all samples since we draw them outside of the loop. </span></span>
<span id="cb79-4"><a href="linearregression.html#cb79-4"></a></span>
<span id="cb79-5"><a href="linearregression.html#cb79-5"></a>iteration &lt;-<span class="st"> </span><span class="cf">function</span>() {</span>
<span id="cb79-6"><a href="linearregression.html#cb79-6"></a>  u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">0</span>,sigma)</span>
<span id="cb79-7"><a href="linearregression.html#cb79-7"></a>  y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>u</span>
<span id="cb79-8"><a href="linearregression.html#cb79-8"></a>  </span>
<span id="cb79-9"><a href="linearregression.html#cb79-9"></a>  <span class="kw">lm</span>(y<span class="op">~</span>x) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb79-10"><a href="linearregression.html#cb79-10"></a><span class="st">    </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="co"># %&gt;% </span></span>
<span id="cb79-11"><a href="linearregression.html#cb79-11"></a>  <span class="co"># dplyr::filter(term == &#39;x&#39;) # One could only extract the slope</span></span>
<span id="cb79-12"><a href="linearregression.html#cb79-12"></a>}</span>
<span id="cb79-13"><a href="linearregression.html#cb79-13"></a></span>
<span id="cb79-14"><a href="linearregression.html#cb79-14"></a><span class="co"># 1000 iterations of the above simulation</span></span>
<span id="cb79-15"><a href="linearregression.html#cb79-15"></a>MC_coef&lt;-<span class="st"> </span><span class="kw">map_df</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>, <span class="op">~</span><span class="kw">iteration</span>()) </span>
<span id="cb79-16"><a href="linearregression.html#cb79-16"></a><span class="kw">str</span>(MC_coef)</span></code></pre></div>
<pre><code>## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:    2000 obs. of  5 variables:
##  $ term     : chr  &quot;(Intercept)&quot; &quot;x&quot; &quot;(Intercept)&quot; &quot;x&quot; ...
##  $ estimate : num  1.577 0.372 1.44 0.387 1.355 ...
##  $ std.error: num  0.2672 0.0639 0.2623 0.0628 0.2626 ...
##  $ statistic: num  5.9 5.82 5.49 6.17 5.16 ...
##  $ p.value  : num  4.94e-09 7.91e-09 5.13e-08 9.92e-10 2.99e-07 ...</code></pre>
<p>Instead of plotting simulated and true parameter regression lines we can take a look at the kernel density of the simulated parameter estimates</p>
<p>Figure <a href="linearregression.html#fig:fig8">1.9</a> shows the simulated distribution of <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> the theoretical one.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="linearregression.html#cb81-1"></a><span class="co"># plot the results</span></span>
<span id="cb81-2"><a href="linearregression.html#cb81-2"></a><span class="kw">str</span>(MC_coef)</span></code></pre></div>
<pre><code>## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:    2000 obs. of  5 variables:
##  $ term     : chr  &quot;(Intercept)&quot; &quot;x&quot; &quot;(Intercept)&quot; &quot;x&quot; ...
##  $ estimate : num  1.577 0.372 1.44 0.387 1.355 ...
##  $ std.error: num  0.2672 0.0639 0.2623 0.0628 0.2626 ...
##  $ statistic: num  5.9 5.82 5.49 6.17 5.16 ...
##  $ p.value  : num  4.94e-09 7.91e-09 5.13e-08 9.92e-10 2.99e-07 ...</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="linearregression.html#cb83-1"></a>MC_coef&lt;-<span class="st"> </span>MC_coef <span class="op">%&gt;%</span></span>
<span id="cb83-2"><a href="linearregression.html#cb83-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">OLScoeff =</span>  <span class="kw">ifelse</span>(term <span class="op">==</span><span class="st"> &quot;x&quot;</span>, <span class="st">&quot;b1hat&quot;</span>, <span class="st">&quot;b0hat&quot;</span>)) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># rename the x to b1hat and (Intercept) to b0hat and create a new column </span></span>
<span id="cb83-3"><a href="linearregression.html#cb83-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Simulated =</span> <span class="kw">ifelse</span>(term <span class="op">==</span><span class="st"> &quot;x&quot;</span>, <span class="st">&quot;b1&quot;</span>, <span class="st">&quot;b0&quot;</span>)) <span class="co">#  %&gt;% </span></span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="linearregression.html#cb84-1"></a><span class="kw">ggplot</span>(<span class="dt">data=</span> MC_coef, <span class="kw">aes</span>(estimate)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb84-2"><a href="linearregression.html#cb84-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb84-3"><a href="linearregression.html#cb84-3"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">data =</span> dplyr<span class="op">::</span><span class="kw">filter</span>(MC_coef, OLScoeff <span class="op">==</span><span class="st"> &quot;b0hat&quot;</span>), <span class="kw">aes</span>(<span class="dt">xintercept=</span>b0), <span class="dt">colour=</span><span class="st">&quot;pink&quot;</span>)  <span class="op">+</span><span class="st">  </span></span>
<span id="cb84-4"><a href="linearregression.html#cb84-4"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">data =</span> dplyr<span class="op">::</span><span class="kw">filter</span>(MC_coef, OLScoeff <span class="op">==</span><span class="st"> &quot;b1hat&quot;</span>), <span class="kw">aes</span>(<span class="dt">xintercept=</span>b1), <span class="dt">colour=</span><span class="st">&quot;darkgreen&quot;</span>)  <span class="op">+</span><span class="st"> </span></span>
<span id="cb84-5"><a href="linearregression.html#cb84-5"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data=</span>MC_coef[<span class="dv">3</span>,], <span class="dt">mapping=</span><span class="kw">aes</span>(<span class="dt">x=</span>estimate, <span class="dt">y=</span><span class="dv">8</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;True parameter: &quot;</span>, MC_coef[<span class="dv">3</span>,<span class="dv">7</span>])), <span class="dt">colour =</span> <span class="st">&quot;pink&quot;</span>) <span class="op">+</span></span>
<span id="cb84-6"><a href="linearregression.html#cb84-6"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data=</span>MC_coef[<span class="dv">4</span>,], <span class="dt">mapping=</span><span class="kw">aes</span>(<span class="dt">x=</span>estimate, <span class="dt">y=</span><span class="dv">8</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;True parameter: &quot;</span>, MC_coef[<span class="dv">4</span>,<span class="dv">7</span>])), <span class="dt">colour =</span> <span class="st">&quot;darkgreen&quot;</span>) <span class="op">+</span></span>
<span id="cb84-7"><a href="linearregression.html#cb84-7"></a><span class="st">  </span><span class="kw">facet_wrap</span>( <span class="op">~</span><span class="st"> </span>OLScoeff, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)   <span class="op">+</span></span>
<span id="cb84-8"><a href="linearregression.html#cb84-8"></a><span class="st">  </span><span class="kw">labs</span>(</span>
<span id="cb84-9"><a href="linearregression.html#cb84-9"></a>    <span class="dt">title =</span> <span class="st">&quot;Histogram Monte Carlo Simulations and True population parameters&quot;</span>) <span class="op">+</span></span>
<span id="cb84-10"><a href="linearregression.html#cb84-10"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig8"></span>
<img src="MEM5220_R_files/figure-html/fig8-1.png" alt="Histogram b0 and b1 and true parameter" width="80%" />
<p class="caption">
Figure 1.9: Histogram b0 and b1 and true parameter
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="linearregression.html#cb86-1"></a>b1_sim &lt;-<span class="st"> </span>MC_coef <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb86-2"><a href="linearregression.html#cb86-2"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(Simulated <span class="op">==</span><span class="st"> &quot;b1&quot;</span>)</span>
<span id="cb86-3"><a href="linearregression.html#cb86-3"></a></span>
<span id="cb86-4"><a href="linearregression.html#cb86-4"></a><span class="kw">mean</span>(b1_sim<span class="op">$</span>estimate)</span></code></pre></div>
<pre><code>## [1] 0.5011414</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="linearregression.html#cb88-1"></a><span class="kw">var</span>(b1_sim<span class="op">$</span>estimate) <span class="op">==</span><span class="st"> </span>(<span class="kw">sd</span>(b1_sim<span class="op">$</span>estimate))<span class="op">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="linearregression.html#cb90-1"></a><span class="kw">all.equal</span>(<span class="kw">var</span>(b1_sim<span class="op">$</span>estimate) , (<span class="kw">sd</span>(b1_sim<span class="op">$</span>estimate))<span class="op">^</span><span class="dv">2</span>) <span class="co"># Floating point arithmetic!</span></span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="linearregression.html#cb92-1"></a><span class="kw">ggplot</span>(<span class="dt">data=</span> b1_sim, <span class="kw">aes</span>(estimate)) <span class="op">+</span><span class="st">  </span></span>
<span id="cb92-2"><a href="linearregression.html#cb92-2"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> Simulated), <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span><span class="st"> </span><span class="co"># computes and draws the kernel density, which is the smoothed version of the histogram</span></span>
<span id="cb92-3"><a href="linearregression.html#cb92-3"></a><span class="st">  </span><span class="co"># stat_function(fun = dnorm, args = list(mean = mean(b1_sim$estimate), sd = sd(b1_sim$estimate)), aes(colour = &quot;true&quot;)) +</span></span>
<span id="cb92-4"><a href="linearregression.html#cb92-4"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="fl">0.5</span>, <span class="dt">sd =</span> <span class="kw">sd</span>(b1_sim<span class="op">$</span>estimate)), <span class="kw">aes</span>(<span class="dt">colour =</span> <span class="st">&quot;Population&quot;</span>)) <span class="op">+</span></span>
<span id="cb92-5"><a href="linearregression.html#cb92-5"></a><span class="st">  </span><span class="co"># labs(</span></span>
<span id="cb92-6"><a href="linearregression.html#cb92-6"></a><span class="st">  </span><span class="co">#  title = &quot;Kernel Density Monte Carlo Simulations vs. True population parameters&quot;</span></span>
<span id="cb92-7"><a href="linearregression.html#cb92-7"></a><span class="st">  </span><span class="co"># ) +</span></span>
<span id="cb92-8"><a href="linearregression.html#cb92-8"></a><span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">name=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig9"></span>
<img src="MEM5220_R_files/figure-html/fig9-1.png" alt="Kernel Density Monte Carlo Simulations vs. True population parameters of b1" width="80%" />
<p class="caption">
Figure 1.10: Kernel Density Monte Carlo Simulations vs. True population parameters of b1
</p>
</div>
</div>
<div id="violation-of-slr.4" class="section level5">
<h5><span class="header-section-number">1.1.2.0.2</span> Violation of SLR.4</h5>
<p>To implement a violation of <strong>SLR.4</strong> (zero conditional mean) consider a case where in the population <span class="math inline">\(u\)</span> is not mean independent of <span class="math inline">\(x\)</span>, for example</p>
<p><span class="math display">\[
\mathbf{E}(u|x) = \frac{x-4}{5}
\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="linearregression.html#cb93-1"></a><span class="co"># Set the random seed</span></span>
<span id="cb93-2"><a href="linearregression.html#cb93-2"></a><span class="kw">set.seed</span>(<span class="dv">1234567</span>)</span>
<span id="cb93-3"><a href="linearregression.html#cb93-3"></a></span>
<span id="cb93-4"><a href="linearregression.html#cb93-4"></a><span class="co"># set sample size and number of simulations</span></span>
<span id="cb93-5"><a href="linearregression.html#cb93-5"></a>n&lt;-<span class="dv">1000</span>; r&lt;-<span class="dv">10000</span></span>
<span id="cb93-6"><a href="linearregression.html#cb93-6"></a></span>
<span id="cb93-7"><a href="linearregression.html#cb93-7"></a><span class="co"># set true parameters: betas and sd of u</span></span>
<span id="cb93-8"><a href="linearregression.html#cb93-8"></a>b0&lt;-<span class="dv">1</span>; b1&lt;-<span class="fl">0.5</span>; su&lt;-<span class="dv">2</span></span>
<span id="cb93-9"><a href="linearregression.html#cb93-9"></a></span>
<span id="cb93-10"><a href="linearregression.html#cb93-10"></a><span class="co"># initialize b0hat and b1hat to store results later:</span></span>
<span id="cb93-11"><a href="linearregression.html#cb93-11"></a>b0hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)</span>
<span id="cb93-12"><a href="linearregression.html#cb93-12"></a>b1hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)</span>
<span id="cb93-13"><a href="linearregression.html#cb93-13"></a></span>
<span id="cb93-14"><a href="linearregression.html#cb93-14"></a><span class="co"># Draw a sample of x, fixed over replications:</span></span>
<span id="cb93-15"><a href="linearregression.html#cb93-15"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">4</span>,<span class="dv">1</span>)</span>
<span id="cb93-16"><a href="linearregression.html#cb93-16"></a></span>
<span id="cb93-17"><a href="linearregression.html#cb93-17"></a><span class="co"># repeat r times:</span></span>
<span id="cb93-18"><a href="linearregression.html#cb93-18"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>r) {</span>
<span id="cb93-19"><a href="linearregression.html#cb93-19"></a>  <span class="co"># Draw a sample of y:</span></span>
<span id="cb93-20"><a href="linearregression.html#cb93-20"></a>  u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, (x<span class="dv">-4</span>)<span class="op">/</span><span class="dv">5</span>, su) <span class="co"># this is where manipulate the assumption of zero conditional mean</span></span>
<span id="cb93-21"><a href="linearregression.html#cb93-21"></a>  y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>u</span>
<span id="cb93-22"><a href="linearregression.html#cb93-22"></a>  </span>
<span id="cb93-23"><a href="linearregression.html#cb93-23"></a>  <span class="co"># estimate parameters by OLS and store them in the vectors</span></span>
<span id="cb93-24"><a href="linearregression.html#cb93-24"></a>  bhat &lt;-<span class="st"> </span><span class="kw">coefficients</span>( <span class="kw">lm</span>(y<span class="op">~</span>x) )</span>
<span id="cb93-25"><a href="linearregression.html#cb93-25"></a>  b0hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;(Intercept)&quot;</span>]</span>
<span id="cb93-26"><a href="linearregression.html#cb93-26"></a>  b1hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;x&quot;</span>]</span>
<span id="cb93-27"><a href="linearregression.html#cb93-27"></a>}</span></code></pre></div>
<p>OLS coefficients</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="linearregression.html#cb94-1"></a><span class="co"># MC estimate of the expected values:</span></span>
<span id="cb94-2"><a href="linearregression.html#cb94-2"></a><span class="kw">mean</span>(b0hat)</span></code></pre></div>
<pre><code>## [1] 0.1985388</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="linearregression.html#cb96-1"></a><span class="kw">mean</span>(b1hat)</span></code></pre></div>
<pre><code>## [1] 0.7000466</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="linearregression.html#cb98-1"></a><span class="co"># MC estimate of the variances:</span></span>
<span id="cb98-2"><a href="linearregression.html#cb98-2"></a><span class="kw">var</span>(b0hat)</span></code></pre></div>
<pre><code>## [1] 0.0690833</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="linearregression.html#cb100-1"></a><span class="kw">var</span>(b1hat)</span></code></pre></div>
<pre><code>## [1] 0.004069063</code></pre>
<p>The average estimates are far from the population parameters <span class="math inline">\(\beta_0=1\)</span> and <span class="math inline">\(\beta_1 = 0.5\)</span>!</p>
</div>
<div id="violation-of-slr.5" class="section level5">
<h5><span class="header-section-number">1.1.2.0.3</span> Violation of SLR.5</h5>
<p>Homoskedasticity is not required for unbiasedness but for it is a requirement for the theorem of sampling variance. Consider the following heteroskedastic behavior of <span class="math inline">\(u\)</span> given <span class="math inline">\(x\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="linearregression.html#cb102-1"></a><span class="co"># Set the random seed</span></span>
<span id="cb102-2"><a href="linearregression.html#cb102-2"></a><span class="kw">set.seed</span>(<span class="dv">1234567</span>)</span>
<span id="cb102-3"><a href="linearregression.html#cb102-3"></a></span>
<span id="cb102-4"><a href="linearregression.html#cb102-4"></a><span class="co"># set sample size and number of simulations</span></span>
<span id="cb102-5"><a href="linearregression.html#cb102-5"></a>n&lt;-<span class="dv">1000</span>; r&lt;-<span class="dv">10000</span></span>
<span id="cb102-6"><a href="linearregression.html#cb102-6"></a></span>
<span id="cb102-7"><a href="linearregression.html#cb102-7"></a><span class="co"># set true parameters: betas and sd of u</span></span>
<span id="cb102-8"><a href="linearregression.html#cb102-8"></a>b0&lt;-<span class="dv">1</span>; b1&lt;-<span class="fl">0.5</span>; su&lt;-<span class="dv">2</span></span>
<span id="cb102-9"><a href="linearregression.html#cb102-9"></a></span>
<span id="cb102-10"><a href="linearregression.html#cb102-10"></a><span class="co"># initialize b0hat and b1hat to store results later:</span></span>
<span id="cb102-11"><a href="linearregression.html#cb102-11"></a>b0hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)</span>
<span id="cb102-12"><a href="linearregression.html#cb102-12"></a>b1hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)</span>
<span id="cb102-13"><a href="linearregression.html#cb102-13"></a></span>
<span id="cb102-14"><a href="linearregression.html#cb102-14"></a><span class="co"># Draw a sample of x, fixed over replications:</span></span>
<span id="cb102-15"><a href="linearregression.html#cb102-15"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">4</span>,<span class="dv">1</span>)</span>
<span id="cb102-16"><a href="linearregression.html#cb102-16"></a></span>
<span id="cb102-17"><a href="linearregression.html#cb102-17"></a><span class="co"># repeat r times:</span></span>
<span id="cb102-18"><a href="linearregression.html#cb102-18"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>r) {</span>
<span id="cb102-19"><a href="linearregression.html#cb102-19"></a>  <span class="co"># Draw a sample of y:</span></span>
<span id="cb102-20"><a href="linearregression.html#cb102-20"></a>  varu &lt;-<span class="st"> </span><span class="dv">4</span><span class="op">/</span><span class="kw">exp</span>(<span class="fl">4.5</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(x)</span>
<span id="cb102-21"><a href="linearregression.html#cb102-21"></a>  u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, <span class="kw">sqrt</span>(varu) )</span>
<span id="cb102-22"><a href="linearregression.html#cb102-22"></a>  y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>u</span>
<span id="cb102-23"><a href="linearregression.html#cb102-23"></a>  </span>
<span id="cb102-24"><a href="linearregression.html#cb102-24"></a>  <span class="co"># estimate parameters by OLS and store them in the vectors</span></span>
<span id="cb102-25"><a href="linearregression.html#cb102-25"></a>  lm_heterosced &lt;-<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span>x)</span>
<span id="cb102-26"><a href="linearregression.html#cb102-26"></a>  </span>
<span id="cb102-27"><a href="linearregression.html#cb102-27"></a>  bhat &lt;-<span class="st"> </span><span class="kw">coefficients</span>( <span class="kw">lm</span>(y<span class="op">~</span>x) )</span>
<span id="cb102-28"><a href="linearregression.html#cb102-28"></a>  b0hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;(Intercept)&quot;</span>]</span>
<span id="cb102-29"><a href="linearregression.html#cb102-29"></a>  b1hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;x&quot;</span>]</span>
<span id="cb102-30"><a href="linearregression.html#cb102-30"></a>}</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="linearregression.html#cb103-1"></a><span class="kw">summary</span>(lm_heterosced) <span class="co"># just the last sample of the MC-simulation</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -23.6742  -0.9033   0.0052   1.0012   9.3411 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.24088    0.27158   4.569 5.51e-06 ***
## x            0.44561    0.06593   6.759 2.37e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.075 on 998 degrees of freedom
## Multiple R-squared:  0.04377,    Adjusted R-squared:  0.04281 
## F-statistic: 45.68 on 1 and 998 DF,  p-value: 2.367e-11</code></pre>
<p>Plot the residual against the regressor suspected of creating heteroskedasticity, or more generally, the fitted values of the regression.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="linearregression.html#cb105-1"></a>res &lt;-<span class="st"> </span><span class="kw">residuals</span>(lm_heterosced)</span>
<span id="cb105-2"><a href="linearregression.html#cb105-2"></a>yhat &lt;-<span class="st"> </span><span class="kw">fitted</span>(lm_heterosced)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="linearregression.html#cb106-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb106-2"><a href="linearregression.html#cb106-2"></a><span class="kw">plot</span>(x, res, <span class="dt">ylab =</span> <span class="st">&quot;residuals&quot;</span>)</span>
<span id="cb106-3"><a href="linearregression.html#cb106-3"></a><span class="kw">plot</span>(yhat, res, <span class="dt">xlab =</span> <span class="st">&quot;fitted values&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;residuals&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig10"></span>
<img src="MEM5220_R_files/figure-html/fig10-1.png" alt="Heteroskedasticity in the simulated data" width="80%" />
<p class="caption">
Figure 1.11: Heteroskedasticity in the simulated data
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="linearregression.html#cb107-1"></a><span class="co"># MC estimate of the expected values:</span></span>
<span id="cb107-2"><a href="linearregression.html#cb107-2"></a><span class="kw">mean</span>(b0hat)</span></code></pre></div>
<pre><code>## [1] 1.0019</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="linearregression.html#cb109-1"></a><span class="kw">mean</span>(b1hat)</span></code></pre></div>
<pre><code>## [1] 0.4992376</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="linearregression.html#cb111-1"></a><span class="co"># MC estimate of the variances:</span></span>
<span id="cb111-2"><a href="linearregression.html#cb111-2"></a><span class="kw">var</span>(b0hat)</span></code></pre></div>
<pre><code>## [1] 0.08967037</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="linearregression.html#cb113-1"></a><span class="kw">var</span>(b1hat)</span></code></pre></div>
<pre><code>## [1] 0.007264373</code></pre>
<p>Unbiasedness is provided but sampling variance is incorrect (compared to the results provided above).</p>
<hr />
</div>
</div>
<div id="nonlinearities" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Nonlinearities</h3>
<p>Sometimes the scatter plot diagram or some theoretical considerations suggest a non-linear relationship. The most popular non-linear transformation involve logarithms of the dependent or independent variables and polynomial functions.</p>
<p>We will use a new dataset, <em>wage1</em>, for this section. A detailed exploratory analysis of the dataset is left to the reader.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="linearregression.html#cb115-1"></a><span class="kw">data</span>(<span class="st">&quot;wage1&quot;</span>)</span></code></pre></div>
<div id="predictor-variable-transformation" class="section level4">
<h4><span class="header-section-number">1.1.3.1</span> Predictor variable transformation</h4>
<p>A common variance stabilizing transformation (VST) is necessary when we see increasing variance in a fitted versus residuals plot.</p>
<p>To use the <em>log</em> of an independent variable is to make its distribution closer to the normal distribution.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="linearregression.html#cb116-1"></a><span class="co"># wage1$logwage &lt;- log(wage1$wage) # one could also create a new variable </span></span>
<span id="cb116-2"><a href="linearregression.html#cb116-2"></a></span>
<span id="cb116-3"><a href="linearregression.html#cb116-3"></a>p1_wagehisto &lt;-<span class="st"> </span><span class="kw">ggplot</span>(wage1)  <span class="op">+</span></span>
<span id="cb116-4"><a href="linearregression.html#cb116-4"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> wage), <span class="dt">fill =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.6</span>)</span>
<span id="cb116-5"><a href="linearregression.html#cb116-5"></a></span>
<span id="cb116-6"><a href="linearregression.html#cb116-6"></a>p2_wagehisto &lt;-<span class="st"> </span><span class="kw">ggplot</span>(wage1)  <span class="op">+</span></span>
<span id="cb116-7"><a href="linearregression.html#cb116-7"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> wage),  <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.6</span>) <span class="op">+</span></span>
<span id="cb116-8"><a href="linearregression.html#cb116-8"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">trans=</span><span class="st">&#39;log2&#39;</span>, <span class="st">&quot;Log Wage&quot;</span>)  <span class="co"># instead of creating a new variable with simply define that the x-scale undergoes a logarithmic transformation</span></span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="linearregression.html#cb117-1"></a><span class="kw">ggarrange</span>(p1_wagehisto, p2_wagehisto,  </span>
<span id="cb117-2"><a href="linearregression.html#cb117-2"></a>          <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>),</span>
<span id="cb117-3"><a href="linearregression.html#cb117-3"></a>          <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">nrow =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig11"></span>
<img src="MEM5220_R_files/figure-html/fig11-1.png" alt="Histogram of wage and log(wage)" width="80%" />
<p class="caption">
Figure 1.12: Histogram of wage and log(wage)
</p>
</div>
<p>A model with a log transformed response:</p>
<p><span class="math display">\[\begin{equation}
log(Y_{i}) = \beta_{0} + \beta_{1} \times x_{i} + \epsilon_{i}
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="linearregression.html#cb119-1"></a>lm_wage &lt;-<span class="st"> </span><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span>educ, <span class="dt">data =</span> wage1)</span>
<span id="cb119-2"><a href="linearregression.html#cb119-2"></a>lm_wage1 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(wage) <span class="op">~</span><span class="st"> </span>educ, <span class="dt">data =</span>  wage1)</span>
<span id="cb119-3"><a href="linearregression.html#cb119-3"></a><span class="kw">summary</span>(lm_wage)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wage ~ educ, data = wage1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3396 -2.1501 -0.9674  1.1921 16.6085 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.90485    0.68497  -1.321    0.187    
## educ         0.54136    0.05325  10.167   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.378 on 524 degrees of freedom
## Multiple R-squared:  0.1648, Adjusted R-squared:  0.1632 
## F-statistic: 103.4 on 1 and 524 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="linearregression.html#cb121-1"></a><span class="kw">summary</span>(lm_wage1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(wage) ~ educ, data = wage1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.21158 -0.36393 -0.07263  0.29712  1.52339 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.583773   0.097336   5.998 3.74e-09 ***
## educ        0.082744   0.007567  10.935  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4801 on 524 degrees of freedom
## Multiple R-squared:  0.1858, Adjusted R-squared:  0.1843 
## F-statistic: 119.6 on 1 and 524 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Plotting Diagnostics for Linear Models</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="linearregression.html#cb123-1"></a><span class="kw">plot</span>(lm_wage)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig121"></span>
<img src="MEM5220_R_files/figure-html/fig12-1.png" alt="Regression diagnostics plot base R - Linear Relationship" width="80%" />
<p class="caption">
Figure 1.13: Regression diagnostics plot base R - Linear Relationship
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig122"></span>
<img src="MEM5220_R_files/figure-html/fig12-2.png" alt="Regression diagnostics plot base R - Linear Relationship" width="80%" />
<p class="caption">
Figure 1.14: Regression diagnostics plot base R - Linear Relationship
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig123"></span>
<img src="MEM5220_R_files/figure-html/fig12-3.png" alt="Regression diagnostics plot base R - Linear Relationship" width="80%" />
<p class="caption">
Figure 1.15: Regression diagnostics plot base R - Linear Relationship
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig124"></span>
<img src="MEM5220_R_files/figure-html/fig12-4.png" alt="Regression diagnostics plot base R - Linear Relationship" width="80%" />
<p class="caption">
Figure 1.16: Regression diagnostics plot base R - Linear Relationship
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="linearregression.html#cb124-1"></a><span class="kw">autoplot</span>(lm_wage, <span class="dt">which =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">colour =</span> <span class="st">&#39;dodgerblue3&#39;</span>,</span>
<span id="cb124-2"><a href="linearregression.html#cb124-2"></a>         <span class="dt">smooth.colour =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">smooth.linetype =</span> <span class="st">&#39;dashed&#39;</span>,</span>
<span id="cb124-3"><a href="linearregression.html#cb124-3"></a>         <span class="dt">ad.colour =</span> <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb124-4"><a href="linearregression.html#cb124-4"></a>         <span class="dt">label =</span> <span class="ot">FALSE</span>,</span>
<span id="cb124-5"><a href="linearregression.html#cb124-5"></a>         <span class="dt">label.size =</span> <span class="dv">3</span>, <span class="dt">label.n =</span> <span class="dv">5</span>, <span class="dt">label.colour =</span> <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb124-6"><a href="linearregression.html#cb124-6"></a>         <span class="dt">ncol =</span> <span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb124-7"><a href="linearregression.html#cb124-7"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig13"></span>
<img src="MEM5220_R_files/figure-html/fig13-1.png" alt="Regression diagnostics autoplot(ggplot) - Linear Relationship" width="80%" />
<p class="caption">
Figure 1.17: Regression diagnostics autoplot(ggplot) - Linear Relationship
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="linearregression.html#cb125-1"></a><span class="kw">autoplot</span>(lm_wage1, <span class="dt">which =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">colour =</span> <span class="st">&#39;dodgerblue3&#39;</span>,</span>
<span id="cb125-2"><a href="linearregression.html#cb125-2"></a>         <span class="dt">smooth.colour =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">smooth.linetype =</span> <span class="st">&#39;dashed&#39;</span>,</span>
<span id="cb125-3"><a href="linearregression.html#cb125-3"></a>         <span class="dt">ad.colour =</span> <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb125-4"><a href="linearregression.html#cb125-4"></a>         <span class="dt">label =</span> <span class="ot">FALSE</span>,</span>
<span id="cb125-5"><a href="linearregression.html#cb125-5"></a>         <span class="dt">label.size =</span> <span class="dv">3</span>, <span class="dt">label.n =</span> <span class="dv">5</span>, <span class="dt">label.colour =</span> <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb125-6"><a href="linearregression.html#cb125-6"></a>         <span class="dt">ncol =</span> <span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb125-7"><a href="linearregression.html#cb125-7"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig14"></span>
<img src="MEM5220_R_files/figure-html/fig14-1.png" alt="Regression diagnostics - Non-Linear Relationship" width="80%" />
<p class="caption">
Figure 1.18: Regression diagnostics - Non-Linear Relationship
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="linearregression.html#cb126-1"></a>p1_nonlinearities &lt;-<span class="st"> </span><span class="kw">ggplot</span>(wage1, <span class="kw">aes</span>(<span class="dt">x =</span> educ, <span class="dt">y =</span> wage )) <span class="op">+</span></span>
<span id="cb126-2"><a href="linearregression.html#cb126-2"></a><span class="st">  </span><span class="kw">geom_point</span>()   <span class="op">+</span><span class="st"> </span></span>
<span id="cb126-3"><a href="linearregression.html#cb126-3"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">trans=</span><span class="st">&#39;log2&#39;</span>, <span class="st">&quot;Log Wage&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb126-4"><a href="linearregression.html#cb126-4"></a><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="kw">aes</span>(<span class="dt">fill=</span><span class="st">&quot;Linear Model&quot;</span>),<span class="dt">size=</span><span class="dv">1</span>,<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span> ,<span class="dt">span =</span><span class="fl">0.3</span>, <span class="dt">se=</span>F) <span class="op">+</span><span class="st"> </span></span>
<span id="cb126-5"><a href="linearregression.html#cb126-5"></a><span class="st">  </span><span class="kw">guides</span>(<span class="dt">fill =</span> <span class="kw">guide_legend</span>(<span class="st">&quot;Model Type&quot;</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb126-6"><a href="linearregression.html#cb126-6"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span>
<span id="cb126-7"><a href="linearregression.html#cb126-7"></a>p1_nonlinearities</span></code></pre></div>
<p><img src="MEM5220_R_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<p>Note that if we re-scale the model from a log scale back to the original scale of the data, we now have</p>
<p><span class="math display">\[\begin{equation}
Y_{i} = exp(\beta_{0} + \beta_{1} \times x_{i})  \times exp(\epsilon_{i})
\end{equation}\]</span></p>
<p>which has errors entering in a multiplicative fashion.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="linearregression.html#cb127-1"></a>log.model.df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> wage1<span class="op">$</span>educ,</span>
<span id="cb127-2"><a href="linearregression.html#cb127-2"></a>                           <span class="dt">y =</span> <span class="kw">exp</span>(<span class="kw">fitted</span>(lm_wage1))) <span class="co"># This is essentially exp(b0_wage1 + b1_wage1 * wage1$educ) </span></span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="linearregression.html#cb128-1"></a>p2_nonlinearities &lt;-<span class="st"> </span><span class="kw">ggplot</span>(wage1, <span class="kw">aes</span>(<span class="dt">x =</span> educ, <span class="dt">y =</span> wage))  <span class="op">+</span></span>
<span id="cb128-2"><a href="linearregression.html#cb128-2"></a><span class="st">  </span><span class="kw">geom_point</span>()   <span class="op">+</span></span>
<span id="cb128-3"><a href="linearregression.html#cb128-3"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> log.model.df, <span class="kw">aes</span>(x, y, <span class="dt">color =</span> <span class="st">&quot;Log Model&quot;</span>), <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="dv">2</span>)  <span class="op">+</span></span>
<span id="cb128-4"><a href="linearregression.html#cb128-4"></a><span class="st">  </span><span class="kw">guides</span>(<span class="dt">color =</span> <span class="kw">guide_legend</span>(<span class="st">&quot;Model Type&quot;</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb128-5"><a href="linearregression.html#cb128-5"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="linearregression.html#cb129-1"></a><span class="kw">ggarrange</span>(p1_nonlinearities, p2_nonlinearities,  </span>
<span id="cb129-2"><a href="linearregression.html#cb129-2"></a>          <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>),</span>
<span id="cb129-3"><a href="linearregression.html#cb129-3"></a>          <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">nrow =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig15"></span>
<img src="MEM5220_R_files/figure-html/fig15-1.png" alt="Wages by Education - Different transformations" width="80%" />
<p class="caption">
Figure 1.19: Wages by Education - Different transformations
</p>
</div>
<p>A: Plotting the data on the transformed log scale and adding the fitted line, the relationship again appears linear, and the variation about the fitted line looks more constant.</p>
<p>B: By plotting the data on the original scale, and adding the fitted regression, we see an exponential relationship. However, this is still a <em>linear</em> model, since the new transformed response, <span class="math inline">\(log(Y_{i}\)</span>, is still a <em>linear</em> combination of the predictors. In other words, only <span class="math inline">\(\beta\)</span> needs to be linear, not the <span class="math inline">\(x\)</span> values.</p>
<p><strong>Quadratic Model</strong></p>
<p><span class="math display">\[\begin{equation}
Y_{i} = \beta_{0} + \beta_{1} \times x_{i}  \beta_{2} \times x^2_{i} + \epsilon_{i}
\end{equation}\]</span></p>
<p>New dataset from Wooldrige: Collected from the real estate pages of the Boston Globe during 1990. These are homes that sold in the Boston, MA area.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="linearregression.html#cb130-1"></a><span class="kw">data</span>(<span class="st">&quot;hprice1&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;wooldridge&quot;</span>)</span></code></pre></div>
<p>In R, independent variables involving mathematical operators can be included in regression equation with the function <code>I()</code></p>
<p>We estimate the following regression:</p>
<p><span class="math display">\[\begin{equation}
hprice ~ \beta_{0} +   \beta_{1} sqrft + u
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="linearregression.html#cb131-1"></a>lm_hprice &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>sqrft, <span class="dt">data  =</span> hprice1)</span></code></pre></div>
<p>and a regression model that includes a squared term</p>
<p><span class="math display">\[\begin{equation}
hprice ~ \beta_{0} +   \beta_{1} sqrft + \beta_{2} sqrft^2 + u  
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="linearregression.html#cb132-1"></a>lm_hprice1 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>sqrft <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(sqrft<span class="op">^</span><span class="dv">2</span>), <span class="dt">data  =</span> hprice1)</span></code></pre></div>
<p>Alternatively use the <code>poly()</code> function. Be careful of the additional argument <code>raw</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="linearregression.html#cb133-1"></a>lm_hprice2 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(sqrft, <span class="dt">degree =</span> <span class="dv">2</span>),  <span class="dt">data  =</span> hprice1) </span>
<span id="cb133-2"><a href="linearregression.html#cb133-2"></a>lm_hprice3 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(sqrft, <span class="dt">degree =</span> <span class="dv">2</span>, <span class="dt">raw =</span> <span class="ot">TRUE</span>),  <span class="dt">data  =</span> hprice1) <span class="co"># if true, use raw and not orthogonal polynomials.</span></span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="linearregression.html#cb134-1"></a><span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice1))</span></code></pre></div>
<pre><code>## [1]  1.849453e+02 -1.710855e-02  3.262809e-05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="linearregression.html#cb136-1"></a><span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice2))</span></code></pre></div>
<pre><code>## [1] 293.5460 754.8517 135.6051</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="linearregression.html#cb138-1"></a><span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice3))</span></code></pre></div>
<pre><code>## [1]  1.849453e+02 -1.710855e-02  3.262809e-05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="linearregression.html#cb140-1"></a><span class="kw">all.equal</span>(<span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice1)), <span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice2)))</span></code></pre></div>
<pre><code>## [1] &quot;Mean relative difference: 5.401501&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="linearregression.html#cb142-1"></a><span class="kw">all.equal</span>(<span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice1)), <span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice3)))</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="linearregression.html#cb144-1"></a><span class="kw">all.equal</span>(<span class="kw">fitted</span>(lm_hprice1), <span class="kw">fitted</span>(lm_hprice2))</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="linearregression.html#cb146-1"></a><span class="kw">all.equal</span>(<span class="kw">fitted</span>(lm_hprice1), <span class="kw">fitted</span>(lm_hprice3))</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>With the function <code>all.equal()</code> we can test if all elements in two vectors are the “nearly” the same. “Nearly” refers to the case when <em>tolerance</em> values are exceeded.</p>
<p>Why are those values not the same depending on the <code>poly()</code> function argument <code>raw = True</code>? In the case of <code>raw = True</code> R uses raw and not orthogonal polynomials.</p>
<p>This can have importan implications in the case when multiple polynimoals are used in the regression. The linear regressar <span class="math inline">\(sqrft\)</span> is uncorrelated linearly with the squared explanatory variable <span class="math inline">\(sqrft^2\)</span>. However, if we add a cubic term <span class="math inline">\(sqrft^3\)</span>, multicollinearty between <span class="math inline">\(sqrft^2\)</span> and <span class="math inline">\(sqrft^3\)</span> might become and issues of the polynomials are <em>NOT</em> orthogonalized.</p>
<p>We can also extract the standard error of our estimated coefficents manually.</p>
<p>Starting with the variance-covariance matrix of the regression model</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="linearregression.html#cb148-1"></a>vcov_lm_hprice2 &lt;-<span class="st"> </span><span class="kw">vcov</span>(lm_hprice2)</span></code></pre></div>
<p>Extracting only the diagonal element of the matrix and taking the square root we obtain the standard errors as reported in <code>summary()</code> function call.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="linearregression.html#cb149-1"></a><span class="kw">sqrt</span>(<span class="kw">diag</span>(vcov_lm_hprice2))</span></code></pre></div>
<pre><code>##              (Intercept) poly(sqrft, degree = 2)1 poly(sqrft, degree = 2)2 
##                 6.638736                62.276866                62.276866</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="linearregression.html#cb151-1"></a><span class="kw">summary</span>(lm_hprice2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = price ~ poly(sqrft, degree = 2), data = hprice1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -158.261  -35.158   -7.924   24.262  223.516 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               293.546      6.639  44.217   &lt;2e-16 ***
## poly(sqrft, degree = 2)1  754.852     62.277  12.121   &lt;2e-16 ***
## poly(sqrft, degree = 2)2  135.605     62.277   2.177   0.0322 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 62.28 on 85 degrees of freedom
## Multiple R-squared:  0.6408, Adjusted R-squared:  0.6324 
## F-statistic: 75.83 on 2 and 85 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</div>
<div id="multiple-linear-regression" class="section level2">
<h2><span class="header-section-number">1.2</span> Multiple Linear Regression</h2>
<hr />
<p><strong>Note</strong></p>
<p>A <strong>(general) linear model</strong> is similar to the simple variant, but with a multivariate <span class="math inline">\(x \epsilon \!R^{\rho}\)</span> and a mean given by a hyperplane in place of a single line.</p>
<ul>
<li>General principles are the same as the simple case</li>
<li>Math is more difficult because we need to use matrices</li>
<li>Interpretation is more difficult because the <span class="math inline">\(\beta_{j}\)</span> are effects conditional on the other variables</li>
</ul>
<p>Many would retain the same signs as the simple linear regression, but the magnitudes would be smaller. In some cases, it is possible for
the relationship to flip directions when a second (highly correlated) variable is added <span class="citation">Dalpiaz (<a href="#ref-dalpiaz2016" role="doc-biblioref">2016</a>)</span>.</p>
<hr />
<p><span class="math display" id="eq:multipleregression">\[\begin{equation}
y = \beta_{0} + \beta_{1}x_{1} +  \beta_{2}x_{2} + \dots + \beta_{k}x_{k} + u   
\tag{1.7}
\end{equation}\]</span></p>
<p>The next example from Wooldrige relates the college GPA (“cloGPA”) to the high school GPA (“hsGPA”) and achievement test score (“ACT”) for a sample of 141 students.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="linearregression.html#cb153-1"></a><span class="kw">data</span>(<span class="st">&quot;gpa1&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;wooldridge&quot;</span>)</span>
<span id="cb153-2"><a href="linearregression.html#cb153-2"></a><span class="kw">attach</span>(gpa1)</span></code></pre></div>
<pre><code>## The following object is masked from package:robustbase:
## 
##     alcohol</code></pre>
<pre><code>## The following objects are masked from package:wooldridge:
## 
##     alcohol, campus</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="linearregression.html#cb156-1"></a>?gpa1</span></code></pre></div>
<p>Obtain parameter estimates</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="linearregression.html#cb157-1"></a>GPAres &lt;-<span class="st"> </span><span class="kw">lm</span>(colGPA <span class="op">~</span><span class="st"> </span>hsGPA <span class="op">+</span><span class="st"> </span>ACT, <span class="dt">data =</span> gpa1)</span>
<span id="cb157-2"><a href="linearregression.html#cb157-2"></a><span class="kw">summary</span>(GPAres)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = colGPA ~ hsGPA + ACT, data = gpa1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.85442 -0.24666 -0.02614  0.28127  0.85357 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 1.286328   0.340822   3.774 0.000238 ***
## hsGPA       0.453456   0.095813   4.733 5.42e-06 ***
## ACT         0.009426   0.010777   0.875 0.383297    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3403 on 138 degrees of freedom
## Multiple R-squared:  0.1764, Adjusted R-squared:  0.1645 
## F-statistic: 14.78 on 2 and 138 DF,  p-value: 1.526e-06</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="linearregression.html#cb159-1"></a><span class="kw">coef</span>(GPAres)[[<span class="dv">1</span>]]</span></code></pre></div>
<pre><code>## [1] 1.286328</code></pre>
<p>In the multiple linear regression setting, some of the interpretations of the coefficients change slightly. Here, <span class="math inline">\(\hat\beta_{0} =\)</span> 1.2863278 is our estimate for <span class="math inline">\(\beta_{0}\)</span> when all of the predictors are 0. In this example this makes sense but think of the following example:</p>
<hr />
<p><strong>Your turn</strong></p>
<p>Assume the following model:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="linearregression.html#cb161-1"></a>mpg_model =<span class="st"> </span><span class="kw">lm</span>(hp <span class="op">~</span><span class="st"> </span>wt <span class="op">+</span><span class="st"> </span>cyl, <span class="dt">data =</span> mtcars)</span>
<span id="cb161-2"><a href="linearregression.html#cb161-2"></a><span class="kw">coef</span>(mpg_model)</span></code></pre></div>
<pre><code>## (Intercept)          wt         cyl 
##  -51.805567    1.330463   31.387901</code></pre>
<p>How do you interpret the intercept coefficient estimate?</p>
<p>A: Here, <span class="math inline">\(\hat\beta_{0} =\)</span> -51.8055669 is our estimate for <span class="math inline">\(\beta_{0}\)</span>, the mean gross horsepower for a car that weights 0 pounds and has 0 cylinders. We see our estimate here is negative, which is a physical impossibility. However, this isn’t unexpected, as we shouldn’t expect our model to be accurate for cars which weight 0 pounds and have no cylinders to propel the engine.</p>
<hr />
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="linearregression.html#cb163-1"></a><span class="kw">with</span> (gpa1, {</span>
<span id="cb163-2"><a href="linearregression.html#cb163-2"></a>  <span class="co"># find min-max seq for grid construction</span></span>
<span id="cb163-3"><a href="linearregression.html#cb163-3"></a>  min_hsGPA &lt;-<span class="st"> </span><span class="kw">min</span>(gpa1<span class="op">$</span>hsGPA)</span>
<span id="cb163-4"><a href="linearregression.html#cb163-4"></a>  max_hsGPA &lt;-<span class="st"> </span><span class="kw">max</span>(gpa1<span class="op">$</span>hsGPA)</span>
<span id="cb163-5"><a href="linearregression.html#cb163-5"></a>  min_ACT &lt;-<span class="st"> </span><span class="kw">min</span>(gpa1<span class="op">$</span>ACT)</span>
<span id="cb163-6"><a href="linearregression.html#cb163-6"></a>  max_ACT &lt;-<span class="st"> </span><span class="kw">max</span>(gpa1<span class="op">$</span>ACT)</span>
<span id="cb163-7"><a href="linearregression.html#cb163-7"></a>  </span>
<span id="cb163-8"><a href="linearregression.html#cb163-8"></a>  </span>
<span id="cb163-9"><a href="linearregression.html#cb163-9"></a>  <span class="co"># linear regression</span></span>
<span id="cb163-10"><a href="linearregression.html#cb163-10"></a>  fit &lt;-<span class="st"> </span><span class="kw">lm</span>(colGPA <span class="op">~</span><span class="st"> </span>hsGPA <span class="op">+</span><span class="st"> </span>ACT)</span>
<span id="cb163-11"><a href="linearregression.html#cb163-11"></a>  </span>
<span id="cb163-12"><a href="linearregression.html#cb163-12"></a>  <span class="co"># predict values on regular xy grid</span></span>
<span id="cb163-13"><a href="linearregression.html#cb163-13"></a>  hsGPA.pred &lt;-<span class="st"> </span><span class="kw">seq</span>(min_hsGPA, max_hsGPA, <span class="dt">length.out =</span> <span class="dv">30</span>)</span>
<span id="cb163-14"><a href="linearregression.html#cb163-14"></a>  ACT.pred &lt;-<span class="st"> </span><span class="kw">seq</span>(min_ACT, max_ACT, <span class="dt">length.out =</span> <span class="dv">30</span>)</span>
<span id="cb163-15"><a href="linearregression.html#cb163-15"></a>  xy &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">hsGPA =</span> hsGPA.pred, </span>
<span id="cb163-16"><a href="linearregression.html#cb163-16"></a>                    <span class="dt">ACT =</span> ACT.pred)</span>
<span id="cb163-17"><a href="linearregression.html#cb163-17"></a>  </span>
<span id="cb163-18"><a href="linearregression.html#cb163-18"></a>  colGPA.pred &lt;-<span class="st"> </span><span class="kw">matrix</span> (<span class="dt">nrow =</span> <span class="dv">30</span>, <span class="dt">ncol =</span> <span class="dv">30</span>, </span>
<span id="cb163-19"><a href="linearregression.html#cb163-19"></a>                         <span class="dt">data =</span> <span class="kw">predict</span>(fit, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(xy), </span>
<span id="cb163-20"><a href="linearregression.html#cb163-20"></a>                                        <span class="dt">interval =</span> <span class="st">&quot;prediction&quot;</span>))</span>
<span id="cb163-21"><a href="linearregression.html#cb163-21"></a>  </span>
<span id="cb163-22"><a href="linearregression.html#cb163-22"></a>  <span class="co"># fitted points for droplines to surface</span></span>
<span id="cb163-23"><a href="linearregression.html#cb163-23"></a>  fitpoints &lt;-<span class="st"> </span><span class="kw">predict</span>(fit) </span>
<span id="cb163-24"><a href="linearregression.html#cb163-24"></a>  </span>
<span id="cb163-25"><a href="linearregression.html#cb163-25"></a>  <span class="kw">scatter3D</span>(<span class="dt">z =</span> colGPA, <span class="dt">x =</span> hsGPA, <span class="dt">y =</span> ACT, <span class="dt">pch =</span> <span class="dv">18</span>, <span class="dt">cex =</span> <span class="dv">2</span>, </span>
<span id="cb163-26"><a href="linearregression.html#cb163-26"></a>            <span class="dt">theta =</span> <span class="dv">20</span>, <span class="dt">phi =</span> <span class="dv">20</span>, <span class="dt">ticktype =</span> <span class="st">&quot;detailed&quot;</span>,</span>
<span id="cb163-27"><a href="linearregression.html#cb163-27"></a>            <span class="dt">xlab =</span> <span class="st">&quot;hsGPA&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;ACT&quot;</span>, <span class="dt">zlab =</span> <span class="st">&quot;colGPA&quot;</span>,  </span>
<span id="cb163-28"><a href="linearregression.html#cb163-28"></a>            <span class="dt">surf =</span> <span class="kw">list</span>(<span class="dt">x =</span> hsGPA.pred, <span class="dt">y =</span> ACT.pred, <span class="dt">z =</span> colGPA.pred,  </span>
<span id="cb163-29"><a href="linearregression.html#cb163-29"></a>                        <span class="dt">facets =</span> <span class="ot">NA</span>, <span class="dt">fit =</span> fitpoints),</span>
<span id="cb163-30"><a href="linearregression.html#cb163-30"></a>            <span class="dt">main =</span> <span class="st">&quot;colGPA&quot;</span>)</span>
<span id="cb163-31"><a href="linearregression.html#cb163-31"></a>  </span>
<span id="cb163-32"><a href="linearregression.html#cb163-32"></a>})</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig16"></span>
<img src="MEM5220_R_files/figure-html/fig16-1.png" alt="College GPA  High School GPA + Achievment test score" width="80%" />
<p class="caption">
Figure 1.20: College GPA High School GPA + Achievment test score
</p>
</div>
<p>The data points (<span class="math inline">\(x_{i1}\)</span>,<span class="math inline">\(x_{i2}\)</span>,<span class="math inline">\(y_{i}\)</span>) now exist in 3-dimensional space, so instead of fitting a line to the data, we will fit a plane.</p>
<div id="ceteris-paribus-interpretation-and-omitted-variable-bias" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Ceteris Paribus Interpretation and Omitted Variable bias</h3>
<p>Consider a regression with two explanatory variables</p>
<p><span class="math display" id="eq:lmtwoexplanatory">\[\begin{equation}
\hat{y} = \hat{\beta}_{0} + \hat{\beta}_{1}x_{1} +  \hat{\beta}_{2}x_{2}    
\tag{1.8}
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="linearregression.html#cb164-1"></a><span class="co"># Parameter estimates for full and simple model:</span></span>
<span id="cb164-2"><a href="linearregression.html#cb164-2"></a>beta.hat &lt;-<span class="st"> </span><span class="kw">coef</span>( <span class="kw">lm</span>(colGPA <span class="op">~</span><span class="st"> </span>ACT<span class="op">+</span>hsGPA, <span class="dt">data=</span>gpa1))</span>
<span id="cb164-3"><a href="linearregression.html#cb164-3"></a>beta.hat</span></code></pre></div>
<pre><code>## (Intercept)         ACT       hsGPA 
## 1.286327767 0.009426012 0.453455885</code></pre>
<p>Now, lets omit one variable in the regression</p>
<p><span class="math display" id="eq:lmomitted">\[\begin{equation}
\hat{y} = \hat{\beta}_{0} + \hat{\beta}_{1}x_{1}    
\tag{1.9}
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="linearregression.html#cb166-1"></a><span class="co"># Relation between regressors:</span></span>
<span id="cb166-2"><a href="linearregression.html#cb166-2"></a>delta.tilde &lt;-<span class="st"> </span><span class="kw">coef</span>( <span class="kw">lm</span>(hsGPA <span class="op">~</span><span class="st"> </span>ACT, <span class="dt">data=</span>gpa1) )</span>
<span id="cb166-3"><a href="linearregression.html#cb166-3"></a>delta.tilde</span></code></pre></div>
<pre><code>## (Intercept)         ACT 
##  2.46253658  0.03889675</code></pre>
<p>The parameter <span class="math inline">\(\hat\beta_1\)</span> is the estimated effect of increasing <span class="math inline">\(x_1\)</span> by one unit (and <strong>NOT</strong> keeping <span class="math inline">\(x_2\)</span> fixed). It can be related to <span class="math inline">\(\hat\beta_1\)</span> using the formula</p>
<p><span class="math display" id="eq:lmommited">\[\begin{equation}
\hat{y} = \hat{\beta}_{0} + \hat{\beta}_{1} x_{1} +  \hat{\beta}_{2}  \tilde\delta_{1}
\tag{1.10}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\tilde\delta_{1}\)</span> is the slope parameters of the linear regression of <span class="math inline">\(x_2\)</span> on <span class="math inline">\(x_1\)</span></p>
<p><span class="math display" id="eq:lmomitted2">\[\begin{equation}
\hat{x}_2 = \tilde\delta_{0} + \tilde\delta_{1} x_{1}
\tag{1.11}
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="linearregression.html#cb168-1"></a><span class="co"># Omitted variables formula for beta1.tilde:</span></span>
<span id="cb168-2"><a href="linearregression.html#cb168-2"></a>beta.hat[<span class="st">&quot;ACT&quot;</span>] <span class="op">+</span><span class="st"> </span>beta.hat[<span class="st">&quot;hsGPA&quot;</span>]<span class="op">*</span>delta.tilde[<span class="st">&quot;ACT&quot;</span>]</span></code></pre></div>
<pre><code>##        ACT 
## 0.02706397</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="linearregression.html#cb170-1"></a><span class="co"># Actual regression with hsGPA omitted:</span></span>
<span id="cb170-2"><a href="linearregression.html#cb170-2"></a><span class="kw">summary</span>(<span class="kw">lm</span>(colGPA <span class="op">~</span><span class="st"> </span>ACT, <span class="dt">data=</span>gpa1))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = colGPA ~ ACT, data = gpa1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.85251 -0.25251 -0.04426  0.26400  0.89336 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.40298    0.26420   9.095  8.8e-16 ***
## ACT          0.02706    0.01086   2.491   0.0139 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3656 on 139 degrees of freedom
## Multiple R-squared:  0.04275,    Adjusted R-squared:  0.03586 
## F-statistic: 6.207 on 1 and 139 DF,  p-value: 0.0139</code></pre>
<p>In this example, the indirect effect is actually stronger than the direct effect. <em>ACT</em> predicts <em>colGPA</em> mainly because it is related to <em>hsGPA</em> which in turn is strongly related to <em>colGPA</em>.</p>
</div>
<div id="standard-errors-multicollinearity-and-vif" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Standard errors, Multicollinearity and VIF</h3>
<p>Multicollinearity means that two or more regressors in a multiple regression model are strongly correlated. If the correlation between two or more regressors is perfect, that is, one regressor can be written as a linear combination of the other(s), we have perfect multicollinearity. While strong multicollinearity in general is unpleasant as it causes the variance of the OLS estimator to be large (we will discuss this in more detail later), the presence of perfect multicollinearity makes it impossible to solve for the OLS estimator, i.e., the model cannot be estimated in the first place.</p>
<div id="perfect-multicollinearity" class="section level4">
<h4><span class="header-section-number">1.2.2.1</span> Perfect multicollinearity</h4>
<p>We will work first with the <em>CAschools</em> data from the <strong>AER</strong> package to simulate an example of perfect multicollinearity</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="linearregression.html#cb172-1"></a><span class="kw">data</span>(<span class="st">&quot;CASchools&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;AER&quot;</span>)</span>
<span id="cb172-2"><a href="linearregression.html#cb172-2"></a>?CASchools</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="linearregression.html#cb173-1"></a><span class="co"># define the fraction of English learners        </span></span>
<span id="cb173-2"><a href="linearregression.html#cb173-2"></a>CASchools<span class="op">$</span>FracEL &lt;-<span class="st"> </span>CASchools<span class="op">$</span>english <span class="op">/</span><span class="st"> </span><span class="dv">100</span></span>
<span id="cb173-3"><a href="linearregression.html#cb173-3"></a></span>
<span id="cb173-4"><a href="linearregression.html#cb173-4"></a><span class="co"># check the correlation between CASchools$FracEL and CASchools$english </span></span>
<span id="cb173-5"><a href="linearregression.html#cb173-5"></a><span class="kw">cor</span>(CASchools<span class="op">$</span>FracEL, CASchools<span class="op">$</span>english)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="linearregression.html#cb175-1"></a><span class="co"># estimate the model</span></span>
<span id="cb175-2"><a href="linearregression.html#cb175-2"></a>mult.mod &lt;-<span class="st"> </span><span class="kw">lm</span>(read <span class="op">~</span><span class="st"> </span>students <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>FracEL, <span class="dt">data =</span> CASchools) </span>
<span id="cb175-3"><a href="linearregression.html#cb175-3"></a></span>
<span id="cb175-4"><a href="linearregression.html#cb175-4"></a><span class="co"># obtain a summary of the model</span></span>
<span id="cb175-5"><a href="linearregression.html#cb175-5"></a><span class="kw">summary</span>(mult.mod)  </span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = read ~ students + english + FracEL, data = CASchools)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -51.077  -9.767  -0.695   9.097  40.005 
## 
## Coefficients: (1 not defined because of singularities)
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.665e+02  9.771e-01 682.054   &lt;2e-16 ***
## students     3.326e-04  1.941e-04   1.714   0.0873 .  
## english     -7.843e-01  4.153e-02 -18.886   &lt;2e-16 ***
## FracEL              NA         NA      NA       NA    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 14.53 on 417 degrees of freedom
## Multiple R-squared:  0.4802, Adjusted R-squared:  0.4777 
## F-statistic: 192.6 on 2 and 417 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The row <em>FracEL</em> in the coefficients section of the output consists of NA entries since FracEL was excluded from the model.</p>
<p>Another example of perfect multicollinearity is known as the dummy variable trap. This may occur when multiple dummy variables are used as regressors. A common case for this is when dummies are used to sort the data into mutually exclusive categories. For example, suppose we have spatial information that indicates whether a school is located in the North, West, South or East of California.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="linearregression.html#cb177-1"></a><span class="co"># set seed for reproducibility</span></span>
<span id="cb177-2"><a href="linearregression.html#cb177-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb177-3"><a href="linearregression.html#cb177-3"></a></span>
<span id="cb177-4"><a href="linearregression.html#cb177-4"></a><span class="co"># generate artificial data on location</span></span>
<span id="cb177-5"><a href="linearregression.html#cb177-5"></a>CASchools<span class="op">$</span>direction &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;West&quot;</span>, <span class="st">&quot;North&quot;</span>, <span class="st">&quot;South&quot;</span>, <span class="st">&quot;East&quot;</span>), </span>
<span id="cb177-6"><a href="linearregression.html#cb177-6"></a>                              <span class="dv">420</span>, </span>
<span id="cb177-7"><a href="linearregression.html#cb177-7"></a>                              <span class="dt">replace =</span> T)</span>
<span id="cb177-8"><a href="linearregression.html#cb177-8"></a></span>
<span id="cb177-9"><a href="linearregression.html#cb177-9"></a><span class="co"># estimate the model</span></span>
<span id="cb177-10"><a href="linearregression.html#cb177-10"></a>mult.mod &lt;-<span class="st"> </span><span class="kw">lm</span>(read <span class="op">~</span><span class="st"> </span>students <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>direction, <span class="dt">data =</span> CASchools)</span>
<span id="cb177-11"><a href="linearregression.html#cb177-11"></a></span>
<span id="cb177-12"><a href="linearregression.html#cb177-12"></a><span class="co"># obtain a model summary</span></span>
<span id="cb177-13"><a href="linearregression.html#cb177-13"></a><span class="kw">summary</span>(mult.mod)   </span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = read ~ students + english + direction, data = CASchools)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -51.373  -9.722  -0.858   9.071  39.590 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     6.657e+02  1.546e+00 430.691   &lt;2e-16 ***
## students        3.347e-04  1.954e-04   1.713   0.0875 .  
## english        -7.909e-01  4.246e-02 -18.629   &lt;2e-16 ***
## directionNorth  1.736e+00  2.070e+00   0.838   0.4024    
## directionSouth  4.131e-01  2.076e+00   0.199   0.8424    
## directionWest   1.118e+00  1.992e+00   0.561   0.5748    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 14.57 on 414 degrees of freedom
## Multiple R-squared:  0.4812, Adjusted R-squared:  0.4749 
## F-statistic:  76.8 on 5 and 414 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Notice that R solves the problem on its own by generating and including the dummies directionNorth, directionSouth and directionWest but omitting directionEast. Of course, the omission of every other dummy instead would achieve the same. Another solution would be to exclude the constant and to include all dummies instead.</p>
<p>A last example considers the case where a perfect linear relationship arises from redundant regressors. Suppose we have a regressor<br />
Spanish speakers, <em>spanish</em>, , the percentage of English speakers in the school where</p>
<p><span class="math display">\[\begin{equation}
spanish = 100 - english  
\end{equation}\]</span></p>
<p>and both <em>spanish</em> and <em>english</em> are included in a regression model.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="linearregression.html#cb179-1"></a><span class="co"># Percentage of english speakers </span></span>
<span id="cb179-2"><a href="linearregression.html#cb179-2"></a>CASchools<span class="op">$</span>spanish &lt;-<span class="st"> </span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>CASchools<span class="op">$</span>english</span>
<span id="cb179-3"><a href="linearregression.html#cb179-3"></a></span>
<span id="cb179-4"><a href="linearregression.html#cb179-4"></a><span class="co"># estimate the model</span></span>
<span id="cb179-5"><a href="linearregression.html#cb179-5"></a>mult.mod &lt;-<span class="st"> </span><span class="kw">lm</span>(read <span class="op">~</span><span class="st"> </span>students <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>spanish, <span class="dt">data =</span> CASchools)</span>
<span id="cb179-6"><a href="linearregression.html#cb179-6"></a></span>
<span id="cb179-7"><a href="linearregression.html#cb179-7"></a><span class="co"># obtain a model summary</span></span>
<span id="cb179-8"><a href="linearregression.html#cb179-8"></a><span class="kw">summary</span>(mult.mod)                                                 </span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = read ~ students + english + spanish, data = CASchools)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -51.077  -9.767  -0.695   9.097  40.005 
## 
## Coefficients: (1 not defined because of singularities)
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.665e+02  9.771e-01 682.054   &lt;2e-16 ***
## students     3.326e-04  1.941e-04   1.714   0.0873 .  
## english     -7.843e-01  4.153e-02 -18.886   &lt;2e-16 ***
## spanish             NA         NA      NA       NA    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 14.53 on 417 degrees of freedom
## Multiple R-squared:  0.4802, Adjusted R-squared:  0.4777 
## F-statistic: 192.6 on 2 and 417 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Once more, <code>lm()</code> refuses to estimate the full model using OLS and excludes spanish.</p>
</div>
<div id="imperfect-multicollinearity" class="section level4">
<h4><span class="header-section-number">1.2.2.2</span> Imperfect multicollinearity</h4>
<p>As opposed to perfect multicollinearity, imperfect multicollinearity is — to a certain extent — less of a problem. In fact, imperfect multicollinearity is the reason why we are interested in estimating multiple regression models in the first place: the OLS estimator allows us to isolate influences of correlated regressors on the dependent variable. If it was not for these dependencies, there would not be a reason to resort to a multiple regression approach and we could simply work with a single-regressor model. However, this is rarely the case in applications. We already know that ignoring dependencies among regressors which influence the outcome variable has an adverse effect on estimation results.</p>
<p>Simulation study: imperfect multicollinearity</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="linearregression.html#cb181-1"></a><span class="co"># set number of observations</span></span>
<span id="cb181-2"><a href="linearregression.html#cb181-2"></a>n &lt;-<span class="st"> </span><span class="dv">50</span></span>
<span id="cb181-3"><a href="linearregression.html#cb181-3"></a></span>
<span id="cb181-4"><a href="linearregression.html#cb181-4"></a><span class="co"># initialize vectors of coefficients</span></span>
<span id="cb181-5"><a href="linearregression.html#cb181-5"></a>coefs1 &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="st">&quot;hat_beta_1&quot;</span> =<span class="st"> </span><span class="kw">numeric</span>(<span class="dv">10000</span>), <span class="st">&quot;hat_beta_2&quot;</span> =<span class="st"> </span><span class="kw">numeric</span>(<span class="dv">10000</span>))</span>
<span id="cb181-6"><a href="linearregression.html#cb181-6"></a>coefs2 &lt;-<span class="st"> </span>coefs1</span>
<span id="cb181-7"><a href="linearregression.html#cb181-7"></a></span>
<span id="cb181-8"><a href="linearregression.html#cb181-8"></a><span class="co"># set seed</span></span>
<span id="cb181-9"><a href="linearregression.html#cb181-9"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb181-10"><a href="linearregression.html#cb181-10"></a></span>
<span id="cb181-11"><a href="linearregression.html#cb181-11"></a><span class="co"># loop sampling and estimation</span></span>
<span id="cb181-12"><a href="linearregression.html#cb181-12"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>) {</span>
<span id="cb181-13"><a href="linearregression.html#cb181-13"></a>  </span>
<span id="cb181-14"><a href="linearregression.html#cb181-14"></a>  <span class="co"># for cov(X_1,X_2) = 0.25</span></span>
<span id="cb181-15"><a href="linearregression.html#cb181-15"></a>  X &lt;-<span class="st"> </span><span class="kw">rmvnorm</span>(n, <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">100</span>), <span class="dt">sigma =</span> <span class="kw">cbind</span>(<span class="kw">c</span>(<span class="dv">10</span>, <span class="fl">2.5</span>), <span class="kw">c</span>(<span class="fl">2.5</span>, <span class="dv">10</span>))) <span class="co"># function from the mvtnorm package</span></span>
<span id="cb181-16"><a href="linearregression.html#cb181-16"></a>  u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">sd =</span> <span class="dv">5</span>)</span>
<span id="cb181-17"><a href="linearregression.html#cb181-17"></a>  Y &lt;-<span class="st"> </span><span class="dv">5</span> <span class="op">+</span><span class="st"> </span><span class="fl">2.5</span> <span class="op">*</span><span class="st"> </span>X[, <span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="dv">3</span> <span class="op">*</span><span class="st"> </span>X[, <span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>u</span>
<span id="cb181-18"><a href="linearregression.html#cb181-18"></a>  coefs1[i, ] &lt;-<span class="st"> </span><span class="kw">lm</span>(Y <span class="op">~</span><span class="st"> </span>X[, <span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>X[, <span class="dv">2</span>])<span class="op">$</span>coefficients[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb181-19"><a href="linearregression.html#cb181-19"></a>  </span>
<span id="cb181-20"><a href="linearregression.html#cb181-20"></a>  <span class="co"># for cov(X_1,X_2) = 0.85</span></span>
<span id="cb181-21"><a href="linearregression.html#cb181-21"></a>  X &lt;-<span class="st"> </span><span class="kw">rmvnorm</span>(n, <span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">100</span>), <span class="dt">sigma =</span> <span class="kw">cbind</span>(<span class="kw">c</span>(<span class="dv">10</span>, <span class="fl">8.5</span>), <span class="kw">c</span>(<span class="fl">8.5</span>, <span class="dv">10</span>)))</span>
<span id="cb181-22"><a href="linearregression.html#cb181-22"></a>  Y &lt;-<span class="st"> </span><span class="dv">5</span> <span class="op">+</span><span class="st"> </span><span class="fl">2.5</span> <span class="op">*</span><span class="st"> </span>X[, <span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="dv">3</span> <span class="op">*</span><span class="st"> </span>X[, <span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>u</span>
<span id="cb181-23"><a href="linearregression.html#cb181-23"></a>  imperf_multicol &lt;-<span class="st"> </span><span class="kw">lm</span>(Y <span class="op">~</span><span class="st"> </span>X[, <span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>X[, <span class="dv">2</span>])</span>
<span id="cb181-24"><a href="linearregression.html#cb181-24"></a>  coefs2[i, ] &lt;-<span class="st"> </span><span class="kw">lm</span>(Y <span class="op">~</span><span class="st"> </span>X[, <span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>X[, <span class="dv">2</span>])<span class="op">$</span>coefficients[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb181-25"><a href="linearregression.html#cb181-25"></a>  </span>
<span id="cb181-26"><a href="linearregression.html#cb181-26"></a>}</span>
<span id="cb181-27"><a href="linearregression.html#cb181-27"></a></span>
<span id="cb181-28"><a href="linearregression.html#cb181-28"></a><span class="co"># obtain variance estimates</span></span>
<span id="cb181-29"><a href="linearregression.html#cb181-29"></a><span class="kw">diag</span>(<span class="kw">var</span>(coefs1))</span></code></pre></div>
<pre><code>## hat_beta_1 hat_beta_2 
##  0.5698281  0.8163287</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="linearregression.html#cb183-1"></a><span class="kw">diag</span>(<span class="kw">var</span>(coefs2))</span></code></pre></div>
<pre><code>## hat_beta_1 hat_beta_2 
##  0.5834243  0.8402187</code></pre>
<p>We are interested in the variances which are the diagonal elements. We see that due to the high collinearity, the variances of <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_2\)</span> and have increased, meaning it is more difficult to precisely estimate the true coefficients.</p>
<p>The variance inflation factor, <em>VIF</em>, accounts for (imperfect) multicollinearity.If <span class="math inline">\(x_t\)</span> is highly related to the other regressors, <span class="math inline">\(R^2_j\)</span> and therefore also <span class="math inline">\(VIF_j\)</span> and the variance of <span class="math inline">\(\hat\beta_j\)</span> are large.</p>
<p><span class="math display" id="eq:VIF">\[\begin{equation}
\frac{1}{1-R^2_j}
\tag{1.12}
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="linearregression.html#cb185-1"></a>GPAres &lt;-<span class="st"> </span><span class="kw">lm</span>(colGPA <span class="op">~</span><span class="st"> </span>hsGPA <span class="op">+</span><span class="st"> </span>ACT, <span class="dt">data =</span> gpa1)</span>
<span id="cb185-2"><a href="linearregression.html#cb185-2"></a>SER&lt;-<span class="kw">summary</span>(GPAres)<span class="op">$</span>sigma</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="linearregression.html#cb186-1"></a><span class="co"># regressing hsGPA on ACT for calculation of R2 &amp; VIF</span></span>
<span id="cb186-2"><a href="linearregression.html#cb186-2"></a>( R2.hsGPA  &lt;-<span class="st"> </span><span class="kw">summary</span>( <span class="kw">lm</span>(hsGPA<span class="op">~</span>ACT, <span class="dt">data=</span>gpa1) )<span class="op">$</span>r.squared )</span></code></pre></div>
<pre><code>## [1] 0.1195815</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="linearregression.html#cb188-1"></a>( VIF.hsGPA &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>R2.hsGPA) )</span></code></pre></div>
<pre><code>## [1] 1.135823</code></pre>
<p>The <strong>car</strong> package implements the command <code>vif()</code> for each regressor</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="linearregression.html#cb190-1"></a><span class="kw">vif</span>(GPAres)</span></code></pre></div>
<pre><code>##    hsGPA      ACT 
## 1.135823 1.135823</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="linearregression.html#cb192-1"></a><span class="kw">vif</span>(imperf_multicol) <span class="co"># from the simulated data</span></span></code></pre></div>
<pre><code>##   X[, 1]   X[, 2] 
## 4.932864 4.932864</code></pre>
</div>
</div>
<div id="reporting-regression-results" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Reporting Regression Results</h3>
<p>As we start moving towards the comparing different regression models this section provides a discussion on how to report regression reports in <code>R</code>. Depending on your script (R scripts, R Markdown, bookdown) and what your desired output format is (LaTeX, word, html) the exact approach might differ. There are multiple packages to format regression or table output, most notably <strong>stargazer</strong><a href="references.html#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>, <strong>huxtable</strong>, <strong>Hmisc</strong> and <strong>xtable</strong>. One can also tidy the the regression output as well as tables with <strong>broom</strong> or <strong>summarytool</strong>. The wrapper <code>knitr::kable()</code> is a support function that renders the table in an R Markdown in a pretty way.</p>
<div id="table" class="section level4">
<h4><span class="header-section-number">1.2.3.1</span> Table</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="linearregression.html#cb194-1"></a>knitr<span class="op">::</span><span class="kw">kable</span>(</span>
<span id="cb194-2"><a href="linearregression.html#cb194-2"></a>  <span class="kw">head</span>(gpa1[,<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>], <span class="dv">10</span>), <span class="dt">booktabs =</span> <span class="ot">TRUE</span>, </span>
<span id="cb194-3"><a href="linearregression.html#cb194-3"></a>  <span class="dt">caption =</span> <span class="st">&quot;A table of the first eight columns and ten rows of the gpa1 data.&quot;</span></span>
<span id="cb194-4"><a href="linearregression.html#cb194-4"></a>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-81">Table 1.2: </span>A table of the first eight columns and ten rows of the gpa1 data.</caption>
<thead>
<tr class="header">
<th align="right">age</th>
<th align="right">soph</th>
<th align="right">junior</th>
<th align="right">senior</th>
<th align="right">senior5</th>
<th align="right">male</th>
<th align="right">campus</th>
<th align="right">business</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">21</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">21</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">20</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">19</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">20</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">20</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">22</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">22</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">22</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">19</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="linearregression.html#cb195-1"></a>knitr<span class="op">::</span><span class="kw">kable</span>(</span>
<span id="cb195-2"><a href="linearregression.html#cb195-2"></a>  <span class="kw">descr</span>(gpa1[,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">stats =</span> <span class="kw">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;sd&quot;</span>, <span class="st">&quot;min&quot;</span>, <span class="st">&quot;med&quot;</span>, <span class="st">&quot;max&quot;</span>), <span class="dt">transpose =</span> <span class="ot">TRUE</span>, </span>
<span id="cb195-3"><a href="linearregression.html#cb195-3"></a>        <span class="dt">omit.headings =</span> <span class="ot">TRUE</span>, <span class="dt">style =</span> <span class="st">&quot;rmarkdown&quot;</span>)</span>
<span id="cb195-4"><a href="linearregression.html#cb195-4"></a>)</span></code></pre></div>
<pre><code>## &#39;omit.headings&#39; argument has been replaced by &#39;headings&#39;; setting headings = FALSE</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Mean</th>
<th align="right">Std.Dev</th>
<th align="right">Min</th>
<th align="right">Median</th>
<th align="right">Max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>age</td>
<td align="right">20.8865248</td>
<td align="right">1.2710637</td>
<td align="right">19</td>
<td align="right">21</td>
<td align="right">30</td>
</tr>
<tr class="even">
<td>junior</td>
<td align="right">0.3829787</td>
<td align="right">0.4878462</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td>soph</td>
<td align="right">0.0212766</td>
<td align="right">0.1448194</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="linearregression.html#cb197-1"></a>model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(colGPA <span class="op">~</span><span class="st"> </span>hsGPA , <span class="dt">data =</span> gpa1)</span>
<span id="cb197-2"><a href="linearregression.html#cb197-2"></a>model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(colGPA <span class="op">~</span><span class="st"> </span>hsGPA <span class="op">+</span><span class="st"> </span>ACT, <span class="dt">data =</span> gpa1)</span>
<span id="cb197-3"><a href="linearregression.html#cb197-3"></a>model3 &lt;-<span class="st"> </span><span class="kw">lm</span>(colGPA <span class="op">~</span><span class="st"> </span>hsGPA <span class="op">+</span><span class="st"> </span>ACT <span class="op">+</span><span class="st"> </span>age, <span class="dt">data =</span> gpa1)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="linearregression.html#cb198-1"></a><span class="kw">invisible</span>(<span class="kw">stargazer</span>(</span>
<span id="cb198-2"><a href="linearregression.html#cb198-2"></a>  <span class="kw">list</span>(model1, </span>
<span id="cb198-3"><a href="linearregression.html#cb198-3"></a>       model2,</span>
<span id="cb198-4"><a href="linearregression.html#cb198-4"></a>       model3)</span>
<span id="cb198-5"><a href="linearregression.html#cb198-5"></a>  ,<span class="dt">keep.stat =</span> <span class="kw">c</span>(<span class="st">&quot;n&quot;</span>, <span class="st">&quot;rsq&quot;</span>), <span class="dt">type =</span> <span class="st">&quot;latex&quot;</span>, <span class="dt">header =</span> <span class="ot">FALSE</span>))<span class="co"># to have number of observations and R^2 reported</span></span></code></pre></div>

<pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="linearregression.html#cb199-1"></a><span class="kw">stargazer</span>(</span>
<span id="cb199-2"><a href="linearregression.html#cb199-2"></a>  <span class="kw">list</span>(model1, </span>
<span id="cb199-3"><a href="linearregression.html#cb199-3"></a>       model2,</span>
<span id="cb199-4"><a href="linearregression.html#cb199-4"></a>       model3)</span>
<span id="cb199-5"><a href="linearregression.html#cb199-5"></a>  ,<span class="dt">keep.stat =</span> <span class="kw">c</span>(<span class="st">&quot;n&quot;</span>, <span class="st">&quot;rsq&quot;</span>), <span class="dt">type =</span> <span class="st">&quot;html&quot;</span>, <span class="dt">header =</span> <span class="ot">FALSE</span>) <span class="co"># to have number of observations and R^2 reported</span></span></code></pre></div>
<table style="text-align:center">
<tr>
<td colspan="4" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="3">
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="3">
colGPA
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(1)
</td>
<td>
(2)
</td>
<td>
(3)
</td>
</tr>
<tr>
<td colspan="4" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
hsGPA
</td>
<td>
0.482<sup>***</sup>
</td>
<td>
0.453<sup>***</sup>
</td>
<td>
0.482<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.090)
</td>
<td>
(0.096)
</td>
<td>
(0.099)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
ACT
</td>
<td>
</td>
<td>
0.009
</td>
<td>
0.009
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.011)
</td>
<td>
(0.011)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
age
</td>
<td>
</td>
<td>
</td>
<td>
0.027
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
<td>
(0.023)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
1.415<sup>***</sup>
</td>
<td>
1.286<sup>***</sup>
</td>
<td>
0.618
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.307)
</td>
<td>
(0.341)
</td>
<td>
(0.663)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td colspan="4" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
141
</td>
<td>
141
</td>
<td>
141
</td>
</tr>
<tr>
<td style="text-align:left">
R<sup>2</sup>
</td>
<td>
0.172
</td>
<td>
0.176
</td>
<td>
0.185
</td>
</tr>
<tr>
<td colspan="4" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
<em>Note:</em>
</td>
<td colspan="3" style="text-align:right">
<sup><em></sup>p&lt;0.1; <sup><strong></sup>p&lt;0.05; <sup></strong></em></sup>p&lt;0.01
</td>
</tr>
</table>
<p>Including the <code>knitr::kable()</code> wrapper</p>
</div>
</div>
<div id="model-formulae" class="section level3">
<h3><span class="header-section-number">1.2.4</span> Model Formulae</h3>
<div id="arithmetic-operations-within-a-formula" class="section level4">
<h4><span class="header-section-number">1.2.4.1</span> Arithmetic operations within a formula</h4>
<p>A model relating to birth weight to cigarette smoking of the mother during pregnancy and the family income.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="linearregression.html#cb200-1"></a><span class="kw">data</span>(<span class="st">&quot;bwght&quot;</span>)</span>
<span id="cb200-2"><a href="linearregression.html#cb200-2"></a><span class="kw">attach</span>(bwght)</span></code></pre></div>
<pre><code>## The following object is masked _by_ .GlobalEnv:
## 
##     bwght</code></pre>
<pre><code>## The following object is masked from gpa1:
## 
##     male</code></pre>
<pre><code>## The following object is masked from package:wooldridge:
## 
##     bwght</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="linearregression.html#cb204-1"></a>lm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(bwght <span class="op">~</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>faminc, <span class="dt">data =</span> bwght)</span>
<span id="cb204-2"><a href="linearregression.html#cb204-2"></a><span class="co"># Weights in pounds, direct way</span></span>
<span id="cb204-3"><a href="linearregression.html#cb204-3"></a>lm2 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">I</span>(bwght<span class="op">/</span><span class="dv">16</span>) <span class="op">~</span><span class="st"> </span>cigs <span class="op">+</span><span class="st"> </span>faminc, <span class="dt">data =</span> bwght)</span>
<span id="cb204-4"><a href="linearregression.html#cb204-4"></a><span class="co"># Packs of cigarettes</span></span>
<span id="cb204-5"><a href="linearregression.html#cb204-5"></a>lm3 &lt;-<span class="st"> </span><span class="kw">lm</span>(bwght <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(cigs<span class="op">/</span><span class="dv">20</span>) <span class="op">+</span><span class="st"> </span>faminc, <span class="dt">data =</span> bwght)</span></code></pre></div>
<p>See table <a href="linearregression.html#tab:regressiontable">1.3</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="linearregression.html#cb205-1"></a><span class="kw">huxreg</span>(lm1, lm2, lm3) <span class="op">%&gt;%</span><span class="st">  </span></span>
<span id="cb205-2"><a href="linearregression.html#cb205-2"></a><span class="st">  </span><span class="kw">set_caption</span>(<span class="st">&#39;(#tab:regressiontable) Regression table&#39;</span>)  <span class="co"># #tab:foo allows to reference to a table directly in a dynamic document. </span></span></code></pre></div>
<table class="huxtable" style="border-collapse: collapse; margin-bottom: 2em; margin-top: 2em; width: 50%; margin-left: auto; margin-right: auto;  ">
<caption style="caption-side: top; text-align: center;"><span id="tab:regressiontable">Table 1.3: </span> Regression table</caption><col><col><col><col><tr>
<td style="vertical-align: top; text-align: center; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;"></td>
<td style="vertical-align: top; text-align: center; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">(1)</td>
<td style="vertical-align: top; text-align: center; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">(2)</td>
<td style="vertical-align: top; text-align: center; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">(3)</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">(Intercept)</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">116.974 ***</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">7.311 ***</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">116.974 ***</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;"></td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">(1.049)&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">(0.066)&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">(1.049)&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">cigs</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">-0.463 ***</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">-0.029 ***</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;"></td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">(0.092)&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">(0.006)&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">faminc</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">0.093 **&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">0.006 **&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">0.093 **&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;"></td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">(0.029)&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">(0.002)&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">(0.029)&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">I(cigs/20)</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">-9.268 ***</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;"></td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">(1.832)&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">N</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">1388&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">1388&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">1388&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">R2</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">0.030&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">0.030&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">0.030&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">logLik</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">-6130.414&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">-2282.061&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">-6130.414&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt; padding: 4pt 4pt 4pt 4pt;">AIC</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt; padding: 4pt 4pt 4pt 4pt;">12268.828&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt; padding: 4pt 4pt 4pt 4pt;">4572.122&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt; padding: 4pt 4pt 4pt 4pt;">12268.828&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td colspan="4" style="vertical-align: top; text-align: left; white-space: normal; padding: 4pt 4pt 4pt 4pt;"> *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.</td>
</tr>
</table>

<pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="linearregression.html#cb206-1"></a><span class="kw">invisible</span>(<span class="kw">stargazer</span>( <span class="co"># invisible supresses additional output such as the package author name when the regression table is compiled</span></span>
<span id="cb206-2"><a href="linearregression.html#cb206-2"></a>  <span class="kw">list</span>(lm1, </span>
<span id="cb206-3"><a href="linearregression.html#cb206-3"></a>       lm2,</span>
<span id="cb206-4"><a href="linearregression.html#cb206-4"></a>       lm3)</span>
<span id="cb206-5"><a href="linearregression.html#cb206-5"></a>  ,<span class="dt">keep.stat =</span> <span class="kw">c</span>(<span class="st">&quot;n&quot;</span>, <span class="st">&quot;rsq&quot;</span>), <span class="dt">type =</span> <span class="st">&quot;latex&quot;</span>, <span class="dt">header =</span> <span class="ot">FALSE</span>))<span class="co"># to have number of observations and R^2 reported}</span></span></code></pre></div>
<p>Dividing the dependent variable by 16 changes all coefficients by the same factor <span class="math inline">\(\frac{1}{16}\)</span> and dividing the regressor by 20 changes its coefficients by the factor 20. Other statistics like <span class="math inline">\(R^2\)</span> are unaffected.</p>
</div>
<div id="standardization-beta-coefficients" class="section level4">
<h4><span class="header-section-number">1.2.4.2</span> Standardization: Beta coefficients</h4>
<p>The standardized dependent variable <span class="math inline">\(y\)</span> and regressor <span class="math inline">\(x_1\)</span> are</p>
<p><span class="math display">\[\begin{equation}
z_y=\frac{y-\bar{y}}{sd(y)}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{equation}
z_{x1}=\frac{x_{1}-\bar{x}_{x1}}{sd(x_{1})}
\end{equation}\]</span></p>
<p>They measure by how many <em>standard deviations</em> <span class="math inline">\(y\)</span> changes as the respective independent variable increases by <em>one standard deviation</em>.</p>
<p>The model does not include a constant because all averages are removed in the standardization.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="linearregression.html#cb207-1"></a><span class="kw">data</span>(hprice2)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="linearregression.html#cb208-1"></a><span class="kw">lm</span>(<span class="kw">scale</span>(price)<span class="op">~</span><span class="dv">0</span> <span class="op">+</span><span class="st">  </span><span class="kw">scale</span>(crime) <span class="op">+</span><span class="st">  </span><span class="kw">scale</span>(rooms) <span class="op">+</span><span class="st"> </span><span class="kw">scale</span>(dist) <span class="op">+</span><span class="st">  </span><span class="kw">scale</span>(stratio), <span class="dt">data =</span> hprice2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = scale(price) ~ 0 + scale(crime) + scale(rooms) + 
##     scale(dist) + scale(stratio), data = hprice2)
## 
## Coefficients:
##   scale(crime)    scale(rooms)     scale(dist)  scale(stratio)  
##      -0.191397        0.565694        0.003809       -0.246953</code></pre>
</div>
<div id="logarithms-quadratics-and-polynomials" class="section level4">
<h4><span class="header-section-number">1.2.4.3</span> Logarithms, Quadratics and Polynomials</h4>
<p>The model for house prices as in Wooldrige:</p>
<p><span class="math display">\[\begin{equation}
log(price) = \beta_0 +  \beta_1 log(nox) + \beta_2 log(dist) + \beta_3 rooms + \beta_4 rooms^{2} + \beta_5 stratio + u 
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="linearregression.html#cb210-1"></a>lm_hprice2 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(price)<span class="op">~</span><span class="st">  </span><span class="kw">log</span>(nox) <span class="op">+</span><span class="st">  </span><span class="kw">log</span>(dist) <span class="op">+</span><span class="st"> </span>rooms <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(rooms<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>stratio, <span class="dt">data =</span> hprice2)</span>
<span id="cb210-2"><a href="linearregression.html#cb210-2"></a><span class="kw">summary</span>(lm_hprice2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(price) ~ log(nox) + log(dist) + rooms + I(rooms^2) + 
##     stratio, data = hprice2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.04285 -0.12774  0.02038  0.12650  1.25272 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 13.385477   0.566473  23.630  &lt; 2e-16 ***
## log(nox)    -0.901682   0.114687  -7.862 2.34e-14 ***
## log(dist)   -0.086781   0.043281  -2.005  0.04549 *  
## rooms       -0.545113   0.165454  -3.295  0.00106 ** 
## I(rooms^2)   0.062261   0.012805   4.862 1.56e-06 ***
## stratio     -0.047590   0.005854  -8.129 3.42e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2592 on 500 degrees of freedom
## Multiple R-squared:  0.6028, Adjusted R-squared:  0.5988 
## F-statistic: 151.8 on 5 and 500 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li>The quadratic term of rooms significantly positive coefficient <span class="math inline">\(\hat\beta_4\)</span> implying that the semi-elasticity increases with more rooms</li>
<li>The negative coefficient for rooms indicates that for small number of rooms the price decreases and</li>
<li>the positive coefficient for <span class="math inline">\(rooms^2\)</span> implies that for “large” value of rooms the price increases</li>
<li>The number of rooms implying the smallest price can be found as</li>
</ul>
<p><span class="math display">\[\begin{equation}
rooms^{\star} = \frac{-\beta_3}{2\beta_4} \approx 4.4
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="linearregression.html#cb212-1"></a>beta3 &lt;-<span class="st"> </span>lm_hprice2<span class="op">$</span>coefficients[[<span class="dv">4</span>]]</span>
<span id="cb212-2"><a href="linearregression.html#cb212-2"></a>beta4 &lt;-<span class="st"> </span>lm_hprice2<span class="op">$</span>coefficients[[<span class="dv">5</span>]]</span>
<span id="cb212-3"><a href="linearregression.html#cb212-3"></a><span class="op">-</span>beta3 <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>beta4)</span></code></pre></div>
<pre><code>## [1] 4.37763</code></pre>
</div>
<div id="interaction-terms" class="section level4">
<h4><span class="header-section-number">1.2.4.4</span> Interaction terms</h4>
<p>Consider the following model,</p>
<p><span class="math display" id="eq:interactionterm">\[\begin{equation}
Y = {\beta}_{0} + {\beta}_{1}x_{1} +  {\beta}_{2}x_{2} + {\beta}_{3}x_{1}x_{2} + u    
\tag{1.13}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, and <span class="math inline">\(Y\)</span> are the same as before, but we have added a new interaction term <span class="math inline">\(x_1x_2\)</span> which multiplies <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, so we also have an additional <span class="math inline">\(\beta\)</span> parameter <span class="math inline">\(\beta_3\)</span>.</p>
<p>This model essentially creates two slopes and two intercepts, <span class="math inline">\(\beta_2\)</span> being the difference in intercepts and <span class="math inline">\(\beta_3\)</span> being the difference in slopes.</p>
<p>Recall that R reads <strong>x1</strong> times <strong>x2</strong> as <span class="math inline">\(y \sim x_1+x_2+x_1x_2\)</span> and <strong>x1:x2</strong> as <span class="math inline">\(y \sim x_1x_2\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="linearregression.html#cb214-1"></a><span class="kw">data</span>(attend)</span></code></pre></div>
</div>
</div>
<div id="mlr-prediction" class="section level3">
<h3><span class="header-section-number">1.2.5</span> MLR Prediction</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="linearregression.html#cb215-1"></a><span class="kw">data</span>(gpa2)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="linearregression.html#cb216-1"></a><span class="co"># Estimate model with interaction effect:</span></span>
<span id="cb216-2"><a href="linearregression.html#cb216-2"></a>myres&lt;-<span class="kw">lm</span>(stndfnl<span class="op">~</span>atndrte<span class="op">*</span>priGPA<span class="op">+</span>ACT<span class="op">+</span><span class="kw">I</span>(priGPA<span class="op">^</span><span class="dv">2</span>)<span class="op">+</span><span class="kw">I</span>(ACT<span class="op">^</span><span class="dv">2</span>), <span class="dt">data=</span>attend)</span>
<span id="cb216-3"><a href="linearregression.html#cb216-3"></a></span>
<span id="cb216-4"><a href="linearregression.html#cb216-4"></a><span class="co"># Estimate for partial effect at priGPA=2.59:</span></span>
<span id="cb216-5"><a href="linearregression.html#cb216-5"></a>b &lt;-<span class="st"> </span><span class="kw">coef</span>(myres)</span>
<span id="cb216-6"><a href="linearregression.html#cb216-6"></a>b[<span class="st">&quot;atndrte&quot;</span>] <span class="op">+</span><span class="st"> </span><span class="fl">2.59</span><span class="op">*</span>b[<span class="st">&quot;atndrte:priGPA&quot;</span>] </span></code></pre></div>
<pre><code>##     atndrte 
## 0.007754572</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="linearregression.html#cb218-1"></a><span class="co"># Test partial effect for priGPA=2.59:</span></span>
<span id="cb218-2"><a href="linearregression.html#cb218-2"></a>Hnull &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;atndrte+2.59*atndrte:priGPA&quot;</span>)</span>
<span id="cb218-3"><a href="linearregression.html#cb218-3"></a>linHyp &lt;-<span class="st"> </span><span class="kw">linearHypothesis</span>(myres,Hnull)</span>
<span id="cb218-4"><a href="linearregression.html#cb218-4"></a><span class="co"># broom::tidy(linHyp)</span></span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="linearregression.html#cb219-1"></a><span class="co"># Regress and report coefficients</span></span>
<span id="cb219-2"><a href="linearregression.html#cb219-2"></a>reg &lt;-<span class="st"> </span><span class="kw">lm</span>(colgpa<span class="op">~</span>sat<span class="op">+</span>hsperc<span class="op">+</span>hsize<span class="op">+</span><span class="kw">I</span>(hsize<span class="op">^</span><span class="dv">2</span>),<span class="dt">data=</span>gpa2)</span>
<span id="cb219-3"><a href="linearregression.html#cb219-3"></a>reg</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = colgpa ~ sat + hsperc + hsize + I(hsize^2), data = gpa2)
## 
## Coefficients:
## (Intercept)          sat       hsperc        hsize   I(hsize^2)  
##    1.492652     0.001492    -0.013856    -0.060881     0.005460</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="linearregression.html#cb221-1"></a><span class="co"># Generate data set containing the regressor values for predictions</span></span>
<span id="cb221-2"><a href="linearregression.html#cb221-2"></a>cvalues &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">sat=</span><span class="dv">1200</span>, <span class="dt">hsperc=</span><span class="dv">30</span>, <span class="dt">hsize=</span><span class="dv">5</span>)</span>
<span id="cb221-3"><a href="linearregression.html#cb221-3"></a></span>
<span id="cb221-4"><a href="linearregression.html#cb221-4"></a><span class="co"># Point estimate of prediction</span></span>
<span id="cb221-5"><a href="linearregression.html#cb221-5"></a><span class="kw">predict</span>(reg, cvalues)</span></code></pre></div>
<pre><code>##        1 
## 2.700075</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="linearregression.html#cb223-1"></a><span class="co"># Point estimate and 95% confidence interval</span></span>
<span id="cb223-2"><a href="linearregression.html#cb223-2"></a><span class="kw">predict</span>(reg, cvalues, <span class="dt">interval =</span> <span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 2.700075 2.661104 2.739047</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="linearregression.html#cb225-1"></a><span class="co"># Define three sets of regressor variables</span></span>
<span id="cb225-2"><a href="linearregression.html#cb225-2"></a>cvalues &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">sat=</span><span class="kw">c</span>(<span class="dv">1200</span>,<span class="dv">900</span>,<span class="dv">1400</span>), <span class="dt">hsperc=</span><span class="kw">c</span>(<span class="dv">30</span>,<span class="dv">20</span>,<span class="dv">5</span>), </span>
<span id="cb225-3"><a href="linearregression.html#cb225-3"></a>                      <span class="dt">hsize=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">3</span>,<span class="dv">1</span>))</span>
<span id="cb225-4"><a href="linearregression.html#cb225-4"></a></span>
<span id="cb225-5"><a href="linearregression.html#cb225-5"></a><span class="co"># Point estimates and 99% confidence intervals for these</span></span>
<span id="cb225-6"><a href="linearregression.html#cb225-6"></a><span class="kw">predict</span>(reg, cvalues, <span class="dt">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="dt">level=</span><span class="fl">0.99</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 2.700075 2.648850 2.751301
## 2 2.425282 2.388540 2.462025
## 3 3.457448 3.385572 3.529325</code></pre>
</div>
</div>
<div id="mlr-analysis-with-qualitative-regressors" class="section level2">
<h2><span class="header-section-number">1.3</span> MLR Analysis with Qualitative Regressors</h2>
<div id="dummy-variabes" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Dummy variabes</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="linearregression.html#cb227-1"></a><span class="kw">data</span>(wage1)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="linearregression.html#cb228-1"></a>lm1_wage1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span>female<span class="op">+</span>educ<span class="op">+</span>exper<span class="op">+</span>tenure, <span class="dt">data=</span>wage1)</span>
<span id="cb228-2"><a href="linearregression.html#cb228-2"></a><span class="kw">summary</span>(lm1_wage1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wage ~ female + educ + exper + tenure, data = wage1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.7675 -1.8080 -0.4229  1.0467 14.0075 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.56794    0.72455  -2.164   0.0309 *  
## female      -1.81085    0.26483  -6.838 2.26e-11 ***
## educ         0.57150    0.04934  11.584  &lt; 2e-16 ***
## exper        0.02540    0.01157   2.195   0.0286 *  
## tenure       0.14101    0.02116   6.663 6.83e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.958 on 521 degrees of freedom
## Multiple R-squared:  0.3635, Adjusted R-squared:  0.3587 
## F-statistic:  74.4 on 4 and 521 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>On average a women makes $ 2 per less than a man with the <em>same</em> education, experience, and tenure.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="linearregression.html#cb230-1"></a>lm2_wage1 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(wage)<span class="op">~</span>married<span class="op">*</span>female<span class="op">+</span>educ<span class="op">+</span>exper<span class="op">+</span><span class="kw">I</span>(exper<span class="op">^</span><span class="dv">2</span>)<span class="op">+</span>tenure<span class="op">+</span><span class="kw">I</span>(tenure<span class="op">^</span><span class="dv">2</span>), <span class="dt">data=</span>wage1)</span>
<span id="cb230-2"><a href="linearregression.html#cb230-2"></a><span class="kw">summary</span>(lm2_wage1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(wage) ~ married * female + educ + exper + I(exper^2) + 
##     tenure + I(tenure^2), data = wage1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.89697 -0.24060 -0.02689  0.23144  1.09197 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     0.3213781  0.1000090   3.213 0.001393 ** 
## married         0.2126757  0.0553572   3.842 0.000137 ***
## female         -0.1103502  0.0557421  -1.980 0.048272 *  
## educ            0.0789103  0.0066945  11.787  &lt; 2e-16 ***
## exper           0.0268006  0.0052428   5.112 4.50e-07 ***
## I(exper^2)     -0.0005352  0.0001104  -4.847 1.66e-06 ***
## tenure          0.0290875  0.0067620   4.302 2.03e-05 ***
## I(tenure^2)    -0.0005331  0.0002312  -2.306 0.021531 *  
## married:female -0.3005931  0.0717669  -4.188 3.30e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3933 on 517 degrees of freedom
## Multiple R-squared:  0.4609, Adjusted R-squared:  0.4525 
## F-statistic: 55.25 on 8 and 517 DF,  p-value: &lt; 2.2e-16</code></pre>
<hr />
<p><strong>Your turn</strong></p>
<ol style="list-style-type: decimal">
<li>What is the reference group in this model?</li>
<li>Ceteris paribus, how much more wage do single males make relative to the reference group?</li>
<li>Ceteris paribus, how much more wage do single females make relative to the reference group?</li>
<li>Ceteris paribus, how much less do married females make than single females?</li>
<li>Do the results make sense economically. What socio-economic factors could explain the results?</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="linearregression.html#cb232-1"></a>df_lm2_wage1 &lt;-<span class="st"> </span><span class="kw">tidy</span>(lm2_wage1)</span>
<span id="cb232-2"><a href="linearregression.html#cb232-2"></a><span class="co"># Singe male</span></span>
<span id="cb232-3"><a href="linearregression.html#cb232-3"></a>marriedmale &lt;-<span class="st"> </span>df_lm2_wage1 <span class="op">%&gt;%</span></span>
<span id="cb232-4"><a href="linearregression.html#cb232-4"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;married&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb232-5"><a href="linearregression.html#cb232-5"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(estimate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb232-6"><a href="linearregression.html#cb232-6"></a><span class="st">  </span><span class="kw">pull</span>() <span class="co"># pull out the single coefficient value of the dataframe</span></span>
<span id="cb232-7"><a href="linearregression.html#cb232-7"></a><span class="co"># Single female</span></span>
<span id="cb232-8"><a href="linearregression.html#cb232-8"></a>singlefemale &lt;-<span class="st"> </span>df_lm2_wage1 <span class="op">%&gt;%</span></span>
<span id="cb232-9"><a href="linearregression.html#cb232-9"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;female&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb232-10"><a href="linearregression.html#cb232-10"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(estimate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb232-11"><a href="linearregression.html#cb232-11"></a><span class="st">  </span><span class="kw">pull</span>() <span class="co"># pull out the single coefficient value of the dataframe</span></span>
<span id="cb232-12"><a href="linearregression.html#cb232-12"></a>marriedfemale &lt;-<span class="st"> </span>df_lm2_wage1 <span class="op">%&gt;%</span></span>
<span id="cb232-13"><a href="linearregression.html#cb232-13"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;married:female&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb232-14"><a href="linearregression.html#cb232-14"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(estimate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb232-15"><a href="linearregression.html#cb232-15"></a><span class="st">  </span><span class="kw">pull</span>() <span class="co"># pull out the single coefficient value of the dataframe</span></span>
<span id="cb232-16"><a href="linearregression.html#cb232-16"></a>married&lt;-<span class="st"> </span>df_lm2_wage1 <span class="op">%&gt;%</span></span>
<span id="cb232-17"><a href="linearregression.html#cb232-17"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;married&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co">#  </span></span>
<span id="cb232-18"><a href="linearregression.html#cb232-18"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(estimate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb232-19"><a href="linearregression.html#cb232-19"></a><span class="st">  </span><span class="kw">pull</span>() <span class="co"># pull out the single coefficient value of the dataframe</span></span></code></pre></div>
<p>A:</p>
<ol style="list-style-type: decimal">
<li>Reference group: <em>single</em> and <em>male</em></li>
<li>Cp. married males make 21.3% (<code>percent(marriedmale)</code>) more than single males.</li>
<li>Cp. a single female makes -11.0% (<code>percent(singlefemale)</code>) less than the reference group.</li>
<li>Married females make 8.79% (<code>percent(abs(marriedfemale) - abs(married))</code>) less than single females.</li>
<li>There seems to be a marriage premium for men but for women the marriage premium is negative.</li>
</ol>
<hr />
</div>
<div id="logical-variables" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Logical variables</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="linearregression.html#cb233-1"></a><span class="co"># replace &quot;female&quot; with logical variable</span></span>
<span id="cb233-2"><a href="linearregression.html#cb233-2"></a>wage1<span class="op">$</span>female &lt;-<span class="st"> </span><span class="kw">as.logical</span>(wage1<span class="op">$</span>female)</span>
<span id="cb233-3"><a href="linearregression.html#cb233-3"></a><span class="kw">table</span>(wage1<span class="op">$</span>female)</span></code></pre></div>
<pre><code>## 
## FALSE  TRUE 
##   274   252</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="linearregression.html#cb235-1"></a><span class="co"># regression with logical variable</span></span>
<span id="cb235-2"><a href="linearregression.html#cb235-2"></a><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span>female<span class="op">+</span>educ<span class="op">+</span>exper<span class="op">+</span>tenure, <span class="dt">data=</span>wage1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = wage ~ female + educ + exper + tenure, data = wage1)
## 
## Coefficients:
## (Intercept)   femaleTRUE         educ        exper       tenure  
##     -1.5679      -1.8109       0.5715       0.0254       0.1410</code></pre>
</div>
<div id="factor-variables" class="section level3">
<h3><span class="header-section-number">1.3.3</span> Factor variables</h3>
<p>As discussed in the R introduction, categorical variables encoded as factors are special <em>animals</em> in R. They are immensely useful in a regression when you have a categorical variable with many levels (e.g. “Very Bad”, “Bad”, “Good”, “Very Good”) but can create a set of subtle issues. Here, we discuss the base R way and the more robust tidyverse way of dealing with factors in the area of regression modelling.</p>
<p>Factor variables can be directly added to the list of regressors. R is clever enough to implicitly add <span class="math inline">\(g-1\)</span> dummy variables if the factor has <span class="math inline">\(g\)</span> outcomes.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="linearregression.html#cb237-1"></a><span class="kw">data</span>(CPS1985,<span class="dt">package=</span><span class="st">&quot;AER&quot;</span>)</span>
<span id="cb237-2"><a href="linearregression.html#cb237-2"></a><span class="kw">str</span>(CPS1985)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    534 obs. of  11 variables:
##  $ wage      : num  5.1 4.95 6.67 4 7.5 ...
##  $ education : num  8 9 12 12 12 13 10 12 16 12 ...
##  $ experience: num  21 42 1 4 17 9 27 9 11 9 ...
##  $ age       : num  35 57 19 22 35 28 43 27 33 27 ...
##  $ ethnicity : Factor w/ 3 levels &quot;cauc&quot;,&quot;hispanic&quot;,..: 2 1 1 1 1 1 1 1 1 1 ...
##  $ region    : Factor w/ 2 levels &quot;south&quot;,&quot;other&quot;: 2 2 2 2 2 2 1 2 2 2 ...
##  $ gender    : Factor w/ 2 levels &quot;male&quot;,&quot;female&quot;: 2 2 1 1 1 1 1 1 1 1 ...
##  $ occupation: Factor w/ 6 levels &quot;worker&quot;,&quot;technical&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ sector    : Factor w/ 3 levels &quot;manufacturing&quot;,..: 1 1 1 3 3 3 3 3 1 3 ...
##  $ union     : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 2 1 1 1 1 ...
##  $ married   : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 1 1 2 1 1 1 2 1 ...</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="linearregression.html#cb239-1"></a><span class="co"># Table of categories and frequencies for two factor variables:</span></span>
<span id="cb239-2"><a href="linearregression.html#cb239-2"></a><span class="kw">table</span>(CPS1985<span class="op">$</span>gender)</span></code></pre></div>
<pre><code>## 
##   male female 
##    289    245</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="linearregression.html#cb241-1"></a><span class="kw">table</span>(CPS1985<span class="op">$</span>occupation)</span></code></pre></div>
<pre><code>## 
##     worker  technical   services     office      sales management 
##        156        105         83         97         38         55</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="linearregression.html#cb243-1"></a><span class="kw">levels</span>(CPS1985<span class="op">$</span>occupation)</span></code></pre></div>
<pre><code>## [1] &quot;worker&quot;     &quot;technical&quot;  &quot;services&quot;   &quot;office&quot;     &quot;sales&quot;     
## [6] &quot;management&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="linearregression.html#cb245-1"></a><span class="kw">levels</span>(CPS1985<span class="op">$</span>gender)</span></code></pre></div>
<pre><code>## [1] &quot;male&quot;   &quot;female&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="linearregression.html#cb247-1"></a><span class="co"># Directly using factor variables in regression formula:</span></span>
<span id="cb247-2"><a href="linearregression.html#cb247-2"></a><span class="kw">lm</span>(<span class="kw">log</span>(wage) <span class="op">~</span><span class="st"> </span>education<span class="op">+</span>experience<span class="op">+</span>gender<span class="op">+</span>occupation, <span class="dt">data=</span>CPS1985)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(wage) ~ education + experience + gender + occupation, 
##     data = CPS1985)
## 
## Coefficients:
##          (Intercept)             education            experience  
##              0.97629               0.07586               0.01188  
##         genderfemale   occupationtechnical    occupationservices  
##             -0.22385               0.14246              -0.21004  
##     occupationoffice       occupationsales  occupationmanagement  
##             -0.05477              -0.20757               0.15254</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="linearregression.html#cb249-1"></a><span class="co"># Fragile method (base R)</span></span>
<span id="cb249-2"><a href="linearregression.html#cb249-2"></a><span class="co"># Manually redefine the  reference category: </span></span>
<span id="cb249-3"><a href="linearregression.html#cb249-3"></a>CPS1985<span class="op">$</span>gender &lt;-<span class="st"> </span><span class="kw">relevel</span>(CPS1985<span class="op">$</span>gender,<span class="st">&quot;female&quot;</span>)</span>
<span id="cb249-4"><a href="linearregression.html#cb249-4"></a>CPS1985<span class="op">$</span>occupation &lt;-<span class="st"> </span><span class="kw">relevel</span>(CPS1985<span class="op">$</span>occupation,<span class="st">&quot;management&quot;</span>)</span>
<span id="cb249-5"><a href="linearregression.html#cb249-5"></a></span>
<span id="cb249-6"><a href="linearregression.html#cb249-6"></a><span class="co"># Rerun regression:</span></span>
<span id="cb249-7"><a href="linearregression.html#cb249-7"></a><span class="kw">lm</span>(<span class="kw">log</span>(wage) <span class="op">~</span><span class="st"> </span>education<span class="op">+</span>experience<span class="op">+</span>gender<span class="op">+</span>occupation, <span class="dt">data=</span>CPS1985)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(wage) ~ education + experience + gender + occupation, 
##     data = CPS1985)
## 
## Coefficients:
##         (Intercept)            education           experience  
##             0.90498              0.07586              0.01188  
##          gendermale     occupationworker  occupationtechnical  
##             0.22385             -0.15254             -0.01009  
##  occupationservices     occupationoffice      occupationsales  
##            -0.36259             -0.20731             -0.36011</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="linearregression.html#cb251-1"></a><span class="co"># Robust method (tidyverse)</span></span>
<span id="cb251-2"><a href="linearregression.html#cb251-2"></a><span class="co"># Manually redefine the  reference category (back to default): </span></span>
<span id="cb251-3"><a href="linearregression.html#cb251-3"></a>CPS1985 &lt;-<span class="st"> </span>CPS1985 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb251-4"><a href="linearregression.html#cb251-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">gender =</span> <span class="kw">fct_relevel</span>(gender, <span class="st">&quot;female&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb251-5"><a href="linearregression.html#cb251-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">occupation =</span> <span class="kw">fct_relevel</span>(occupation, <span class="st">&quot;worker&quot;</span>))</span>
<span id="cb251-6"><a href="linearregression.html#cb251-6"></a></span>
<span id="cb251-7"><a href="linearregression.html#cb251-7"></a><span class="kw">lm</span>(<span class="kw">log</span>(wage) <span class="op">~</span><span class="st"> </span>education<span class="op">+</span>experience<span class="op">+</span>gender<span class="op">+</span>occupation, <span class="dt">data=</span>CPS1985)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(wage) ~ education + experience + gender + occupation, 
##     data = CPS1985)
## 
## Coefficients:
##          (Intercept)             education            experience  
##              0.75244               0.07586               0.01188  
##           gendermale  occupationmanagement   occupationtechnical  
##              0.22385               0.15254               0.14246  
##   occupationservices      occupationoffice       occupationsales  
##             -0.21004              -0.05477              -0.20757</code></pre>
<div id="breaking-a-numeric-variable-into-categories" class="section level4">
<h4><span class="header-section-number">1.3.3.1</span> Breaking a numeric variable into categories</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="linearregression.html#cb253-1"></a><span class="kw">data</span>(lawsch85)</span>
<span id="cb253-2"><a href="linearregression.html#cb253-2"></a><span class="kw">str</span>(lawsch85<span class="op">$</span>rank)</span></code></pre></div>
<pre><code>##  int [1:156] 128 104 34 49 95 98 124 157 145 91 ...</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="linearregression.html#cb255-1"></a><span class="co"># Define cut points for the rank</span></span>
<span id="cb255-2"><a href="linearregression.html#cb255-2"></a>cutpts &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">25</span>,<span class="dv">40</span>,<span class="dv">60</span>,<span class="dv">100</span>,<span class="dv">175</span>)</span>
<span id="cb255-3"><a href="linearregression.html#cb255-3"></a></span>
<span id="cb255-4"><a href="linearregression.html#cb255-4"></a><span class="co"># Create factor variable containing ranges for the rank</span></span>
<span id="cb255-5"><a href="linearregression.html#cb255-5"></a>lawsch85<span class="op">$</span>rankcat &lt;-<span class="st"> </span><span class="kw">cut</span>(lawsch85<span class="op">$</span>rank, cutpts)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="linearregression.html#cb256-1"></a><span class="co"># Display frequencies</span></span>
<span id="cb256-2"><a href="linearregression.html#cb256-2"></a><span class="kw">table</span>(lawsch85<span class="op">$</span>rankcat)</span></code></pre></div>
<pre><code>## 
##    (0,10]   (10,25]   (25,40]   (40,60]  (60,100] (100,175] 
##        10        16        13        18        37        62</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="linearregression.html#cb258-1"></a><span class="co"># Choose reference category</span></span>
<span id="cb258-2"><a href="linearregression.html#cb258-2"></a>lawsch85<span class="op">$</span>rankcat &lt;-<span class="st"> </span><span class="kw">relevel</span>(lawsch85<span class="op">$</span>rankcat,<span class="st">&quot;(100,175]&quot;</span>)</span>
<span id="cb258-3"><a href="linearregression.html#cb258-3"></a></span>
<span id="cb258-4"><a href="linearregression.html#cb258-4"></a><span class="co"># Run regression</span></span>
<span id="cb258-5"><a href="linearregression.html#cb258-5"></a>res &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(salary)<span class="op">~</span>rankcat<span class="op">+</span>LSAT<span class="op">+</span>GPA<span class="op">+</span><span class="kw">log</span>(libvol)<span class="op">+</span><span class="kw">log</span>(cost), <span class="dt">data=</span>lawsch85)</span></code></pre></div>
<p>We can perform an Anova test on the regression object</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="linearregression.html#cb259-1"></a><span class="co"># ANOVA table</span></span>
<span id="cb259-2"><a href="linearregression.html#cb259-2"></a>car<span class="op">::</span><span class="kw">Anova</span>(res)</span></code></pre></div>
<table class="huxtable" style="border-collapse: collapse; margin-bottom: 2em; margin-top: 2em; width: 68.8888888888889%; margin-left: 0%; margin-right: auto;  ">
<col><col><col><col><tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Sum Sq</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Df</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">F value</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Pr(&gt;F)</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1.87&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">5</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">51&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1.17e-28</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">0.0253&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">1</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">3.45&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.0655&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.000251</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.0342&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.854&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">0.0143&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">1</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">1.95&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.165&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">8.21e-06</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.00112</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.973&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">0.924&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">126</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
</table>

<p>The regression results imply that graduates from the top 100 schools collect a starting salary which is around 70% higher than those of the schools below rank 100. This approximation is inaccurate with these large numbers and the coefficient of 0.7 actually implies a difference of ex(0.7-1) = 1.103 or 101.3%.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="linearregression.html#cb260-1"></a><span class="co"># Robust method (tidyverse)</span></span>
<span id="cb260-2"><a href="linearregression.html#cb260-2"></a><span class="co"># Manually redefine the  reference category (back to default): </span></span>
<span id="cb260-3"><a href="linearregression.html#cb260-3"></a>CPS1985 &lt;-<span class="st"> </span>CPS1985 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb260-4"><a href="linearregression.html#cb260-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">gender =</span> <span class="kw">fct_relevel</span>(gender, <span class="st">&quot;female&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb260-5"><a href="linearregression.html#cb260-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">occupation =</span> <span class="kw">fct_relevel</span>(occupation, <span class="st">&quot;worker&quot;</span>))</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="linearregression.html#cb261-1"></a><span class="kw">lm</span>(<span class="kw">log</span>(wage) <span class="op">~</span><span class="st"> </span>education<span class="op">+</span>experience<span class="op">+</span>gender<span class="op">+</span>occupation, <span class="dt">data=</span>CPS1985)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(wage) ~ education + experience + gender + occupation, 
##     data = CPS1985)
## 
## Coefficients:
##          (Intercept)             education            experience  
##              0.75244               0.07586               0.01188  
##           gendermale  occupationmanagement   occupationtechnical  
##              0.22385               0.15254               0.14246  
##   occupationservices      occupationoffice       occupationsales  
##             -0.21004              -0.05477              -0.20757</code></pre>
</div>
<div id="breaking-a-numeric-variable-into-categories-1" class="section level4">
<h4><span class="header-section-number">1.3.3.2</span> Breaking a numeric variable into categories</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="linearregression.html#cb263-1"></a><span class="kw">data</span>(lawsch85)</span>
<span id="cb263-2"><a href="linearregression.html#cb263-2"></a><span class="kw">str</span>(lawsch85<span class="op">$</span>rank)</span></code></pre></div>
<pre><code>##  int [1:156] 128 104 34 49 95 98 124 157 145 91 ...</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="linearregression.html#cb265-1"></a><span class="co"># Define cut points for the rank</span></span>
<span id="cb265-2"><a href="linearregression.html#cb265-2"></a>cutpts &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">25</span>,<span class="dv">40</span>,<span class="dv">60</span>,<span class="dv">100</span>,<span class="dv">175</span>)</span>
<span id="cb265-3"><a href="linearregression.html#cb265-3"></a></span>
<span id="cb265-4"><a href="linearregression.html#cb265-4"></a><span class="co"># Create factor variable containing ranges for the rank</span></span>
<span id="cb265-5"><a href="linearregression.html#cb265-5"></a>lawsch85<span class="op">$</span>rankcat &lt;-<span class="st"> </span><span class="kw">cut</span>(lawsch85<span class="op">$</span>rank, cutpts)</span>
<span id="cb265-6"><a href="linearregression.html#cb265-6"></a></span>
<span id="cb265-7"><a href="linearregression.html#cb265-7"></a><span class="co"># Display frequencies</span></span>
<span id="cb265-8"><a href="linearregression.html#cb265-8"></a><span class="kw">table</span>(lawsch85<span class="op">$</span>rankcat)</span></code></pre></div>
<pre><code>## 
##    (0,10]   (10,25]   (25,40]   (40,60]  (60,100] (100,175] 
##        10        16        13        18        37        62</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="linearregression.html#cb267-1"></a><span class="co"># Choose reference category</span></span>
<span id="cb267-2"><a href="linearregression.html#cb267-2"></a>lawsch85<span class="op">$</span>rankcat &lt;-<span class="st"> </span><span class="kw">relevel</span>(lawsch85<span class="op">$</span>rankcat,<span class="st">&quot;(100,175]&quot;</span>)</span>
<span id="cb267-3"><a href="linearregression.html#cb267-3"></a></span>
<span id="cb267-4"><a href="linearregression.html#cb267-4"></a><span class="co"># Run regression</span></span>
<span id="cb267-5"><a href="linearregression.html#cb267-5"></a>(res &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(salary)<span class="op">~</span>rankcat<span class="op">+</span>LSAT<span class="op">+</span>GPA<span class="op">+</span><span class="kw">log</span>(libvol)<span class="op">+</span><span class="kw">log</span>(cost), <span class="dt">data=</span>lawsch85))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(salary) ~ rankcat + LSAT + GPA + log(libvol) + 
##     log(cost), data = lawsch85)
## 
## Coefficients:
##     (Intercept)    rankcat(0,10]   rankcat(10,25]   rankcat(25,40]  
##       9.1652952        0.6995659        0.5935434        0.3750763  
##  rankcat(40,60]  rankcat(60,100]             LSAT              GPA  
##       0.2628191        0.1315950        0.0056908        0.0137255  
##     log(libvol)        log(cost)  
##       0.0363619        0.0008412</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="linearregression.html#cb269-1"></a><span class="co"># ANOVA table</span></span>
<span id="cb269-2"><a href="linearregression.html#cb269-2"></a>car<span class="op">::</span><span class="kw">Anova</span>(res)</span></code></pre></div>
<table class="huxtable" style="border-collapse: collapse; margin-bottom: 2em; margin-top: 2em; width: 68.8888888888889%; margin-left: 0%; margin-right: auto;  ">
<col><col><col><col><tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Sum Sq</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Df</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">F value</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Pr(&gt;F)</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1.87&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">5</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">51&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1.17e-28</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">0.0253&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">1</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">3.45&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.0655&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.000251</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.0342&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.854&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">0.0143&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt;">1</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">1.95&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.165&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">8.21e-06</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.00112</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.973&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">0.924&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">126</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
</table>

<p>The regression results imply that graduates from the top 100 schools collect a starting salary which is around 70% higher than those of the schools below rank 100. This approximation is inaccurate with these large numbers and the coefficient of 0.7 actually implies a difference of ex(0.7-1) = 1.103 or 101.3%.</p>
</div>
</div>
<div id="interactions-and-differences-in-regression-functions-across-groups" class="section level3">
<h3><span class="header-section-number">1.3.4</span> Interactions and differences in regression functions across groups</h3>
<p>Dummy variables and factor variables can be interacted just like any other variable</p>
<ul>
<li>Use the <em>subset</em> option of <code>lm()</code> to directly define the estimation sample</li>
<li>The dummy variable <em>female</em> is interacted with all other regressor</li>
<li>The F test for all interaction effects is performed using the function <code>linearHypothesis()</code> from the <strong>car</strong> package</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="linearregression.html#cb270-1"></a><span class="kw">data</span>(gpa3)</span>
<span id="cb270-2"><a href="linearregression.html#cb270-2"></a></span>
<span id="cb270-3"><a href="linearregression.html#cb270-3"></a><span class="co"># Model with full interactions with female dummy (only for spring data)</span></span>
<span id="cb270-4"><a href="linearregression.html#cb270-4"></a>reg&lt;-<span class="kw">lm</span>(cumgpa<span class="op">~</span>female<span class="op">*</span>(sat<span class="op">+</span>hsperc<span class="op">+</span>tothrs), <span class="dt">data=</span>gpa3, <span class="dt">subset=</span>(spring<span class="op">==</span><span class="dv">1</span>))</span>
<span id="cb270-5"><a href="linearregression.html#cb270-5"></a><span class="kw">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = cumgpa ~ female * (sat + hsperc + tothrs), data = gpa3, 
##     subset = (spring == 1))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.51370 -0.28645 -0.02306  0.27555  1.24760 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    1.4808117  0.2073336   7.142 5.17e-12 ***
## female        -0.3534862  0.4105293  -0.861  0.38979    
## sat            0.0010516  0.0001811   5.807 1.40e-08 ***
## hsperc        -0.0084516  0.0013704  -6.167 1.88e-09 ***
## tothrs         0.0023441  0.0008624   2.718  0.00688 ** 
## female:sat     0.0007506  0.0003852   1.949  0.05211 .  
## female:hsperc -0.0005498  0.0031617  -0.174  0.86206    
## female:tothrs -0.0001158  0.0016277  -0.071  0.94331    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4678 on 358 degrees of freedom
## Multiple R-squared:  0.4059, Adjusted R-squared:  0.3943 
## F-statistic: 34.95 on 7 and 358 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="linearregression.html#cb272-1"></a><span class="co"># F-Test from package &quot;car&quot;. H0: the interaction coefficients are zero</span></span>
<span id="cb272-2"><a href="linearregression.html#cb272-2"></a><span class="co"># matchCoefs(...) selects all coeffs with names containing &quot;female&quot;</span></span>
<span id="cb272-3"><a href="linearregression.html#cb272-3"></a></span>
<span id="cb272-4"><a href="linearregression.html#cb272-4"></a><span class="kw">linearHypothesis</span>(reg, <span class="kw">matchCoefs</span>(reg, <span class="st">&quot;female&quot;</span>))</span></code></pre></div>
<table class="huxtable" style="border-collapse: collapse; margin-bottom: 2em; margin-top: 2em; width: 80%; margin-left: 0%; margin-right: auto;  ">
<col><col><col><col><col><col><tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Res.Df</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">RSS</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Df</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Sum of Sq</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">F</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Pr(&gt;F)</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">362</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">85.5</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);"></td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">358</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">78.4</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">4</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">7.16</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">8.18</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">2.54e-06</td>
</tr>
</table>

<p>As the p-value is much less than 0.05, we reject the null that the interaction with female dummy is statistically insignificant.</p>
<div id="visualizing-coefficients" class="section level4">
<h4><span class="header-section-number">1.3.4.1</span> Visualizing coefficients</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="linearregression.html#cb273-1"></a>treg &lt;-<span class="st"> </span><span class="kw">tidy</span>(reg, <span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="linearregression.html#cb274-1"></a><span class="kw">ggplot</span>(treg, <span class="kw">aes</span>(estimate, term, <span class="dt">color =</span> term)) <span class="op">+</span></span>
<span id="cb274-2"><a href="linearregression.html#cb274-2"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb274-3"><a href="linearregression.html#cb274-3"></a><span class="st">  </span><span class="kw">geom_errorbarh</span>(<span class="kw">aes</span>(<span class="dt">xmin =</span> conf.low, <span class="dt">xmax =</span> conf.high))  <span class="op">+</span></span>
<span id="cb274-4"><a href="linearregression.html#cb274-4"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span> <span class="st">&quot;grey&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig17"></span>
<img src="MEM5220_R_files/figure-html/fig17-1.png" alt="Coefficient plots" width="80%" />
<p class="caption">
Figure 1.21: Coefficient plots
</p>
</div>
<p>To recap, the general form in which we specify regression models in R:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="linearregression.html#cb275-1"></a><span class="co">## response ~ terms</span></span>
<span id="cb275-2"><a href="linearregression.html#cb275-2"></a><span class="co">## </span></span>
<span id="cb275-3"><a href="linearregression.html#cb275-3"></a><span class="co">## y ~ age + sex            # age + sex main effects</span></span>
<span id="cb275-4"><a href="linearregression.html#cb275-4"></a><span class="co">## y ~ age + sex + age:sex  # add second-order interaction</span></span>
<span id="cb275-5"><a href="linearregression.html#cb275-5"></a><span class="co">## y ~ age*sex              # second-order interaction +</span></span>
<span id="cb275-6"><a href="linearregression.html#cb275-6"></a><span class="co">##                          # all main effects</span></span>
<span id="cb275-7"><a href="linearregression.html#cb275-7"></a><span class="co">## y ~ (age + sex + pressure)^2</span></span>
<span id="cb275-8"><a href="linearregression.html#cb275-8"></a><span class="co">##                          # age+sex+pressure+age:sex+age:pressure...</span></span>
<span id="cb275-9"><a href="linearregression.html#cb275-9"></a><span class="co">## y ~ (age + sex + pressure)^2 - sex:pressure</span></span>
<span id="cb275-10"><a href="linearregression.html#cb275-10"></a><span class="co">##                          # all main effects and all 2nd order</span></span>
<span id="cb275-11"><a href="linearregression.html#cb275-11"></a><span class="co">##                          # interactions except sex:pressure</span></span>
<span id="cb275-12"><a href="linearregression.html#cb275-12"></a><span class="co">## y ~ (age + race)*sex     # age+race+sex+age:sex+race:sex</span></span>
<span id="cb275-13"><a href="linearregression.html#cb275-13"></a><span class="co">## y ~ treatment*(age*race + age*sex) # no interact. with race,sex</span></span>
<span id="cb275-14"><a href="linearregression.html#cb275-14"></a><span class="co">## sqrt(y) ~ sex*sqrt(age) + race</span></span>
<span id="cb275-15"><a href="linearregression.html#cb275-15"></a><span class="co">## # functions, with dummy variables generated if</span></span>
<span id="cb275-16"><a href="linearregression.html#cb275-16"></a><span class="co">## # race is an R factor (classification) variable</span></span>
<span id="cb275-17"><a href="linearregression.html#cb275-17"></a><span class="co">## y ~ sex + poly(age,2)    # poly generates orthogonal polynomials</span></span>
<span id="cb275-18"><a href="linearregression.html#cb275-18"></a><span class="co">## race.sex &lt;- interaction(race,sex)</span></span>
<span id="cb275-19"><a href="linearregression.html#cb275-19"></a><span class="co">## y ~ age + race.sex       # for when you want dummy variables for</span></span>
<span id="cb275-20"><a href="linearregression.html#cb275-20"></a><span class="co">##                          # all combinations of the factors</span></span></code></pre></div>
</div>
</div>
</div>
<div id="heteroskedasticity" class="section level2">
<h2><span class="header-section-number">1.4</span> Heteroskedasticity</h2>
<p>The homoskedasticity assumptions SLR.5 and MLR.5 require that the variance of the error term is unrelated to the regressors, i.e.</p>
<p><span class="math display">\[\begin{equation}
Var(u|x_1, \dots , x_n) = \sigma^2  
\end{equation}\]</span></p>
<p>Unbiasedness and consistency do not depend on this assumption, but the sampling distribution does. If homoskedasticity is violated, the standard errors are invalid and all inferences from <span class="math inline">\(t\)</span>, <span class="math inline">\(F\)</span>, and other tests based on them are unreliable.</p>
<p>There are various ways of dealing with heteroskedasticity in R. The <strong>car</strong> package provides linear hypothesis.
For high-dimensional fixed effects the <strong>lfe</strong> package is a good alternative. It also allows to specify clusters as part of the formula.
A good balance between functionality and ease of use is provided by the <strong>sandwich</strong> package <span class="citation">Zeileis et al. (<a href="#ref-Zeileis2017" role="doc-biblioref">2017</a>)</span>.</p>
<div id="spotting-heteroskedasticity-in-scatter-plots" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Spotting Heteroskedasticity in Scatter Plots</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="linearregression.html#cb276-1"></a><span class="kw">data</span>(<span class="st">&quot;food&quot;</span>,<span class="dt">package=</span><span class="st">&quot;PoEdata&quot;</span>)</span>
<span id="cb276-2"><a href="linearregression.html#cb276-2"></a>mod1 &lt;-<span class="st"> </span><span class="kw">lm</span>(food_exp<span class="op">~</span>income, <span class="dt">data=</span>food)</span>
<span id="cb276-3"><a href="linearregression.html#cb276-3"></a><span class="kw">plot</span>(food<span class="op">$</span>income,food<span class="op">$</span>food_exp, <span class="dt">type=</span><span class="st">&quot;p&quot;</span>,</span>
<span id="cb276-4"><a href="linearregression.html#cb276-4"></a>     <span class="dt">xlab=</span><span class="st">&quot;income&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;food expenditure&quot;</span>)</span>
<span id="cb276-5"><a href="linearregression.html#cb276-5"></a><span class="kw">abline</span>(mod1)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig18"></span>
<img src="MEM5220_R_files/figure-html/fig18-1.png" alt="Heteroskedasticity in the ‘food’ data" width="80%" />
<p class="caption">
Figure 1.22: Heteroskedasticity in the ‘food’ data
</p>
</div>
<p>Another useful method to visualize possible heteroskedasticity is to plot the residuals against the regressors suspected of creating heteroskedasticity, or, more generally, against the fitted values of the regression.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="linearregression.html#cb277-1"></a>res &lt;-<span class="st"> </span><span class="kw">residuals</span>(mod1)</span>
<span id="cb277-2"><a href="linearregression.html#cb277-2"></a>yhat &lt;-<span class="st"> </span><span class="kw">fitted</span>(mod1)</span>
<span id="cb277-3"><a href="linearregression.html#cb277-3"></a><span class="kw">plot</span>(food<span class="op">$</span>income,res, <span class="dt">xlab=</span><span class="st">&quot;income&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;residuals&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig191"></span>
<img src="MEM5220_R_files/figure-html/fig19-1.png" alt="Residual plots in the ‘food’ model " width="80%" />
<p class="caption">
Figure 1.23: Residual plots in the ‘food’ model
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="linearregression.html#cb278-1"></a><span class="kw">plot</span>(yhat,res, <span class="dt">xlab=</span><span class="st">&quot;fitted values&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;residuals&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig192"></span>
<img src="MEM5220_R_files/figure-html/fig19-2.png" alt="Residual plots in the ‘food’ model " width="80%" />
<p class="caption">
Figure 1.24: Residual plots in the ‘food’ model
</p>
</div>
</div>
<div id="heteroskedasticity-tests" class="section level3">
<h3><span class="header-section-number">1.4.2</span> Heteroskedasticity Tests</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="linearregression.html#cb279-1"></a><span class="kw">data</span>(gpa3, <span class="dt">package=</span><span class="st">&#39;wooldridge&#39;</span>)</span>
<span id="cb279-2"><a href="linearregression.html#cb279-2"></a></span>
<span id="cb279-3"><a href="linearregression.html#cb279-3"></a></span>
<span id="cb279-4"><a href="linearregression.html#cb279-4"></a><span class="co"># Estimate model (only for spring data)</span></span>
<span id="cb279-5"><a href="linearregression.html#cb279-5"></a>reg &lt;-<span class="st"> </span><span class="kw">lm</span>(cumgpa<span class="op">~</span>sat<span class="op">+</span>hsperc<span class="op">+</span>tothrs<span class="op">+</span>female<span class="op">+</span>black<span class="op">+</span>white, </span>
<span id="cb279-6"><a href="linearregression.html#cb279-6"></a>          <span class="dt">data=</span>gpa3, <span class="dt">subset=</span>(spring<span class="op">==</span><span class="dv">1</span>))</span>
<span id="cb279-7"><a href="linearregression.html#cb279-7"></a></span>
<span id="cb279-8"><a href="linearregression.html#cb279-8"></a></span>
<span id="cb279-9"><a href="linearregression.html#cb279-9"></a><span class="co"># Breusch-Pagan (BP) Test</span></span>
<span id="cb279-10"><a href="linearregression.html#cb279-10"></a></span>
<span id="cb279-11"><a href="linearregression.html#cb279-11"></a><span class="kw">bptest</span>(reg)</span></code></pre></div>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  reg
## BP = 44.557, df = 6, p-value = 5.732e-08</code></pre>
<p>The R function that does this job is <code>hccm()</code>, which is part of the car package and yields a heteroskedasticity-robust coefficient covariance matrix. This matrix can then be used with other functions, such as <code>coeftest()</code> (instead of summary), <code>waldtest()</code> (instead of anova), or <code>linearHypothesis()</code> to perform hypothesis testing. The function <code>hccm()</code> takes several arguments, among which is the model for which we want the robust standard errors and the type of standard errors we wish to calculate.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="linearregression.html#cb281-1"></a><span class="co"># Usual SE:</span></span>
<span id="cb281-2"><a href="linearregression.html#cb281-2"></a><span class="kw">coeftest</span>(reg)</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  1.47006477  0.22980308  6.3971 4.942e-10 ***
## sat          0.00114073  0.00017856  6.3885 5.197e-10 ***
## hsperc      -0.00856636  0.00124042 -6.9060 2.275e-11 ***
## tothrs       0.00250400  0.00073099  3.4255 0.0006847 ***
## female       0.30343329  0.05902033  5.1412 4.497e-07 ***
## black       -0.12828368  0.14737012 -0.8705 0.3846164    
## white       -0.05872173  0.14098956 -0.4165 0.6772953    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="linearregression.html#cb283-1"></a><span class="co"># Refined White heteroscedasticity-robust SE:</span></span>
<span id="cb283-2"><a href="linearregression.html#cb283-2"></a><span class="kw">coeftest</span>(reg, <span class="dt">vcov=</span>hccm)</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  1.47006477  0.22938036  6.4089 4.611e-10 ***
## sat          0.00114073  0.00019532  5.8402 1.169e-08 ***
## hsperc      -0.00856636  0.00144359 -5.9341 6.963e-09 ***
## tothrs       0.00250400  0.00074930  3.3418   0.00092 ***
## female       0.30343329  0.06003964  5.0539 6.911e-07 ***
## black       -0.12828368  0.12818828 -1.0007   0.31762    
## white       -0.05872173  0.12043522 -0.4876   0.62615    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="linearregression.html#cb285-1"></a>cov3 &lt;-<span class="st"> </span><span class="kw">hccm</span>(reg, <span class="dt">type=</span><span class="st">&quot;hc3&quot;</span>) <span class="co"># hc3 is the standard method</span></span>
<span id="cb285-2"><a href="linearregression.html#cb285-2"></a>ref.HC3 &lt;-<span class="st"> </span><span class="kw">coeftest</span>(reg, <span class="dt">vcov.=</span>cov3)</span>
<span id="cb285-3"><a href="linearregression.html#cb285-3"></a></span>
<span id="cb285-4"><a href="linearregression.html#cb285-4"></a><span class="co"># Supply other White corrections</span></span>
<span id="cb285-5"><a href="linearregression.html#cb285-5"></a>cov1 &lt;-<span class="st"> </span><span class="kw">hccm</span>(reg, <span class="dt">type=</span><span class="st">&quot;hc1&quot;</span>)</span>
<span id="cb285-6"><a href="linearregression.html#cb285-6"></a>ref.HC1 &lt;-<span class="st"> </span><span class="kw">coeftest</span>(reg, <span class="dt">vcov.=</span>cov1)</span></code></pre></div>
<p>Another way of dealing with heteroskedasticity is to use the <code>lmrob()</code> function from the <strong>robustbase</strong> package<a href="references.html#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. This package is quite interesting, and offers quite a lot of functions for robust linear, and nonlinear, regression models. Running a robust linear regression is just the same as with <code>lm()</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="linearregression.html#cb286-1"></a>regrobfit &lt;-<span class="st"> </span><span class="kw">lmrob</span>(cumgpa<span class="op">~</span>sat<span class="op">+</span>hsperc<span class="op">+</span>tothrs<span class="op">+</span>female<span class="op">+</span>black<span class="op">+</span>white, </span>
<span id="cb286-2"><a href="linearregression.html#cb286-2"></a>                   <span class="dt">data=</span>gpa3, <span class="dt">subset=</span>(spring<span class="op">==</span><span class="dv">1</span>))</span>
<span id="cb286-3"><a href="linearregression.html#cb286-3"></a></span>
<span id="cb286-4"><a href="linearregression.html#cb286-4"></a><span class="kw">summary</span>(regrobfit)</span></code></pre></div>
<pre><code>## 
## Call:
## lmrob(formula = cumgpa ~ sat + hsperc + tothrs + female + black + white, 
##     data = gpa3, subset = (spring == 1))
##  \--&gt; method = &quot;MM&quot;
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.57535 -0.30124 -0.02834  0.26687  1.27950 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.4693758  0.2315018   6.347 6.62e-10 ***
## sat          0.0011185  0.0001953   5.727 2.17e-08 ***
## hsperc      -0.0079056  0.0014293  -5.531 6.14e-08 ***
## tothrs       0.0021841  0.0007750   2.818   0.0051 ** 
## female       0.3002542  0.0599150   5.011 8.50e-07 ***
## black       -0.1281927  0.1268974  -1.010   0.3131    
## white       -0.0305168  0.1181863  -0.258   0.7964    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Robust residual standard error: 0.4201 
## Multiple R-squared:  0.411,  Adjusted R-squared:  0.4012 
## Convergence in 15 IRWLS iterations
## 
## Robustness weights: 
##  22 weights are ~= 1. The remaining 344 ones are summarized as
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.1291  0.8670  0.9471  0.8933  0.9854  0.9987 
## Algorithmic parameters: 
##        tuning.chi                bb        tuning.psi        refine.tol 
##         1.548e+00         5.000e-01         4.685e+00         1.000e-07 
##           rel.tol         scale.tol         solve.tol       eps.outlier 
##         1.000e-07         1.000e-10         1.000e-07         2.732e-04 
##             eps.x warn.limit.reject warn.limit.meanrw 
##         2.601e-09         5.000e-01         5.000e-01 
##      nResample         max.it       best.r.s       k.fast.s          k.max 
##            500             50              2              1            200 
##    maxit.scale      trace.lev            mts     compute.rd fast.s.large.n 
##            200              0           1000              0           2000 
##                   psi           subsampling                   cov 
##            &quot;bisquare&quot;         &quot;nonsingular&quot;         &quot;.vcov.avar1&quot; 
## compute.outlier.stats 
##                  &quot;SM&quot; 
## seed : int(0)</code></pre>
<p>This however, gives you different estimates than when fitting a linear regression model. The estimates should be the same, only the standard errors should be different. This is because the estimation method is different, and is also robust to outlines (at least that’s my understanding, I haven’t read the theoretical papers behind the package yet).</p>
<p>Finally, it is also possible to bootstrap the standard errors. For this I will use the <code>bootstrap()</code> function from the modelr package:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="linearregression.html#cb288-1"></a>resamples &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb288-2"><a href="linearregression.html#cb288-2"></a></span>
<span id="cb288-3"><a href="linearregression.html#cb288-3"></a>boot_gpa3 &lt;-<span class="st"> </span>gpa3 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb288-4"><a href="linearregression.html#cb288-4"></a><span class="st">  </span>modelr<span class="op">::</span><span class="kw">bootstrap</span>(resamples)</span></code></pre></div>
<p>The column strap contains resamples of the original data. I will run my linear regression from before on each of the resamples:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="linearregression.html#cb289-1"></a>boot_lin_reg &lt;-<span class="st"> </span>boot_gpa3 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb289-2"><a href="linearregression.html#cb289-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">regressions =</span> </span>
<span id="cb289-3"><a href="linearregression.html#cb289-3"></a>           <span class="kw">map</span>(strap, </span>
<span id="cb289-4"><a href="linearregression.html#cb289-4"></a>               <span class="op">~</span><span class="kw">lm</span>(cumgpa<span class="op">~</span>sat<span class="op">+</span>hsperc<span class="op">+</span>tothrs<span class="op">+</span>female<span class="op">+</span>black<span class="op">+</span>white, </span>
<span id="cb289-5"><a href="linearregression.html#cb289-5"></a>                   <span class="dt">data=</span> . , <span class="dt">subset=</span>(spring<span class="op">==</span><span class="dv">1</span>)))</span>
<span id="cb289-6"><a href="linearregression.html#cb289-6"></a>  )</span></code></pre></div>
<p>We have added a new column called regressions which contains the linear regressions on each bootstrapped sample. Now, I will create a list of tidied regression results:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="linearregression.html#cb290-1"></a>tidied &lt;-<span class="st"> </span>boot_lin_reg <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb290-2"><a href="linearregression.html#cb290-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">tidy_lm =</span> </span>
<span id="cb290-3"><a href="linearregression.html#cb290-3"></a>           <span class="kw">map</span>(regressions, broom<span class="op">::</span>tidy))</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="linearregression.html#cb291-1"></a>tidied<span class="op">$</span>tidy_lm[[<span class="dv">1</span>]]</span></code></pre></div>
<table class="huxtable" style="border-collapse: collapse; margin-bottom: 2em; margin-top: 2em; width: 97.7777777777778%; margin-left: 0%; margin-right: auto;  ">
<col><col><col><col><col><tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">term</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">estimate</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">std.error</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">statistic</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">p.value</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">(Intercept)</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1.1&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.242&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">4.55</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">7.39e-06</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">sat</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.00112</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.000181</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">6.17</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">1.84e-09</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">hsperc</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.00704</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.00124&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-5.68</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">2.78e-08</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">tothrs</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.00288</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.000762</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">3.78</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.000184</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">female</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.532&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.0599&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">8.88</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">3.2e-17&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">black</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.164&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.148&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">1.1&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.271&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">white</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.199&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.141&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1.41</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.159&nbsp;&nbsp;&nbsp;</td>
</tr>
</table>

<pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="linearregression.html#cb292-1"></a>list_mods &lt;-<span class="st"> </span>tidied <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb292-2"><a href="linearregression.html#cb292-2"></a><span class="st">  </span><span class="kw">pull</span>(tidy_lm)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="linearregression.html#cb293-1"></a>mods_df &lt;-<span class="st"> </span><span class="kw">map2_df</span>(list_mods, </span>
<span id="cb293-2"><a href="linearregression.html#cb293-2"></a>                   <span class="kw">seq</span>(<span class="dv">1</span>, resamples), </span>
<span id="cb293-3"><a href="linearregression.html#cb293-3"></a>                   <span class="op">~</span><span class="kw">mutate</span>(.x, <span class="dt">resample =</span> .y))</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="linearregression.html#cb294-1"></a><span class="kw">head</span>(mods_df, <span class="dv">5</span>)</span></code></pre></div>
<table class="huxtable" style="border-collapse: collapse; margin-bottom: 2em; margin-top: 2em; width: 98.8888888888889%; margin-left: 0%; margin-right: auto;  ">
<col><col><col><col><col><col><tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">term</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">estimate</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">std.error</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">statistic</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">p.value</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">resample</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">(Intercept)</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1.1&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.242&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">4.55</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">7.39e-06</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">sat</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.00112</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.000181</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">6.17</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">1.84e-09</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">1</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">hsperc</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.00704</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.00124&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-5.68</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">2.78e-08</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">tothrs</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.00288</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.000762</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">3.78</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.000184</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">1</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">female</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.532&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.0599&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">8.88</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">3.2e-17&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1</td>
</tr>
</table>

<pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="linearregression.html#cb295-1"></a>r.std.error &lt;-<span class="st"> </span>mods_df <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb295-2"><a href="linearregression.html#cb295-2"></a><span class="st">  </span><span class="kw">group_by</span>(term) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb295-3"><a href="linearregression.html#cb295-3"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">r.std.error =</span> <span class="kw">sd</span>(estimate))</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="linearregression.html#cb296-1"></a>reg <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb296-2"><a href="linearregression.html#cb296-2"></a><span class="st">  </span>broom<span class="op">::</span><span class="kw">tidy</span>()   <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb296-3"><a href="linearregression.html#cb296-3"></a><span class="st">  </span><span class="kw">full_join</span>(r.std.error)</span></code></pre></div>
<pre><code>## Joining, by = &quot;term&quot;</code></pre>
<table class="huxtable" style="border-collapse: collapse; margin-bottom: 2em; margin-top: 2em; width: 100%; margin-left: 0%; margin-right: auto;  ">
<col><col><col><col><col><col><tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">term</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">estimate</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">std.error</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">statistic</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">p.value</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">r.std.error</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">(Intercept)</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">1.47&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.23&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">6.4&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">4.94e-10</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.218&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">sat</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.00114</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.000179</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">6.39&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">5.2e-10&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.000194</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">hsperc</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.00857</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.00124&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-6.91&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">2.27e-11</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.00139&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">tothrs</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.0025&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.000731</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">3.43&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.000685</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.000753</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">female</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.303&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.059&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">5.14&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">4.5e-07&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.0647&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">black</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">-0.128&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.147&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">-0.87&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt;">0.385&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.138&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">white</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.0587&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.141&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-0.416</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.677&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.119&nbsp;&nbsp;&nbsp;</td>
</tr>
</table>

<p>Using the whole bootstrapping procedure is longer than simply using either one of the first two methods. However, this procedure is very flexible and can thus be adapted to a very large range of situations.</p>
</div>
</div>
<div id="weighted-least-squares" class="section level2">
<h2><span class="header-section-number">1.5</span> Weighted least squares</h2>
<p>Weighted Least Squares (WLS) attempts to provide a more efficient alternative to OLS. It is a special version of a feasible generalized least squares (FGLS) estimator.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="linearregression.html#cb298-1"></a><span class="kw">data</span>(<span class="st">&quot;k401k&quot;</span>)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="linearregression.html#cb299-1"></a><span class="co"># OLS (only for singles: fsize==1)</span></span>
<span id="cb299-2"><a href="linearregression.html#cb299-2"></a><span class="kw">lm</span>(nettfa <span class="op">~</span><span class="st"> </span>inc <span class="op">+</span><span class="st"> </span><span class="kw">I</span>((age<span class="dv">-25</span>)<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>e401k, </span>
<span id="cb299-3"><a href="linearregression.html#cb299-3"></a>   <span class="dt">data=</span>k401ksubs, <span class="dt">subset=</span>(fsize<span class="op">==</span><span class="dv">1</span>))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = nettfa ~ inc + I((age - 25)^2) + male + e401k, data = k401ksubs, 
##     subset = (fsize == 1))
## 
## Coefficients:
##     (Intercept)              inc  I((age - 25)^2)             male  
##       -20.98499          0.77058          0.02513          2.47793  
##           e401k  
##         6.88622</code></pre>
<p>Following Wooldrige, we assume that the variance is proportional to the income variable <em>inc.</em>. Therefore, the optimal weight is <span class="math inline">\(\frac{1}{inc}\)</span> which is given as <em>weight</em> in the <code>lm()</code> call.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="linearregression.html#cb301-1"></a><span class="co"># WLS</span></span>
<span id="cb301-2"><a href="linearregression.html#cb301-2"></a><span class="kw">lm</span>(nettfa <span class="op">~</span><span class="st"> </span>inc <span class="op">+</span><span class="st"> </span><span class="kw">I</span>((age<span class="dv">-25</span>)<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>e401k, <span class="dt">weight=</span><span class="dv">1</span><span class="op">/</span>inc, </span>
<span id="cb301-3"><a href="linearregression.html#cb301-3"></a>   <span class="dt">data=</span>k401ksubs, <span class="dt">subset=</span>(fsize<span class="op">==</span><span class="dv">1</span>))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = nettfa ~ inc + I((age - 25)^2) + male + e401k, data = k401ksubs, 
##     subset = (fsize == 1), weights = 1/inc)
## 
## Coefficients:
##     (Intercept)              inc  I((age - 25)^2)             male  
##       -16.70252          0.74038          0.01754          1.84053  
##           e401k  
##         5.18828</code></pre>
<p>We can also use heteroscedasticity-robust statistics to account for the fact that our variance function might be misspecified.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="linearregression.html#cb303-1"></a><span class="co"># WLS</span></span>
<span id="cb303-2"><a href="linearregression.html#cb303-2"></a>wlsreg &lt;-<span class="st"> </span><span class="kw">lm</span>(nettfa <span class="op">~</span><span class="st"> </span>inc <span class="op">+</span><span class="st"> </span><span class="kw">I</span>((age<span class="dv">-25</span>)<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>e401k, </span>
<span id="cb303-3"><a href="linearregression.html#cb303-3"></a>             <span class="dt">weight=</span><span class="dv">1</span><span class="op">/</span>inc, <span class="dt">data=</span>k401ksubs, <span class="dt">subset=</span>(fsize<span class="op">==</span><span class="dv">1</span>))</span>
<span id="cb303-4"><a href="linearregression.html#cb303-4"></a></span>
<span id="cb303-5"><a href="linearregression.html#cb303-5"></a><span class="co"># non-robust results</span></span>
<span id="cb303-6"><a href="linearregression.html#cb303-6"></a><span class="kw">coeftest</span>(wlsreg)</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                    Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)     -16.7025205   1.9579947 -8.5304 &lt; 2.2e-16 ***
## inc               0.7403843   0.0643029 11.5140 &lt; 2.2e-16 ***
## I((age - 25)^2)   0.0175373   0.0019315  9.0796 &lt; 2.2e-16 ***
## male              1.8405293   1.5635872  1.1771  0.239287    
## e401k             5.1882807   1.7034258  3.0458  0.002351 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="linearregression.html#cb305-1"></a><span class="co"># robust results (Refined White SE:)</span></span>
<span id="cb305-2"><a href="linearregression.html#cb305-2"></a><span class="kw">coeftest</span>(wlsreg,hccm)</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                    Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)     -16.7025205   2.2482355 -7.4292 1.606e-13 ***
## inc               0.7403843   0.0752396  9.8403 &lt; 2.2e-16 ***
## I((age - 25)^2)   0.0175373   0.0025924  6.7650 1.742e-11 ***
## male              1.8405293   1.3132477  1.4015 0.1612159    
## e401k             5.1882807   1.5743329  3.2955 0.0009994 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="linearregression.html#cb307-1"></a><span class="kw">coeftest</span>(wlsreg, <span class="dt">vcov. =</span> vcovHC)</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                    Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)     -16.7025205   2.2482355 -7.4292 1.606e-13 ***
## inc               0.7403843   0.0752396  9.8403 &lt; 2.2e-16 ***
## I((age - 25)^2)   0.0175373   0.0025924  6.7650 1.742e-11 ***
## male              1.8405293   1.3132477  1.4015 0.1612159    
## e401k             5.1882807   1.5743329  3.2955 0.0009994 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="linearregression.html#cb309-1"></a>mySummary &lt;-<span class="st"> </span><span class="cf">function</span>(model, VCOV) {</span>
<span id="cb309-2"><a href="linearregression.html#cb309-2"></a>  <span class="kw">print</span>(<span class="kw">coeftest</span>(model, <span class="dt">vcov. =</span> VCOV))</span>
<span id="cb309-3"><a href="linearregression.html#cb309-3"></a>  <span class="kw">print</span>(<span class="kw">waldtest</span>(model, <span class="dt">vcov =</span> VCOV))</span>
<span id="cb309-4"><a href="linearregression.html#cb309-4"></a>}</span>
<span id="cb309-5"><a href="linearregression.html#cb309-5"></a><span class="kw">mySummary</span>(wlsreg, <span class="dt">VCOV =</span> vcovHAC)</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                    Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)     -16.7025205   2.2425229 -7.4481 1.397e-13 ***
## inc               0.7403843   0.0752621  9.8374 &lt; 2.2e-16 ***
## I((age - 25)^2)   0.0175373   0.0025797  6.7981 1.392e-11 ***
## male              1.8405293   1.3056244  1.4097  0.158785    
## e401k             5.1882807   1.5733280  3.2976  0.000992 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Wald test
## 
## Model 1: nettfa ~ inc + I((age - 25)^2) + male + e401k
## Model 2: nettfa ~ 1
##   Res.Df Df      F    Pr(&gt;F)    
## 1   2012                        
## 2   2016 -4 39.602 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The assumption that the variance is proportional to a regressor is usually hard to justify. Typically, we do not know the variance function; we have to estimate it. We can estimate the relation between variance and regressors using a linear regression of the log of the squared residuals from an initial OLS regression <span class="math inline">\(log(\hat{u}^{2})\)</span> as the dependent variable.</p>
<p>Wooldrige suggests two version for the selection of regressors:</p>
<ul>
<li>the regressors <span class="math inline">\(x_1, \dots , x_k\)</span> from the original model similar to the BP test</li>
<li><span class="math inline">\(\hat{y}\)</span> and <span class="math inline">\(\hat{y}^{2}\)</span> from the original model similar to the White test</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="linearregression.html#cb311-1"></a><span class="kw">data</span>(<span class="st">&quot;smoke&quot;</span>)</span>
<span id="cb311-2"><a href="linearregression.html#cb311-2"></a><span class="co"># OLS</span></span>
<span id="cb311-3"><a href="linearregression.html#cb311-3"></a>olsreg&lt;-<span class="kw">lm</span>(cigs<span class="op">~</span><span class="kw">log</span>(income)<span class="op">+</span><span class="kw">log</span>(cigpric)<span class="op">+</span>educ<span class="op">+</span>age<span class="op">+</span><span class="kw">I</span>(age<span class="op">^</span><span class="dv">2</span>)<span class="op">+</span>restaurn, </span>
<span id="cb311-4"><a href="linearregression.html#cb311-4"></a>           <span class="dt">data=</span>smoke)</span>
<span id="cb311-5"><a href="linearregression.html#cb311-5"></a>olsreg</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = cigs ~ log(income) + log(cigpric) + educ + age + 
##     I(age^2) + restaurn, data = smoke)
## 
## Coefficients:
##  (Intercept)   log(income)  log(cigpric)          educ           age  
##    -3.639826      0.880268     -0.750862     -0.501498      0.770694  
##     I(age^2)      restaurn  
##    -0.009023     -2.825085</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="linearregression.html#cb313-1"></a><span class="co"># BP test</span></span>
<span id="cb313-2"><a href="linearregression.html#cb313-2"></a><span class="kw">bptest</span>(olsreg)</span></code></pre></div>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  olsreg
## BP = 32.258, df = 6, p-value = 1.456e-05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="linearregression.html#cb315-1"></a><span class="co"># FGLS: estimation of the variance function</span></span>
<span id="cb315-2"><a href="linearregression.html#cb315-2"></a>logu2 &lt;-<span class="st"> </span><span class="kw">log</span>(<span class="kw">resid</span>(olsreg)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb315-3"><a href="linearregression.html#cb315-3"></a>varreg&lt;-<span class="kw">lm</span>(logu2<span class="op">~</span><span class="kw">log</span>(income)<span class="op">+</span><span class="kw">log</span>(cigpric)<span class="op">+</span>educ<span class="op">+</span>age<span class="op">+</span><span class="kw">I</span>(age<span class="op">^</span><span class="dv">2</span>)<span class="op">+</span>restaurn, </span>
<span id="cb315-4"><a href="linearregression.html#cb315-4"></a>           <span class="dt">data=</span>smoke)</span>
<span id="cb315-5"><a href="linearregression.html#cb315-5"></a></span>
<span id="cb315-6"><a href="linearregression.html#cb315-6"></a><span class="co"># FGLS: WLS</span></span>
<span id="cb315-7"><a href="linearregression.html#cb315-7"></a>w &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="kw">exp</span>(<span class="kw">fitted</span>(varreg))</span>
<span id="cb315-8"><a href="linearregression.html#cb315-8"></a><span class="kw">lm</span>(cigs<span class="op">~</span><span class="kw">log</span>(income)<span class="op">+</span><span class="kw">log</span>(cigpric)<span class="op">+</span>educ<span class="op">+</span>age<span class="op">+</span><span class="kw">I</span>(age<span class="op">^</span><span class="dv">2</span>)<span class="op">+</span>restaurn, </span>
<span id="cb315-9"><a href="linearregression.html#cb315-9"></a>   <span class="dt">weight=</span>w ,<span class="dt">data=</span>smoke)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = cigs ~ log(income) + log(cigpric) + educ + age + 
##     I(age^2) + restaurn, data = smoke, weights = w)
## 
## Coefficients:
##  (Intercept)   log(income)  log(cigpric)          educ           age  
##     5.635463      1.295239     -2.940312     -0.463446      0.481948  
##     I(age^2)      restaurn  
##    -0.005627     -3.461064</code></pre>
</div>
<div id="model-specification-and-parameter-heterogeneity" class="section level2">
<h2><span class="header-section-number">1.6</span> Model specification and Parameter Heterogeneity</h2>
<div id="functional-form-misspecifcation" class="section level3">
<h3><span class="header-section-number">1.6.1</span> Functional Form Misspecifcation</h3>
<p>We have seen many ways to specify the relation between the dependent variable and the regressors. An obvious question is to ask whether or not a given specification is “correct”.</p>
<div id="reset" class="section level4">
<h4><span class="header-section-number">1.6.1.1</span> RESET</h4>
<p>The Regression Equation Specification Error Test (RESET) is a convenient tool to test the null hypothesis that the functional form is adequate.</p>
<p>We can run the test ourselves or use the boxed routine <code>resettest()</code> from the package <strong>lmtest</strong>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="linearregression.html#cb317-1"></a><span class="kw">data</span>(<span class="st">&quot;hprice1&quot;</span>)</span>
<span id="cb317-2"><a href="linearregression.html#cb317-2"></a><span class="co"># original linear regression</span></span>
<span id="cb317-3"><a href="linearregression.html#cb317-3"></a>orig &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>lotsize<span class="op">+</span>sqrft<span class="op">+</span>bdrms, <span class="dt">data=</span>hprice1)</span>
<span id="cb317-4"><a href="linearregression.html#cb317-4"></a></span>
<span id="cb317-5"><a href="linearregression.html#cb317-5"></a><span class="co"># regression for RESET test</span></span>
<span id="cb317-6"><a href="linearregression.html#cb317-6"></a>RESETreg &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>lotsize<span class="op">+</span>sqrft<span class="op">+</span>bdrms<span class="op">+</span><span class="kw">I</span>(<span class="kw">fitted</span>(orig)<span class="op">^</span><span class="dv">2</span>)<span class="op">+</span><span class="st"> </span></span>
<span id="cb317-7"><a href="linearregression.html#cb317-7"></a><span class="st">                 </span><span class="kw">I</span>(<span class="kw">fitted</span>(orig)<span class="op">^</span><span class="dv">3</span>), <span class="dt">data=</span>hprice1)</span>
<span id="cb317-8"><a href="linearregression.html#cb317-8"></a>RESETreg</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = price ~ lotsize + sqrft + bdrms + I(fitted(orig)^2) + 
##     I(fitted(orig)^3), data = hprice1)
## 
## Coefficients:
##       (Intercept)            lotsize              sqrft  
##         1.661e+02          1.537e-04          1.760e-02  
##             bdrms  I(fitted(orig)^2)  I(fitted(orig)^3)  
##         2.175e+00          3.534e-04          1.546e-06</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="linearregression.html#cb319-1"></a><span class="co"># RESET test. H0: all coeffs including &quot;fitted&quot; are=0 </span></span>
<span id="cb319-2"><a href="linearregression.html#cb319-2"></a><span class="kw">linearHypothesis</span>(RESETreg, <span class="kw">matchCoefs</span>(RESETreg,<span class="st">&quot;fitted&quot;</span>))</span></code></pre></div>
<table class="huxtable" style="border-collapse: collapse; margin-bottom: 2em; margin-top: 2em; width: 76.6666666666667%; margin-left: 0%; margin-right: auto;  ">
<col><col><col><col><col><col><tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Res.Df</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">RSS</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Df</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Sum of Sq</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">F</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Pr(&gt;F)</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">84</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">3.01e+05</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);"></td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">&nbsp;&nbsp;&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">82</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">2.7e+05&nbsp;</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">2</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">3.07e+04</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">4.67</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.012</td>
</tr>
</table>

<p>Automatic routine:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="linearregression.html#cb320-1"></a><span class="co"># original linear regression</span></span>
<span id="cb320-2"><a href="linearregression.html#cb320-2"></a>orig &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>lotsize<span class="op">+</span>sqrft<span class="op">+</span>bdrms, <span class="dt">data=</span>hprice1)</span>
<span id="cb320-3"><a href="linearregression.html#cb320-3"></a></span>
<span id="cb320-4"><a href="linearregression.html#cb320-4"></a><span class="co"># RESET test</span></span>
<span id="cb320-5"><a href="linearregression.html#cb320-5"></a><span class="kw">resettest</span>(orig)</span></code></pre></div>
<pre><code>## 
##  RESET test
## 
## data:  orig
## RESET = 4.6682, df1 = 2, df2 = 82, p-value = 0.01202</code></pre>
<p>Wooldrige (2016, Section 9.2) also discusses tests of non-nested models. We can use the <code>encomptest()</code> function from the package <strong>lmtest</strong>.</p>
<p>Two alternative models for the housing price</p>
<p><span class="math display">\[\begin{equation}
price = \beta_0 + \beta_1 lotsize  +\beta_2 sqrft  +\beta_3 bdrms  + u 
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
price = \beta_0 + \beta_1 log(lotsize)  +\beta_2 log(sqrft)  +\beta_3 log(bdrms)  + u 
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="linearregression.html#cb322-1"></a><span class="co"># two alternative models</span></span>
<span id="cb322-2"><a href="linearregression.html#cb322-2"></a>model1 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st">     </span>lotsize  <span class="op">+</span><span class="st">     </span>sqrft  <span class="op">+</span><span class="st"> </span>bdrms, <span class="dt">data=</span>hprice1)</span>
<span id="cb322-3"><a href="linearregression.html#cb322-3"></a>model2 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(lotsize) <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(sqrft) <span class="op">+</span><span class="st"> </span>bdrms, <span class="dt">data=</span>hprice1)</span>
<span id="cb322-4"><a href="linearregression.html#cb322-4"></a></span>
<span id="cb322-5"><a href="linearregression.html#cb322-5"></a><span class="co"># Test against comprehensive model</span></span>
<span id="cb322-6"><a href="linearregression.html#cb322-6"></a><span class="kw">encomptest</span>(model1,model2, <span class="dt">data=</span>hprice1)</span></code></pre></div>
<table class="huxtable" style="border-collapse: collapse; margin-bottom: 2em; margin-top: 2em; width: 44.4444444444444%; margin-left: 0%; margin-right: auto;  ">
<col><col><col><col><tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Res.Df</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Df</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">F</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt; font-weight: bold;">Pr(&gt;F)</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0.4pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">82</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">-2</td>
<td style="vertical-align: top; text-align: right; white-space: normal; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">7.86</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0pt 0pt; padding: 4pt 4pt 4pt 4pt; background-color: rgb(242, 242, 242);">0.000753</td>
</tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0.4pt; padding: 4pt 4pt 4pt 4pt;">82</td>
<td style="vertical-align: top; text-align: right; white-space: nowrap; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">-2</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">7.05</td>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0.4pt 0.4pt 0pt; padding: 4pt 4pt 4pt 4pt;">0.00149&nbsp;</td>
</tr>
</table>

<p>The output shows the “encompassing model” <span class="math inline">\(E\)</span> with all variables. Both models are rejected against this comprehensive model.</p>
</div>
<div id="outlying-observations" class="section level4">
<h4><span class="header-section-number">1.6.1.2</span> Outlying observations</h4>
<p>Dealing with outliers is a tricky business. R offers different packages to test and adjust for outliers. But outliers can be a matter of opinion and not all outlier detection methods give the same results. With the <strong>OutliersO3</strong> package we can compare different outlier detection methods.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="linearregression.html#cb323-1"></a><span class="kw">data</span>(rdchem)</span>
<span id="cb323-2"><a href="linearregression.html#cb323-2"></a>s3 &lt;-<span class="st"> </span><span class="kw">O3prep</span>(rdchem, <span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;HDo&quot;</span>, <span class="st">&quot;adjOut&quot;</span>, <span class="st">&quot;DDC&quot;</span>))</span>
<span id="cb323-3"><a href="linearregression.html#cb323-3"></a>O3s3 &lt;-<span class="st"> </span><span class="kw">O3plotM</span>(s3)</span>
<span id="cb323-4"><a href="linearregression.html#cb323-4"></a><span class="kw">print</span>(O3s3<span class="op">$</span>nOut)</span></code></pre></div>
<pre><code>##    HDo adjOut    DDC 
##     10      1      9</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="linearregression.html#cb325-1"></a>O3s3<span class="op">$</span>gO3</span></code></pre></div>
<p><img src="MEM5220_R_files/figure-html/unnamed-chunk-139-1.png" width="672" /></p>
<p>An O3 plot of stackloss using the methods HDoutliers, adjOutlyingness
and DectectDeviatingCells. The darker the cell, the more methods agree. If they all agree, the cell is coloured red and if all but one agree then orange.</p>
<p>We use functions from the <strong>car</strong> package to obtain a table of different measures of leverage and influence for all observations.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="linearregression.html#cb326-1"></a><span class="co"># Regression</span></span>
<span id="cb326-2"><a href="linearregression.html#cb326-2"></a>reg &lt;-<span class="st"> </span><span class="kw">lm</span>(rdintens<span class="op">~</span>sales<span class="op">+</span>profmarg, <span class="dt">data=</span>rdchem)</span>
<span id="cb326-3"><a href="linearregression.html#cb326-3"></a></span>
<span id="cb326-4"><a href="linearregression.html#cb326-4"></a><span class="co"># Studentized residuals for all observations:</span></span>
<span id="cb326-5"><a href="linearregression.html#cb326-5"></a>studres &lt;-<span class="st"> </span><span class="kw">rstudent</span>(reg)</span>
<span id="cb326-6"><a href="linearregression.html#cb326-6"></a></span>
<span id="cb326-7"><a href="linearregression.html#cb326-7"></a><span class="co"># Display extreme values:</span></span>
<span id="cb326-8"><a href="linearregression.html#cb326-8"></a><span class="kw">min</span>(studres)</span></code></pre></div>
<pre><code>## [1] -1.818039</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="linearregression.html#cb328-1"></a><span class="kw">max</span>(studres)</span></code></pre></div>
<pre><code>## [1] 4.555033</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="linearregression.html#cb330-1"></a><span class="co"># Histogram (and overlayed density plot):</span></span>
<span id="cb330-2"><a href="linearregression.html#cb330-2"></a><span class="kw">hist</span>(studres, <span class="dt">freq=</span><span class="ot">FALSE</span>)</span>
<span id="cb330-3"><a href="linearregression.html#cb330-3"></a><span class="kw">lines</span>(<span class="kw">density</span>(studres), <span class="dt">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="MEM5220_R_files/figure-html/unnamed-chunk-140-1.png" width="672" /></p>
</div>
<div id="missing-data" class="section level4">
<h4><span class="header-section-number">1.6.1.3</span> Missing Data</h4>
<p>Missing values in data is a common phenomenon in real world problems. In R, missing data can be represented by different values of the variable.</p>
<ul>
<li><strong>NA</strong> (not available) indicates that we do not have the information</li>
<li><strong>NaN</strong> (not a number) indicates that the value is not defined, for example when we take the log of a negative number</li>
</ul>
<p>Base R offers many functions to detect missing observations. Sometimes using <strong>mice</strong> and <strong>VIM</strong> package for looking at missing data pattern and imputing missing data is even easier.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="linearregression.html#cb331-1"></a><span class="kw">data</span>(<span class="st">&quot;lawsch85&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;wooldridge&quot;</span> )</span>
<span id="cb331-2"><a href="linearregression.html#cb331-2"></a></span>
<span id="cb331-3"><a href="linearregression.html#cb331-3"></a><span class="co"># extract LSAT</span></span>
<span id="cb331-4"><a href="linearregression.html#cb331-4"></a>lsat &lt;-<span class="st"> </span>lawsch85<span class="op">$</span>LSAT</span>
<span id="cb331-5"><a href="linearregression.html#cb331-5"></a></span>
<span id="cb331-6"><a href="linearregression.html#cb331-6"></a><span class="co"># Create logical indicator for missings</span></span>
<span id="cb331-7"><a href="linearregression.html#cb331-7"></a>missLSAT &lt;-<span class="st"> </span><span class="kw">is.na</span>(lawsch85<span class="op">$</span>LSAT)</span>
<span id="cb331-8"><a href="linearregression.html#cb331-8"></a></span>
<span id="cb331-9"><a href="linearregression.html#cb331-9"></a><span class="co"># LSAT and indicator for Schools No. 120-129:</span></span>
<span id="cb331-10"><a href="linearregression.html#cb331-10"></a><span class="kw">rbind</span>(lsat,missLSAT)[,<span class="dv">120</span><span class="op">:</span><span class="dv">129</span>]</span></code></pre></div>
<pre><code>##          [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
## lsat      156  159  157  167   NA  158  155  157   NA   163
## missLSAT    0    0    0    0    1    0    0    0    1     0</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="linearregression.html#cb333-1"></a><span class="co"># Frequencies of indicator</span></span>
<span id="cb333-2"><a href="linearregression.html#cb333-2"></a><span class="kw">table</span>(missLSAT)</span></code></pre></div>
<pre><code>## missLSAT
## FALSE  TRUE 
##   150     6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="linearregression.html#cb335-1"></a><span class="co"># Missings for all variables in data frame (counts)</span></span>
<span id="cb335-2"><a href="linearregression.html#cb335-2"></a><span class="kw">colSums</span>(<span class="kw">is.na</span>(lawsch85))</span></code></pre></div>
<pre><code>##    rank  salary    cost    LSAT     GPA  libvol faculty     age  clsize 
##       0       8       6       6       7       1       4      45       3 
##   north   south    east    west lsalary studfac   top10  r11_25  r26_40 
##       0       0       0       0       8       6       0       0       0 
##  r41_60 llibvol   lcost 
##       0       1       6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="linearregression.html#cb337-1"></a><span class="co"># Indicator for complete cases</span></span>
<span id="cb337-2"><a href="linearregression.html#cb337-2"></a>compl &lt;-<span class="st"> </span><span class="kw">complete.cases</span>(lawsch85)</span>
<span id="cb337-3"><a href="linearregression.html#cb337-3"></a><span class="kw">table</span>(compl)</span></code></pre></div>
<pre><code>## compl
## FALSE  TRUE 
##    66    90</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="linearregression.html#cb339-1"></a><span class="co"># MICE package function to display msising values </span></span>
<span id="cb339-2"><a href="linearregression.html#cb339-2"></a><span class="kw">head</span>(<span class="kw">md.pattern</span>(lawsch85, <span class="dt">plot =</span> <span class="ot">FALSE</span>)) </span></code></pre></div>
<pre><code>##    rank north south east west top10 r11_25 r26_40 r41_60 libvol llibvol
## 90    1     1     1    1    1     1      1      1      1      1       1
## 41    1     1     1    1    1     1      1      1      1      1       1
## 6     1     1     1    1    1     1      1      1      1      1       1
## 1     1     1     1    1    1     1      1      1      1      1       1
## 3     1     1     1    1    1     1      1      1      1      1       1
## 1     1     1     1    1    1     1      1      1      1      1       1
##    clsize faculty cost LSAT studfac lcost GPA salary lsalary age  
## 90      1       1    1    1       1     1   1      1       1   1 0
## 41      1       1    1    1       1     1   1      1       1   0 1
## 6       1       1    1    1       1     1   1      0       0   1 2
## 1       1       1    1    1       1     1   1      0       0   0 3
## 3       1       1    1    0       1     1   0      1       1   1 2
## 1       1       1    1    0       1     1   0      1       1   0 3</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="linearregression.html#cb341-1"></a>aggr_plot &lt;-<span class="st"> </span><span class="kw">aggr</span>(lawsch85, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&#39;navyblue&#39;</span>,<span class="st">&#39;red&#39;</span>), <span class="dt">numbers=</span><span class="ot">TRUE</span>, <span class="dt">sortVars=</span><span class="ot">TRUE</span>, <span class="dt">labels=</span><span class="kw">names</span>(lawsch85), <span class="dt">cex.axis=</span>.<span class="dv">7</span>, <span class="dt">gap=</span><span class="dv">3</span>, <span class="dt">ylab=</span><span class="kw">c</span>(<span class="st">&quot;Histogram of missing data&quot;</span>,<span class="st">&quot;Pattern&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:fig20"></span>
<img src="MEM5220_R_files/figure-html/fig20-1.png" alt="Visualizing missing data" width="80%" />
<p class="caption">
Figure 1.25: Visualizing missing data
</p>
</div>
<pre><code>## 
##  Variables sorted by number of missings: 
##  Variable       Count
##       age 0.288461538
##    salary 0.051282051
##   lsalary 0.051282051
##       GPA 0.044871795
##      cost 0.038461538
##      LSAT 0.038461538
##   studfac 0.038461538
##     lcost 0.038461538
##   faculty 0.025641026
##    clsize 0.019230769
##    libvol 0.006410256
##   llibvol 0.006410256
##      rank 0.000000000
##     north 0.000000000
##     south 0.000000000
##      east 0.000000000
##      west 0.000000000
##     top10 0.000000000
##    r11_25 0.000000000
##    r26_40 0.000000000
##    r41_60 0.000000000</code></pre>
<p>Regression command like <code>lm()</code> have as argument <strong>na.rm=TRUE</strong>!</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="linearregression.html#cb343-1"></a><span class="co"># Mean of a variable with missings:</span></span>
<span id="cb343-2"><a href="linearregression.html#cb343-2"></a><span class="kw">mean</span>(lawsch85<span class="op">$</span>LSAT)</span></code></pre></div>
<pre><code>## [1] NA</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="linearregression.html#cb345-1"></a><span class="kw">mean</span>(lawsch85<span class="op">$</span>LSAT,<span class="dt">na.rm=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 158.2933</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="linearregression.html#cb347-1"></a><span class="co"># Regression with missings</span></span>
<span id="cb347-2"><a href="linearregression.html#cb347-2"></a><span class="kw">summary</span>(<span class="kw">lm</span>(<span class="kw">log</span>(salary)<span class="op">~</span>LSAT<span class="op">+</span>cost<span class="op">+</span>age, <span class="dt">data=</span>lawsch85))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(salary) ~ LSAT + cost + age, data = lawsch85)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.40989 -0.09438  0.00317  0.10436  0.45483 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 4.384e+00  6.781e-01   6.465 4.94e-09 ***
## LSAT        3.722e-02  4.501e-03   8.269 1.06e-12 ***
## cost        1.114e-05  4.321e-06   2.577 0.011563 *  
## age         1.503e-03  4.354e-04   3.453 0.000843 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1545 on 91 degrees of freedom
##   (61 observations deleted due to missingness)
## Multiple R-squared:  0.6708, Adjusted R-squared:  0.6599 
## F-statistic: 61.81 on 3 and 91 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>R packages provide multiple imputation algorithms. Without going into detail how those algorithms work, we can use for example the <strong>meth=“pmm”</strong> argument from the <strong>mice</strong> package to apply a predictive mean matching as imputation method.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="linearregression.html#cb349-1"></a><span class="co"># We use a diffferent dataset to speed up the imputation process</span></span>
<span id="cb349-2"><a href="linearregression.html#cb349-2"></a>data &lt;-<span class="st"> </span>airquality</span>
<span id="cb349-3"><a href="linearregression.html#cb349-3"></a>data[<span class="dv">4</span><span class="op">:</span><span class="dv">10</span>,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>,<span class="dv">7</span>)</span>
<span id="cb349-4"><a href="linearregression.html#cb349-4"></a>data[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,<span class="dv">4</span>] &lt;-<span class="st"> </span><span class="ot">NA</span></span>
<span id="cb349-5"><a href="linearregression.html#cb349-5"></a>tempData &lt;-<span class="st"> </span><span class="kw">mice</span>(data,<span class="dt">m=</span><span class="dv">5</span>,<span class="dt">maxit=</span><span class="dv">50</span>,<span class="dt">meth=</span><span class="st">&#39;pmm&#39;</span>,<span class="dt">seed=</span><span class="dv">500</span>)</span></code></pre></div>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="linearregression.html#cb350-1"></a><span class="kw">summary</span>(tempData)</span></code></pre></div>
<pre><code>## Class: mids
## Number of multiple imputations:  5 
## Imputation methods:
##   Ozone Solar.R    Wind    Temp   Month     Day 
##   &quot;pmm&quot;   &quot;pmm&quot;   &quot;pmm&quot;   &quot;pmm&quot;      &quot;&quot;      &quot;&quot; 
## PredictorMatrix:
##         Ozone Solar.R Wind Temp Month Day
## Ozone       0       1    1    1     1   1
## Solar.R     1       0    1    1     1   1
## Wind        1       1    0    1     1   1
## Temp        1       1    1    0     1   1
## Month       1       1    1    1     0   1
## Day         1       1    1    1     1   0</code></pre>
</div>
</div>
</div>
<div id="least-absolute-deviations-lad-estimation" class="section level2">
<h2><span class="header-section-number">1.7</span> Least absolute Deviations (LAD) Estimation</h2>
<p>As an alternative to OLS, the least absolute deviations (LAD) is less sensitive to outliers. Instead of minimizing the sum of <em>squared</em> residuals, it minimizes the sum of the <em>absolute values</em> of the residuals.</p>
<p>In R, general quantile regression (and LAD as the default special case) can easily be implemented with the command <code>reg()</code> from the <strong>quantreg</strong> package.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="linearregression.html#cb352-1"></a><span class="co"># OLS Regression</span></span>
<span id="cb352-2"><a href="linearregression.html#cb352-2"></a>ols &lt;-<span class="st"> </span><span class="kw">lm</span>(rdintens <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(sales<span class="op">/</span><span class="dv">1000</span>) <span class="op">+</span>profmarg, <span class="dt">data=</span>rdchem)</span>
<span id="cb352-3"><a href="linearregression.html#cb352-3"></a><span class="co"># LAD Regression</span></span>
<span id="cb352-4"><a href="linearregression.html#cb352-4"></a>lad &lt;-<span class="st"> </span><span class="kw">rq</span>(rdintens <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(sales<span class="op">/</span><span class="dv">1000</span>) <span class="op">+</span>profmarg, <span class="dt">data=</span>rdchem)</span>
<span id="cb352-5"><a href="linearregression.html#cb352-5"></a></span>
<span id="cb352-6"><a href="linearregression.html#cb352-6"></a><span class="co"># regression table</span></span>
<span id="cb352-7"><a href="linearregression.html#cb352-7"></a><span class="kw">stargazer</span>(ols,lad,  <span class="dt">type =</span> <span class="st">&quot;text&quot;</span>)</span></code></pre></div>
<pre><code>## 
## =================================================
##                          Dependent variable:     
##                     -----------------------------
##                               rdintens           
##                            OLS          quantile 
##                                        regression
##                            (1)            (2)    
## -------------------------------------------------
## I(sales/1000)             0.053          0.019   
##                          (0.044)        (0.059)  
##                                                  
## profmarg                  0.045         0.118**  
##                          (0.046)        (0.049)  
##                                                  
## Constant                 2.625***       1.623*** 
##                          (0.586)        (0.509)  
##                                                  
## -------------------------------------------------
## Observations                32             32    
## R2                        0.076                  
## Adjusted R2               0.012                  
## Residual Std. Error  1.862 (df = 29)             
## F Statistic         1.195 (df = 2; 29)           
## =================================================
## Note:                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Note: LAD inferences are only valid asymptotically, so the results in this example with <span class="math inline">\(n =32\)</span> should be taken with caution.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-dalpiaz2016">
<p>Dalpiaz, David. 2016. <em>Applied Statistics</em>. <a href="http://www.stat.illinois.edu">http://www.stat.illinois.edu</a>.</p>
</div>
<div id="ref-hill2008principles">
<p>Hill, R Carter, William E Griffiths, Guay C Lim, and Mark Andrew Lim. 2008. <em>Principles of Econometrics</em>. Vol. 5. Wiley Hoboken, NJ.</p>
</div>
<div id="ref-wooldridge2015introductory">
<p>Wooldridge, Jeffrey M. 2015. <em>Introductory Econometrics: A Modern Approach</em>. Nelson Education.</p>
</div>
<div id="ref-Zeileis2017">
<p>Zeileis, Achim, Thomas Lumley, Susanne Berger, and Nathaniel Graham. 2017. <em>Sandwich: Robust Covariance Matrix Estimators</em> (version 2.4-0). <a href="https://CRAN.R-project.org/package=sandwich">https://CRAN.R-project.org/package=sandwich</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="binarymodels.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["MEM5220_R.pdf", "MEM5220_R.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
