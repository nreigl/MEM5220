<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>MEM52220 - Applied Econometrics</title>
  <meta name="description" content="This manual constitutues the classroom material of the applied econometrics course at Tallinn University of Technology">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="MEM52220 - Applied Econometrics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This manual constitutues the classroom material of the applied econometrics course at Tallinn University of Technology" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="MEM52220 - Applied Econometrics" />
  
  <meta name="twitter:description" content="This manual constitutues the classroom material of the applied econometrics course at Tallinn University of Technology" />
  

<meta name="author" content="Nicolas Reigl">


<meta name="date" content="2018-07-26">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="binarymodels.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MEM5220 - Applied Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i><b>1.1</b> Prerequisites</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#resources"><i class="fa fa-check"></i><b>1.2</b> Resources</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.3</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linearregression.html"><a href="linearregression.html"><i class="fa fa-check"></i><b>2</b> Linear Regression</a><ul>
<li class="chapter" data-level="2.1" data-path="linearregression.html"><a href="linearregression.html#simple-linear-regression"><i class="fa fa-check"></i><b>2.1</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="2.1.1" data-path="linearregression.html"><a href="linearregression.html#regression-through-the-origin-and-regression-on-a-constant"><i class="fa fa-check"></i><b>2.1.1</b> Regression through the Origin and Regression on a Constant</a></li>
<li class="chapter" data-level="2.1.2" data-path="linearregression.html"><a href="linearregression.html#simulating-slr"><i class="fa fa-check"></i><b>2.1.2</b> Simulating SLR</a></li>
<li class="chapter" data-level="2.1.3" data-path="linearregression.html"><a href="linearregression.html#nonlinearities"><i class="fa fa-check"></i><b>2.1.3</b> Nonlinearities</a></li>
<li class="chapter" data-level="2.1.4" data-path="linearregression.html"><a href="linearregression.html#inference-for-simple-linear-regression"><i class="fa fa-check"></i><b>2.1.4</b> Inference for Simple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="linearregression.html"><a href="linearregression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>2.2</b> Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="binarymodels.html"><a href="binarymodels.html"><i class="fa fa-check"></i><b>3</b> Binary limited dependent variable models</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MEM52220 - Applied Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linearregression" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Linear Regression</h1>
<p>The general form in which we specify regression models in R:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## response ~ terms</span>
<span class="co">## </span>
<span class="co">## y ~ age + sex            # age + sex main effects</span>
<span class="co">## y ~ age + sex + age:sex  # add second-order interaction</span>
<span class="co">## y ~ age*sex              # second-order interaction +</span>
<span class="co">##                          # all main effects</span>
<span class="co">## y ~ (age + sex + pressure)^2</span>
<span class="co">##                          # age+sex+pressure+age:sex+age:pressure...</span>
<span class="co">## y ~ (age + sex + pressure)^2 - sex:pressure</span>
<span class="co">##                          # all main effects and all 2nd order</span>
<span class="co">##                          # interactions except sex:pressure</span>
<span class="co">## y ~ (age + race)*sex     # age+race+sex+age:sex+race:sex</span>
<span class="co">## y ~ treatment*(age*race + age*sex) # no interact. with race,sex</span>
<span class="co">## sqrt(y) ~ sex*sqrt(age) + race</span>
<span class="co">## # functions, with dummy variables generated if</span>
<span class="co">## # race is an R factor (classification) variable</span>
<span class="co">## y ~ sex + poly(age,2)    # poly generates orthogonal polynomials</span>
<span class="co">## race.sex &lt;- interaction(race,sex)</span>
<span class="co">## y ~ age + race.sex       # for when you want dummy variables for</span>
<span class="co">##                          # all combinations of the factors</span></code></pre>
<div id="simple-linear-regression" class="section level2">
<h2><span class="header-section-number">2.1</span> Simple Linear Regression</h2>
<p>We start off with a simple OLS Regression. We will work with multiple data sources:</p>
<ul>
<li>Data from <span class="citation">Wooldridge (<a href="#ref-wooldridge2015introductory">2015</a>)</span> : Introductory Econometrics: A Modern Approch.</li>
<li><em>More datasources in the future</em></li>
</ul>
<p>To load the dataset and necessary functions:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># This function 1. checks if the packages are installed. 2. It installs the packages if they were not in the list of installed packages. 3. It loads the packages into the workspace</span>
PACKAGES&lt;-<span class="kw">c</span>(<span class="st">&quot;wooldridge&quot;</span>,  <span class="co"># Wooldrige Datasets</span>
            <span class="st">&quot;tidyverse&quot;</span>,  <span class="co"># for data manipulation and ggplots</span>
            <span class="st">&quot;broom&quot;</span>,  <span class="co"># Tidy regression output</span>
            <span class="st">&quot;ggpubr&quot;</span>,  <span class="co"># Multiple ggplots on a page. Note that, the installation of ggpubr will automatically install the gridExtra and the cowplot package; so you don’t need to re-install them. </span>
            <span class="st">&quot;ggfortify&quot;</span>) <span class="co"># Simple ggplot recipe for lm objects)</span>
inst&lt;-<span class="kw">match</span>(PACKAGES, <span class="kw">.packages</span>(<span class="dt">all=</span><span class="ot">TRUE</span>))
need&lt;-<span class="kw">which</span>(<span class="kw">is.na</span>(inst))
<span class="cf">if</span> (<span class="kw">length</span>(need)<span class="op">&gt;</span><span class="dv">0</span>) <span class="kw">install.packages</span>(PACKAGES[need])
<span class="kw">lapply</span>(PACKAGES, require, <span class="dt">character.only=</span>T)</code></pre>
<pre><code>## Loading required package: wooldridge</code></pre>
<pre><code>## Loading required package: tidyverse</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────────── tidyverse 1.2.1.9000 ──</code></pre>
<pre><code>## ✔ ggplot2 3.0.0     ✔ purrr   0.2.5
## ✔ tibble  1.4.2     ✔ dplyr   0.7.6
## ✔ tidyr   0.8.1     ✔ stringr 1.3.1
## ✔ readr   1.1.1     ✔ forcats 0.3.0</code></pre>
<pre><code>## ── Conflicts ─────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre><code>## Loading required package: broom</code></pre>
<pre><code>## Loading required package: ggpubr</code></pre>
<pre><code>## Loading required package: magrittr</code></pre>
<pre><code>## 
## Attaching package: &#39;magrittr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     set_names</code></pre>
<pre><code>## The following object is masked from &#39;package:tidyr&#39;:
## 
##     extract</code></pre>
<pre><code>## Loading required package: ggfortify</code></pre>
<p>Classic examples of quantities modeled with simple linear regression:</p>
<ul>
<li>College GPA ∼ SAT scores <span class="math inline">\(\beta &gt; 0\)</span></li>
<li>Change in GDP ∼ change in unemployment <span class="math inline">\(\beta &lt; 0\)</span></li>
<li>House price ∼ number of bedrooms <span class="math inline">\(\beta &gt; 0\)</span></li>
<li>Species heart weight ∼ species body weight <span class="math inline">\(\beta &gt; 0\)</span></li>
<li>Fatalities per year ∼ speed limit <span class="math inline">\(\beta &lt; 0\)</span></li>
</ul>
<p>Notice that these simple linear regressions are simplifications of
more complex relationships between the variables in question.</p>
<p>In this exercise we use the dataset <em>ceosal1</em>. Let us analyse the dataset first</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;ceosal1&quot;</span>)
<span class="kw">help</span>(<span class="st">&quot;ceosal1&quot;</span>)
?ceosal1</code></pre>
<p>As we see from the R documentation the <em>ceosal1</em> dataset contain of a random sample of data reported in the May 6, 1991 issue of Businessweek.</p>
<p>To get a first look at the data you can use the <code>View()</code> function inside R Studio.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(ceosal1)</code></pre>
<p>We could also take a look at the variable names, the dimension of the data frame, and some sample observations with <code>str()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(ceosal1)</code></pre>
<pre><code>## &#39;data.frame&#39;:    209 obs. of  12 variables:
##  $ salary  : int  1095 1001 1122 578 1368 1145 1078 1094 1237 833 ...
##  $ pcsalary: int  20 32 9 -9 7 5 10 7 16 5 ...
##  $ sales   : num  27595 9958 6126 16246 21783 ...
##  $ roe     : num  14.1 10.9 23.5 5.9 13.8 ...
##  $ pcroe   : num  106.4 -30.6 -16.3 -25.7 -3 ...
##  $ ros     : int  191 13 14 -21 56 55 62 44 37 37 ...
##  $ indus   : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ finance : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ consprod: int  0 0 0 0 0 0 0 0 0 0 ...
##  $ utility : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ lsalary : num  7 6.91 7.02 6.36 7.22 ...
##  $ lsales  : num  10.23 9.21 8.72 9.7 9.99 ...
##  - attr(*, &quot;time.stamp&quot;)= chr &quot;25 Jun 2011 23:03&quot;</code></pre>
<p>As we have seen before in the general R tutorial, there are a number of additional functions to access some of this information directly.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(ceosal1)</code></pre>
<pre><code>## [1] 209  12</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">nrow</span>(ceosal1)</code></pre>
<pre><code>## [1] 209</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ncol</span>(ceosal1)</code></pre>
<pre><code>## [1] 12</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ceosal1)</code></pre>
<pre><code>##      salary         pcsalary          sales              roe       
##  Min.   :  223   Min.   :-61.00   Min.   :  175.2   Min.   : 0.50  
##  1st Qu.:  736   1st Qu.: -1.00   1st Qu.: 2210.3   1st Qu.:12.40  
##  Median : 1039   Median :  9.00   Median : 3705.2   Median :15.50  
##  Mean   : 1281   Mean   : 13.28   Mean   : 6923.8   Mean   :17.18  
##  3rd Qu.: 1407   3rd Qu.: 20.00   3rd Qu.: 7177.0   3rd Qu.:20.00  
##  Max.   :14822   Max.   :212.00   Max.   :97649.9   Max.   :56.30  
##      pcroe            ros            indus           finance      
##  Min.   :-98.9   Min.   :-58.0   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:-21.2   1st Qu.: 21.0   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median : -3.0   Median : 52.0   Median :0.0000   Median :0.0000  
##  Mean   : 10.8   Mean   : 61.8   Mean   :0.3206   Mean   :0.2201  
##  3rd Qu.: 19.5   3rd Qu.: 81.0   3rd Qu.:1.0000   3rd Qu.:0.0000  
##  Max.   :977.0   Max.   :418.0   Max.   :1.0000   Max.   :1.0000  
##     consprod         utility          lsalary          lsales      
##  Min.   :0.0000   Min.   :0.0000   Min.   :5.407   Min.   : 5.166  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:6.601   1st Qu.: 7.701  
##  Median :0.0000   Median :0.0000   Median :6.946   Median : 8.217  
##  Mean   :0.2871   Mean   :0.1722   Mean   :6.950   Mean   : 8.292  
##  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:7.249   3rd Qu.: 8.879  
##  Max.   :1.0000   Max.   :1.0000   Max.   :9.604   Max.   :11.489</code></pre>
<p>The interesting task here is to determine how far a high the CEO salary is, for a given return on equity.</p>
<hr />
<p><strong>Your turn</strong></p>
<p>What sign would be expect of <span class="math inline">\(\beta\)</span> (the slope)?</p>
<p>A: Without seeing the data <strong>my</strong> prior is that <span class="math inline">\(\beta &gt; 0\)</span>.</p>
<hr />
<p><strong>Note</strong></p>
<p>A simple linear model as assumes that the mean of each <span class="math inline">\(y_{i}\)</span> conditioned on <span class="math inline">\(x_{i}\)</span>
is a linear function of <span class="math inline">\(x_{i}\)</span>. But notice that simple linear regressions are simplifications of
more complex relationships between the variables in question.</p>
<hr />
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use ggplot style</span>
<span class="kw">ggplot</span>(ceosal1, <span class="kw">aes</span>(<span class="dt">x =</span> roe, <span class="dt">y =</span> salary)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre>
<div class="figure"><span id="fig:ceosal1"></span>
<img src="MEM5220_R_files/figure-html/ceosal1-1.png" alt="Relationship between ROE and Salary" width="672" />
<p class="caption">
Figure 2.1: Relationship between ROE and Salary
</p>
</div>
<p>Consider a simple regression model</p>
<p><span class="math inline">\(salary = \beta_0 + \beta_1roe + u\)</span></p>
<p>We are concerned with the population parameter <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>. The general form of the model.</p>
<p><span class="math display" id="eq:populationparameterBeta0">\[\begin{equation}
\hat{\beta}_{0} = \bar{y} - \hat{\beta}_{1}\bar{x}
\tag{2.1}
\end{equation}\]</span></p>
<p>The ordinary least squares (OLS) estimators are</p>
<p><span class="math display" id="eq:OLSestimator">\[\begin{equation}
\hat{\beta}_{0} = \bar{y} - \hat{\beta}_{1}\bar{x}
\tag{2.2}
\end{equation}\]</span></p>
<p>Ingredients for the OLS formulas</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attach</span>(ceosal1)
<span class="kw">cov</span>(roe, salary)</code></pre>
<pre><code>## [1] 1342.538</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(roe)</code></pre>
<pre><code>## [1] 72.56499</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(salary)</code></pre>
<pre><code>## [1] 1281.12</code></pre>
<p>Manual calculation of the OLS coefficients</p>
<pre class="sourceCode r"><code class="sourceCode r">b1hat &lt;-<span class="st"> </span><span class="kw">cov</span>(roe,salary)<span class="op">/</span><span class="kw">var</span>(roe)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">b0hat &lt;-<span class="st"> </span><span class="kw">mean</span>(salary) <span class="op">-</span><span class="st"> </span>b1hat <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(roe)</code></pre>
<p>Or use the <code>lm()</code> function</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(salary <span class="op">~</span><span class="st"> </span>roe, <span class="dt">data=</span>ceosal1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = salary ~ roe, data = ceosal1)
## 
## Coefficients:
## (Intercept)          roe  
##       963.2         18.5</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">lm1_ceosal1 &lt;-<span class="st"> </span><span class="kw">lm</span>(salary <span class="op">~</span><span class="st"> </span>roe, <span class="dt">data=</span>ceosal1) </code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">unique</span>(ceosal1<span class="op">$</span>roe)</code></pre>
<pre><code>##   [1] 14.1 10.9 23.5  5.9 13.8 20.0 16.4 16.3 10.5 26.3 25.9 26.8 14.8 22.3
##  [15] 56.3 12.6 20.4  1.9 19.9 15.4 38.7 24.4 15.6 14.4 19.0 16.1 12.1 16.2
##  [29] 18.4 14.2 14.9 12.4 17.1 16.9 18.1 19.3 18.3 13.7 12.7 15.1 16.5 10.2
##  [43] 19.6 12.8 15.9 17.3  8.5 19.5 19.2 28.1 25.0 15.0 20.3 22.7 13.2 10.3
##  [57] 17.7 10.0  6.8 13.1 15.8 15.3  0.5 13.0 11.1  8.9 17.5  9.3  9.5 15.5
##  [71]  8.6 24.6  7.2 11.6 26.4 21.4  9.0  9.4  3.5 22.1 33.3 22.8 20.9  6.7
##  [85]  7.1 11.8 14.0 10.1  6.4 17.6 23.6 35.7 23.2 44.4  2.1 23.4 25.7 27.0
##  [99] 43.7 24.8 26.2 44.5 35.1 11.0 19.4 28.5 43.9 15.7 28.2 42.2 21.5 29.5
## [113] 22.6 22.9  7.8 48.1 18.0 21.7 21.3 26.9 30.5 29.1 40.8 10.8  5.1 12.3
## [127]  7.4  6.2 10.6  2.9 13.5 10.7 11.9 12.9  7.3 14.6 14.5 14.7</code></pre>
<p>Plot the linear regression fit the <em>base</em> r way.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(salary<span class="op">~</span><span class="st"> </span>roe, <span class="dt">data =</span> ceosal1,
     <span class="dt">xlab =</span> <span class="st">&quot;Return on equity&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Salary&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Salary vs return on equity&quot;</span>,
     <span class="dt">pch  =</span> <span class="dv">20</span>,
     <span class="dt">cex  =</span> <span class="dv">2</span>,
     <span class="dt">col  =</span> <span class="st">&quot;grey&quot;</span>)
<span class="kw">abline</span>(lm1_ceosal1, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">col =</span> <span class="st">&quot;darkorange&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig1"></span>
<img src="MEM5220_R_files/figure-html/fig1-1.png" alt="OLS regression base Rstyle" width="80%" />
<p class="caption">
Figure 2.2: OLS regression base Rstyle
</p>
</div>
<p>Or use ggplot</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(ceosal1, <span class="kw">aes</span>(<span class="dt">x =</span> roe, <span class="dt">y =</span> salary)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig2"></span>
<img src="MEM5220_R_files/figure-html/fig2-1.png" alt="OLS regression ggplot2 style" width="80%" />
<p class="caption">
Figure 2.3: OLS regression ggplot2 style
</p>
</div>
<p>Determine the names of the elements of the list using the <code>names()</code> command.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(lm1_ceosal1)</code></pre>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;</code></pre>
<p>Extract one element, for example the residuals from the list object</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(lm1_ceosal1<span class="op">$</span>residuals) <span class="co"># head() just prints out the first 6 residual values</span></code></pre>
<pre><code>##         1         2         3         4         5         6 
## -129.0581 -163.8543 -275.9692 -494.3483  149.4923 -188.2151</code></pre>
<p>Another way to access stored information in <em>lm1_ceosal1</em> are the <code>coef()</code>, <code>resid()</code>, and <code>fitted()</code> functions. These return the coefficients, residuals, and fitted values, respectively.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(lm1_ceosal1)</code></pre>
<pre><code>## (Intercept)         roe 
##   963.19134    18.50119</code></pre>
<p>The function <code>summary()</code> is useful in many situations. We see that when it is called on our model, it returns a good deal of information.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm1_ceosal1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = salary ~ roe, data = ceosal1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1160.2  -526.0  -254.0   138.8 13499.9 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   963.19     213.24   4.517 1.05e-05 ***
## roe            18.50      11.12   1.663   0.0978 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1367 on 207 degrees of freedom
## Multiple R-squared:  0.01319,    Adjusted R-squared:  0.008421 
## F-statistic: 2.767 on 1 and 207 DF,  p-value: 0.09777</code></pre>
<p>The <code>summary()</code> command also returns a list, and we can again use <code>names()</code> to learn what about the elements of this list.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(<span class="kw">summary</span>(lm1_ceosal1))</code></pre>
<pre><code>##  [1] &quot;call&quot;          &quot;terms&quot;         &quot;residuals&quot;     &quot;coefficients&quot; 
##  [5] &quot;aliased&quot;       &quot;sigma&quot;         &quot;df&quot;            &quot;r.squared&quot;    
##  [9] &quot;adj.r.squared&quot; &quot;fstatistic&quot;    &quot;cov.unscaled&quot;</code></pre>
<p>So, for example, if we wanted to directly access the value of <span class="math inline">\(R^2\)</span>, instead of copy and pasting it out of the printed statement from <code>summary()</code>, we could do so.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm1_ceosal1)<span class="op">$</span>r.squared</code></pre>
<pre><code>## [1] 0.01318862</code></pre>
<hr />
<p><strong>Your turn</strong></p>
<p>Recall that the residual sum of squares (SSR) is</p>
<p><span class="math display">\[\begin{equation}
R^2 = \frac{Var(\hat{y})}{Var(y)} = 1 - \frac{Var(\hat{u})}{Var(y)} 
\end{equation}\]</span></p>
<p>Calculate <span class="math inline">\(R^2\)</span> manually:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(<span class="kw">fitted</span>(lm1_ceosal1))<span class="op">/</span><span class="kw">var</span>(ceosal1<span class="op">$</span>salary)</code></pre>
<pre><code>## [1] 0.01318862</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">var</span>(<span class="kw">residuals</span>(lm1_ceosal1))<span class="op">/</span><span class="kw">var</span>(ceosal1<span class="op">$</span>salary)</code></pre>
<pre><code>## [1] 0.01318862</code></pre>
<hr />
<p>Another useful function is the <code>predict()</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
roe_sample &lt;-<span class="kw">sample</span>(ceosal1<span class="op">$</span>roe, <span class="dv">1</span>)</code></pre>
<p>Let’s make a prediction for salary when the return on equity is 20.2999992.</p>
<pre class="sourceCode r"><code class="sourceCode r">b0hat_sample &lt;-<span class="st"> </span><span class="kw">mean</span>(salary) <span class="op">-</span><span class="st"> </span>b1hat <span class="op">*</span><span class="st"> </span>roe_sample </code></pre>
<p>We are not restricted to observed values of the explanatory variable. Instead we can supply also our own predictor values</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(lm1_ceosal1, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">roe =</span> <span class="dv">30</span>))</code></pre>
<pre><code>##        1 
## 1518.227</code></pre>
<p>The above code reads “predict the salary when the return on equity is 30 using the <em>lm1_ceosal1</em> model.”</p>
<div id="regression-through-the-origin-and-regression-on-a-constant" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Regression through the Origin and Regression on a Constant</h3>
<p>Regression without intercept (through origin)</p>
<pre class="sourceCode r"><code class="sourceCode r">lm2 &lt;-<span class="st"> </span><span class="kw">lm</span>(salary <span class="op">~</span><span class="st">  </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>roe, <span class="dt">data =</span> ceosal1)</code></pre>
<p>Regression without slope</p>
<pre class="sourceCode r"><code class="sourceCode r">lm3 &lt;-<span class="st"> </span><span class="kw">lm</span>(salary <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> ceosal1)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(salary<span class="op">~</span><span class="st"> </span>roe, <span class="dt">data =</span> ceosal1,
     <span class="dt">xlab =</span> <span class="st">&quot;Return on equity&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Salary&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Salary vs return on equity&quot;</span>,
     <span class="dt">pch  =</span> <span class="dv">20</span>,
     <span class="dt">cex  =</span> <span class="dv">2</span>,
     <span class="dt">col  =</span> <span class="st">&quot;grey&quot;</span>)
<span class="kw">abline</span>(lm1_ceosal1, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;darkorange&quot;</span>)
<span class="kw">abline</span>(lm2,<span class="dt">lwd =</span> <span class="dv">3</span>,  <span class="dt">lty =</span> <span class="dv">2</span>,   <span class="dt">col =</span> <span class="st">&quot;darkblue&quot;</span>)
<span class="kw">abline</span>(lm3, <span class="dt">lwd =</span> <span class="dv">3</span>,  <span class="dt">lty =</span> <span class="dv">3</span>,   <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, 
       <span class="kw">c</span>(<span class="st">&quot;full&quot;</span>, 
         <span class="st">&quot;through origin&quot;</span>, 
         <span class="st">&quot;constant only&quot;</span>), 
       <span class="dt">lwd =</span><span class="dv">2</span>, 
       <span class="dt">lty =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig3"></span>
<img src="MEM5220_R_files/figure-html/fig3-1.png" alt="Regression through the Origin and on a Constant" width="80%" />
<p class="caption">
Figure 2.4: Regression through the Origin and on a Constant
</p>
</div>
</div>
<div id="simulating-slr" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Simulating SLR</h3>
<div id="expected-values-variance-and-standard-errors" class="section level5">
<h5><span class="header-section-number">2.1.2.0.1</span> Expected Values, Variance, and Standard Errors</h5>
<p>The <strong>Gauss–Markov theorem</strong> tells us that when estimating the parameters of the simple linear regression model <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>, the <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> which we derived are the best linear unbiased estimates, or BLUE for short. (The actual conditions for the Gauss–Markov theorem are more relaxed than the SLR model.)</p>
<p>In short those assumptions are:</p>
<ul>
<li>SLR.1 Linear population regression function <span class="math inline">\(y = \beta_0 + \beta_{1} \times x + u\)</span></li>
<li>SLR.2 Random sampling of x and y from the population<br />
</li>
<li>SLR.3 Variation in the sample values: <span class="math inline">\(x_{1}, \dots , x_{n}\)</span></li>
<li>SLR.4 Zero conditional mean: <span class="math inline">\(\mathbf{E}(u|x) = 0\)</span></li>
<li>SLR.5 Homeskedasticity: <span class="math inline">\(Var(u|x) = \sigma^2\)</span></li>
</ul>
<p>Recall that under <strong>SLR.1 - SLR.4</strong> the OLS parameter estimators are unbiased. Under <strong>SLR.1 - SLR.4</strong> the OLS parameter estimators have a specific sampling variance.</p>
<p>Simulating a model is an important concept. In practice you will almost never have a true model, and you will use data to attempt to recover information about the unknown true model. With simulation, we decide the true model and simulate data from it. Then, we apply a method to the data, in this case least squares. Now, since we know the true model, we can assess how well it did.</p>
<p>Simulation also helps to grasp the concepts of estimators, estimates, unbiasedness, the sampling variance of the estimators, and the consequences of violated assumptions.</p>
<p>Sample size</p>
<pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">200</span></code></pre>
<p>True parameters</p>
<pre class="sourceCode r"><code class="sourceCode r">b0&lt;-<span class="st"> </span><span class="dv">1</span>
b1 &lt;-<span class="st"> </span><span class="fl">0.5</span>
sigma &lt;-<span class="st"> </span><span class="dv">2</span> <span class="co"># standard deviation of the error term u </span>
x1 &lt;-<span class="st"> </span><span class="dv">5</span></code></pre>
<p>Determine the distribution of the independent variable</p>
<pre class="sourceCode r"><code class="sourceCode r">yhat1 &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1 <span class="op">*</span><span class="st"> </span>x1 <span class="co">#  Note that we do not include the error term </span></code></pre>
<p>Plot a Gaussian distribution of the dependent variable based on the parameters</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean =</span> yhat1, <span class="dt">sd =</span> sigma), <span class="dv">-5</span>, <span class="dv">15</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> yhat1, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;f(y|x = 5)&quot;</span>), <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>))</code></pre>
<p><img src="MEM5220_R_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>This represent the theoretical (true) probability distribution of <span class="math inline">\(y\)</span>, given <span class="math inline">\(x\)</span></p>
<p>We can calculate the variance of <span class="math inline">\(b_{1}\)</span> and plot the corresponding density function.</p>
<p><span class="math display" id="eq:variancebeta">\[\begin{equation}
var(b_2) = \frac{\sigma^2}{\sum{}{}(x_1 - \bar{x})}
\tag{2.3}
\end{equation}\]</span></p>
<p>Assume that <span class="math inline">\(x_{2}\)</span> represents a second possible predictor of <span class="math inline">\(y\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">x2 &lt;-<span class="st"> </span><span class="dv">18</span>

x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(x1, n<span class="op">/</span><span class="dv">2</span>), <span class="kw">rep</span>(x2, n<span class="op">/</span><span class="dv">2</span>))
xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(x)

sumxbar &lt;-<span class="st"> </span><span class="kw">sum</span>((x<span class="op">-</span>xbar)<span class="op">^</span><span class="dv">2</span>)
varb &lt;-<span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>sumxbar
sdb &lt;-<span class="kw">sqrt</span>(varb)
leftlim &lt;-<span class="st"> </span>b1<span class="dv">-3</span><span class="op">*</span>sdb
rightlim &lt;-<span class="st"> </span>b1<span class="op">+</span><span class="dv">3</span><span class="op">*</span>sdb</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean =</span> b1, <span class="dt">sd =</span> sdb), leftlim, rightlim,)
<span class="kw">abline</span>(<span class="dt">v =</span> b1, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig4"></span>
<img src="MEM5220_R_files/figure-html/fig4-1.png" alt="The theoretical (true) probability density function of b1" width="80%" />
<p class="caption">
Figure 2.5: The theoretical (true) probability density function of b1
</p>
</div>
<p>Draw sample of size <span class="math inline">\(n\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">4</span>, sigma)
<span class="co"># Another way is to assume that the values for x are fixed and know</span>
<span class="co"># x= seq(from = 0, to = 10, length.out = n)</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, sigma)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1 <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>u</code></pre>
<p>Estimate parameter by OLS</p>
<pre class="sourceCode r"><code class="sourceCode r">olsreg &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span>x )</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">simulation.df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x,y)
population.df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(b0, b1)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(simulation.df, 
     <span class="dt">xlab =</span> <span class="st">&quot;x&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;y&quot;</span>,
     <span class="co"># main = &quot;Simulate least squares regression&quot;,</span>
     <span class="dt">pch  =</span> <span class="dv">20</span>,
     <span class="dt">cex  =</span> <span class="dv">2</span>,
     <span class="dt">col  =</span> <span class="st">&quot;grey&quot;</span>)
<span class="kw">abline</span>(olsreg, <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;darkorange&quot;</span>)
<span class="kw">abline</span>(b0, b1,  <span class="dt">lwd =</span> <span class="dv">3</span>,  <span class="dt">lty =</span> <span class="dv">2</span>,   <span class="dt">col =</span> <span class="st">&quot;darkblue&quot;</span>)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, 
       <span class="kw">c</span>(<span class="st">&quot;OLS regression function&quot;</span>, 
         <span class="st">&quot;Population regression function&quot;</span>), 
       <span class="dt">lwd =</span><span class="dv">2</span>, 
       <span class="dt">lty =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig5"></span>
<img src="MEM5220_R_files/figure-html/fig5-1.png" alt="Simulated Sample and OLS Regression Line" width="80%" />
<p class="caption">
Figure 2.6: Simulated Sample and OLS Regression Line
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">lable1 &lt;-<span class="st"> &quot;OLS regression function&quot;</span>
<span class="kw">ggplot</span>(simulation.df, <span class="kw">aes</span>(<span class="dt">x =</span> x,  <span class="dt">y =</span> y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept=</span>b0,<span class="dt">slope=</span>b1,<span class="dt">colour=</span><span class="st">&quot;Population regression function&quot;</span>), <span class="dt">linetype =</span><span class="st">&quot;dashed&quot;</span>, <span class="dt">show.legend  =</span> <span class="ot">TRUE</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="kw">aes</span>(<span class="dt">colour =</span><span class="st">&quot;OLS regression function&quot;</span>), <span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>,<span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">show.legend =</span><span class="ot">TRUE</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Regression functions&quot;</span> 
       <span class="co"># , title = &quot;Simulate least squares regression&quot;</span>
       ) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig6"></span>
<img src="MEM5220_R_files/figure-html/fig6-1.png" alt="Simulated Sample and OLS Regression Line (gpplot Style)" width="80%" />
<p class="caption">
Figure 2.7: Simulated Sample and OLS Regression Line (gpplot Style)
</p>
</div>
<p>Since the expected values and variances of our estimators are defined over separate random samples from the same population, it makes sense to repeat our simulation exercise over many simulated samples.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set the random seed</span>
<span class="kw">set.seed</span>(<span class="dv">1234567</span>)

<span class="co"># set sample size and number of simulations</span>
n&lt;-<span class="dv">1000</span>; r&lt;-<span class="dv">10000</span>

<span class="co"># set true parameters: betas and sd of u</span>
b0&lt;-<span class="fl">1.0</span>; b1&lt;-<span class="fl">0.5</span>; sigma&lt;-<span class="dv">2</span>

<span class="co"># initialize b0hat and b1hat to store results later:</span>
b0hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)
b1hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)

<span class="co"># Draw a sample of x, fixed over replications:</span>
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">4</span>,<span class="dv">1</span>)

<span class="co"># repeat r times:</span>
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>r) {
  <span class="co"># Draw a sample of y:</span>
  u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">0</span>,sigma)
  y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>u
  
  <span class="co"># estimate parameters by OLS and store them in the vectors</span>
  bhat &lt;-<span class="st"> </span><span class="kw">coefficients</span>( <span class="kw">lm</span>(y<span class="op">~</span>x) )
  b0hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;(Intercept)&quot;</span>]
  b1hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;x&quot;</span>]
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># MC estimate of the expected values:</span>
<span class="kw">mean</span>(b0hat)</code></pre>
<pre><code>## [1] 0.9985388</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(b1hat)</code></pre>
<pre><code>## [1] 0.5000466</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># MC estimate of the variances:</span>
<span class="kw">var</span>(b0hat)</code></pre>
<pre><code>## [1] 0.0690833</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(b1hat)</code></pre>
<pre><code>## [1] 0.004069063</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Initialize empty plot</span>
<span class="kw">plot</span>( <span class="ot">NULL</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">8</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">6</span>), <span class="dt">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;y&quot;</span>)
<span class="co"># add OLS regression lines</span>
<span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="kw">abline</span>(b0hat[j],b1hat[j],<span class="dt">col=</span><span class="st">&quot;gray&quot;</span>)
<span class="co"># add population regression line</span>
<span class="kw">abline</span>(b0,b1,<span class="dt">lwd=</span><span class="dv">2</span>)
<span class="co"># add legend</span>
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;Population&quot;</span>,<span class="st">&quot;OLS regressions&quot;</span>),
       <span class="dt">lwd=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">1</span>),<span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;gray&quot;</span>))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig7"></span>
<img src="MEM5220_R_files/figure-html/fig7-1.png" alt="Population and Simulated OLS Regression Lines" width="80%" />
<p class="caption">
Figure 2.8: Population and Simulated OLS Regression Lines
</p>
</div>
<p>Even though the loop solution is transparent, let us take a look at a different, more <em>modern</em> approach.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define a function the returns the alpha -- its point estimate, standard error, etc. -- from the OLS</span>
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">4</span>,<span class="dv">1</span>) <span class="co"># </span><span class="al">NOTE</span><span class="co"> 1: Although a normal distribution is usually defined by its mean and variance, &#39;rnorm()&#39; requires the standard deviation as input for the second moment.</span>
<span class="co"># </span><span class="al">NOTE</span><span class="co"> 2: We use the same values for x in all samples since we draw them outside of the loop. </span>

iteration &lt;-<span class="st"> </span><span class="cf">function</span>() {
  u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">0</span>,sigma)
  y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>u
  
  <span class="kw">lm</span>(y<span class="op">~</span>x) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="co"># %&gt;% </span>
  <span class="co"># filter(term == &#39;x&#39;) # One could only extract the slope</span>
}

<span class="co"># 1000 iterations of the above simulation</span>
MC_coef&lt;-<span class="st"> </span><span class="kw">map_df</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>, <span class="op">~</span><span class="kw">iteration</span>()) 
<span class="kw">str</span>(MC_coef)</code></pre>
<pre><code>## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:    2000 obs. of  5 variables:
##  $ term     : chr  &quot;(Intercept)&quot; &quot;x&quot; &quot;(Intercept)&quot; &quot;x&quot; ...
##  $ estimate : num  1.577 0.372 1.44 0.387 1.355 ...
##  $ std.error: num  0.2672 0.0639 0.2623 0.0628 0.2626 ...
##  $ statistic: num  5.9 5.82 5.49 6.17 5.16 ...
##  $ p.value  : num  4.94e-09 7.91e-09 5.13e-08 9.92e-10 2.99e-07 ...</code></pre>
<p>Instead of plotting simulated and true parameter regression lines we can take a look at the kernel density of the simulated parameter estimates</p>
<p>Figure <a href="linearregression.html#fig:fig8">2.9</a> shows the simulated distribution of <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> the theoretical one.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot the results</span>
<span class="kw">str</span>(MC_coef)</code></pre>
<pre><code>## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:    2000 obs. of  5 variables:
##  $ term     : chr  &quot;(Intercept)&quot; &quot;x&quot; &quot;(Intercept)&quot; &quot;x&quot; ...
##  $ estimate : num  1.577 0.372 1.44 0.387 1.355 ...
##  $ std.error: num  0.2672 0.0639 0.2623 0.0628 0.2626 ...
##  $ statistic: num  5.9 5.82 5.49 6.17 5.16 ...
##  $ p.value  : num  4.94e-09 7.91e-09 5.13e-08 9.92e-10 2.99e-07 ...</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">MC_coef&lt;-<span class="st"> </span>MC_coef <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">OLScoeff =</span>  <span class="kw">ifelse</span>(term <span class="op">==</span><span class="st"> &quot;x&quot;</span>, <span class="st">&quot;b1hat&quot;</span>, <span class="st">&quot;b0hat&quot;</span>)) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># rename the x to b1hat and (Intercept) to b0hat and create a new column </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Simulated =</span> <span class="kw">ifelse</span>(term <span class="op">==</span><span class="st"> &quot;x&quot;</span>, <span class="st">&quot;b1&quot;</span>, <span class="st">&quot;b0&quot;</span>)) <span class="co">#  %&gt;% </span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data=</span> MC_coef, <span class="kw">aes</span>(estimate)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">data =</span> <span class="kw">filter</span>(MC_coef, OLScoeff <span class="op">==</span><span class="st"> &quot;b0hat&quot;</span>), <span class="kw">aes</span>(<span class="dt">xintercept=</span>b0), <span class="dt">colour=</span><span class="st">&quot;pink&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">data =</span> <span class="kw">filter</span>(MC_coef, OLScoeff <span class="op">==</span><span class="st"> &quot;b1hat&quot;</span>), <span class="kw">aes</span>(<span class="dt">xintercept=</span>b1), <span class="dt">colour=</span><span class="st">&quot;darkgreen&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data=</span>MC_coef[<span class="dv">3</span>,], <span class="dt">mapping=</span><span class="kw">aes</span>(<span class="dt">x=</span>estimate, <span class="dt">y=</span><span class="dv">8</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;True parameter: &quot;</span>, MC_coef[<span class="dv">3</span>,<span class="dv">7</span>])), <span class="dt">colour =</span> <span class="st">&quot;pink&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data=</span>MC_coef[<span class="dv">4</span>,], <span class="dt">mapping=</span><span class="kw">aes</span>(<span class="dt">x=</span>estimate, <span class="dt">y=</span><span class="dv">8</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;True parameter: &quot;</span>, MC_coef[<span class="dv">4</span>,<span class="dv">7</span>])), <span class="dt">colour =</span> <span class="st">&quot;darkgreen&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>( <span class="op">~</span><span class="st"> </span>OLScoeff, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)   <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">title =</span> <span class="st">&quot;Histogram Monte Carlo Simulations and True population parameters&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig8"></span>
<img src="MEM5220_R_files/figure-html/fig8-1.png" alt="Histogram b0 and b1 and true parameter" width="80%" />
<p class="caption">
Figure 2.9: Histogram b0 and b1 and true parameter
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">b1_sim &lt;-<span class="st"> </span>MC_coef <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(Simulated <span class="op">==</span><span class="st"> &quot;b1&quot;</span>)

<span class="kw">mean</span>(b1_sim<span class="op">$</span>estimate)</code></pre>
<pre><code>## [1] 0.5011414</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(b1_sim<span class="op">$</span>estimate) <span class="op">==</span><span class="st"> </span>(<span class="kw">sd</span>(b1_sim<span class="op">$</span>estimate))<span class="op">^</span><span class="dv">2</span></code></pre>
<pre><code>## [1] FALSE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">all.equal</span>(<span class="kw">var</span>(b1_sim<span class="op">$</span>estimate) , (<span class="kw">sd</span>(b1_sim<span class="op">$</span>estimate))<span class="op">^</span><span class="dv">2</span>) <span class="co"># Floating point arithmetic!</span></code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data=</span> b1_sim, <span class="kw">aes</span>(estimate)) <span class="op">+</span><span class="st">  </span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> Simulated), <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span><span class="st"> </span><span class="co"># computes and draws the kernel density, which is the smoothed version of the histogram</span>
<span class="st">  </span><span class="co"># stat_function(fun = dnorm, args = list(mean = mean(b1_sim$estimate), sd = sd(b1_sim$estimate)), aes(colour = &quot;true&quot;)) +</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="fl">0.5</span>, <span class="dt">sd =</span> <span class="kw">sd</span>(b1_sim<span class="op">$</span>estimate)), <span class="kw">aes</span>(<span class="dt">colour =</span> <span class="st">&quot;true&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="co"># labs(</span>
<span class="st">   </span><span class="co">#  title = &quot;Kernel Density Monte Carlo Simulations vs. True population parameters&quot;</span>
<span class="st">    </span><span class="co"># ) +</span>
<span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">name=</span><span class="st">&quot;&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig9"></span>
<img src="MEM5220_R_files/figure-html/fig9-1.png" alt="Simulated and theoretical distributions of b1" width="80%" />
<p class="caption">
Figure 2.10: Simulated and theoretical distributions of b1
</p>
</div>
<p><strong>Rework this section</strong> might have mixed up what is simulated and what is biased</p>
</div>
<div id="violation-of-slr.4" class="section level5">
<h5><span class="header-section-number">2.1.2.0.2</span> Violation of SLR.4</h5>
<p>To implement a violation of <strong>SLR.4</strong> (zero conditional mean) consider a case where in the population <span class="math inline">\(u\)</span> is not mean independent of <span class="math inline">\(x\)</span>, for example</p>
<p><span class="math display">\[
\mathbf{E}(u|x) = \frac{x-4}{5}
\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set the random seed</span>
<span class="kw">set.seed</span>(<span class="dv">1234567</span>)

<span class="co"># set sample size and number of simulations</span>
n&lt;-<span class="dv">1000</span>; r&lt;-<span class="dv">10000</span>

<span class="co"># set true parameters: betas and sd of u</span>
b0&lt;-<span class="dv">1</span>; b1&lt;-<span class="fl">0.5</span>; su&lt;-<span class="dv">2</span>

<span class="co"># initialize b0hat and b1hat to store results later:</span>
b0hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)
b1hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)

<span class="co"># Draw a sample of x, fixed over replications:</span>
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">4</span>,<span class="dv">1</span>)

<span class="co"># repeat r times:</span>
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>r) {
<span class="co"># Draw a sample of y:</span>
u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, (x<span class="dv">-4</span>)<span class="op">/</span><span class="dv">5</span>, su) <span class="co"># this is where manipulate the assumption of zero conditional mean</span>
y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>u

<span class="co"># estimate parameters by OLS and store them in the vectors</span>
bhat &lt;-<span class="st"> </span><span class="kw">coefficients</span>( <span class="kw">lm</span>(y<span class="op">~</span>x) )
b0hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;(Intercept)&quot;</span>]
b1hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;x&quot;</span>]
}</code></pre>
<p>OLS coefficients</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># MC estimate of the expected values:</span>
<span class="kw">mean</span>(b0hat)</code></pre>
<pre><code>## [1] 0.1985388</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(b1hat)</code></pre>
<pre><code>## [1] 0.7000466</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># MC estimate of the variances:</span>
<span class="kw">var</span>(b0hat)</code></pre>
<pre><code>## [1] 0.0690833</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(b1hat)</code></pre>
<pre><code>## [1] 0.004069063</code></pre>
<p>The average estimates are far from the population parameters <span class="math inline">\(\beta_0=1\)</span> and <span class="math inline">\(\beta_1 = 0.5\)</span>!</p>
</div>
<div id="violation-of-slr.5" class="section level5">
<h5><span class="header-section-number">2.1.2.0.3</span> Violation of SLR.5</h5>
<p>Homoskedasticity is not required for unbiasedness but for it is a requirement for the theorem of sampling variance. Consider the following heteroskedastic behavior of <span class="math inline">\(u\)</span> given <span class="math inline">\(x\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set the random seed</span>
<span class="kw">set.seed</span>(<span class="dv">1234567</span>)

<span class="co"># set sample size and number of simulations</span>
n&lt;-<span class="dv">1000</span>; r&lt;-<span class="dv">10000</span>

<span class="co"># set true parameters: betas and sd of u</span>
b0&lt;-<span class="dv">1</span>; b1&lt;-<span class="fl">0.5</span>; su&lt;-<span class="dv">2</span>

<span class="co"># initialize b0hat and b1hat to store results later:</span>
b0hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)
b1hat &lt;-<span class="st"> </span><span class="kw">numeric</span>(r)

<span class="co"># Draw a sample of x, fixed over replications:</span>
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">4</span>,<span class="dv">1</span>)

<span class="co"># repeat r times:</span>
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>r) {
  <span class="co"># Draw a sample of y:</span>
  varu &lt;-<span class="st"> </span><span class="dv">4</span><span class="op">/</span><span class="kw">exp</span>(<span class="fl">4.5</span>) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(x)
  u &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, <span class="kw">sqrt</span>(varu) )
  y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>u
  
  <span class="co"># estimate parameters by OLS and store them in the vectors</span>
  lm_heterosced &lt;-<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span>x)
  
  bhat &lt;-<span class="st"> </span><span class="kw">coefficients</span>( <span class="kw">lm</span>(y<span class="op">~</span>x) )
  b0hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;(Intercept)&quot;</span>]
  b1hat[j] &lt;-<span class="st"> </span>bhat[<span class="st">&quot;x&quot;</span>]
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm_heterosced) <span class="co"># just the last sample of the MC-simulation</span></code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -23.6742  -0.9033   0.0052   1.0012   9.3411 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.24088    0.27158   4.569 5.51e-06 ***
## x            0.44561    0.06593   6.759 2.37e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.075 on 998 degrees of freedom
## Multiple R-squared:  0.04377,    Adjusted R-squared:  0.04281 
## F-statistic: 45.68 on 1 and 998 DF,  p-value: 2.367e-11</code></pre>
<p>Plot the residual against the regressor suspected of creating heteroskedasticity, or more generally, the fitted values of the regression.</p>
<pre class="sourceCode r"><code class="sourceCode r">res &lt;-<span class="st"> </span><span class="kw">residuals</span>(lm_heterosced)
yhat &lt;-<span class="st"> </span><span class="kw">fitted</span>(lm_heterosced)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(x, res, <span class="dt">ylab =</span> <span class="st">&quot;residuals&quot;</span>)
<span class="kw">plot</span>(yhat, res, <span class="dt">xlab =</span> <span class="st">&quot;fitted values&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;residuals&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig10"></span>
<img src="MEM5220_R_files/figure-html/fig10-1.png" alt="Heteroskedasticity in the simulated data" width="80%" />
<p class="caption">
Figure 2.11: Heteroskedasticity in the simulated data
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># MC estimate of the expected values:</span>
<span class="kw">mean</span>(b0hat)</code></pre>
<pre><code>## [1] 1.0019</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(b1hat)</code></pre>
<pre><code>## [1] 0.4992376</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># MC estimate of the variances:</span>
<span class="kw">var</span>(b0hat)</code></pre>
<pre><code>## [1] 0.08967037</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(b1hat)</code></pre>
<pre><code>## [1] 0.007264373</code></pre>
<p>Unbiasedness is provided but sampling variance is incorrect (compared to the results provided above).</p>
</div>
</div>
<div id="nonlinearities" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Nonlinearities</h3>
<p>Sometimes the scatter plot diagram or some theoretical considerations suggest a non-linear relationship. The most popular non-linear relationships involve logarithms of the dependent or independent variables and polynomial functions.</p>
<p>We will use a new dataset, <em>wage1</em>, for this section. A detailed exploratory analysis of the dataset is left to the reader.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;wage1&quot;</span>)
<span class="kw">attach</span>(wage1)</code></pre>
<div id="predicated-variable-transformation" class="section level4">
<h4><span class="header-section-number">2.1.3.1</span> Predicated variable transformation</h4>
<p>A common variance stabilizing transformation (VST) when we see increasing variance in a fitted versus residuals plot is <span class="math inline">\(log(Y)\)</span>.</p>
<p>Related, to use the <em>log</em> of an independent variable is to make its distribution closer to the normal distribution.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># wage1$logwage &lt;- log(wage1$wage) # one could also create a new variable </span>

p1_wagehisto &lt;-<span class="st"> </span><span class="kw">ggplot</span>(wage1)  <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> wage), <span class="dt">fill =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.6</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()


p2_wagehisto &lt;-<span class="st"> </span><span class="kw">ggplot</span>(wage1)  <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> wage),  <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.6</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">trans=</span><span class="st">&#39;log2&#39;</span>, <span class="st">&quot;Log Wage&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># instead of creating a new variable with simply define that the x-scale undergoes a logarithmic transformation</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggarrange</span>(p1_wagehisto, p2_wagehisto,  
          <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>),
          <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">nrow =</span> <span class="dv">1</span>)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig11"></span>
<img src="MEM5220_R_files/figure-html/fig11-1.png" alt="Histogram of wage and log(wage)" width="80%" />
<p class="caption">
Figure 2.12: Histogram of wage and log(wage)
</p>
</div>
<p>A model with a log transformed response:</p>
<p><span class="math display">\[\begin{equation}
log(Y_{i}) = \beta_{0} + \beta_{1} \times x_{i} + \epsilon_{i}
\end{equation}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">lm_wage &lt;-<span class="st"> </span><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span>educ, <span class="dt">data =</span> wage1)
lm_wage1 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(wage)<span class="op">~</span><span class="st"> </span>educ, <span class="dt">data =</span>  wage1)
<span class="kw">summary</span>(lm_wage)</code></pre>
<pre><code>## 
## Call:
## lm(formula = wage ~ educ, data = wage1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3396 -2.1501 -0.9674  1.1921 16.6085 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.90485    0.68497  -1.321    0.187    
## educ         0.54136    0.05325  10.167   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.378 on 524 degrees of freedom
## Multiple R-squared:  0.1648, Adjusted R-squared:  0.1632 
## F-statistic: 103.4 on 1 and 524 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm_wage1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = log(wage) ~ educ, data = wage1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.21158 -0.36393 -0.07263  0.29712  1.52339 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.583773   0.097336   5.998 3.74e-09 ***
## educ        0.082744   0.007567  10.935  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4801 on 524 degrees of freedom
## Multiple R-squared:  0.1858, Adjusted R-squared:  0.1843 
## F-statistic: 119.6 on 1 and 524 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Plotting Diagnostics for Linear Models</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lm_wage)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig12"></span>
<img src="MEM5220_R_files/figure-html/fig12-1.png" alt="Regression diagnostics plot base R - Linear Relationship" width="80%" />
<p class="caption">
Figure 2.13: Regression diagnostics plot base R - Linear Relationship
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig12"></span>
<img src="MEM5220_R_files/figure-html/fig12-2.png" alt="Regression diagnostics plot base R - Linear Relationship" width="80%" />
<p class="caption">
Figure 2.13: Regression diagnostics plot base R - Linear Relationship
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig12"></span>
<img src="MEM5220_R_files/figure-html/fig12-3.png" alt="Regression diagnostics plot base R - Linear Relationship" width="80%" />
<p class="caption">
Figure 2.13: Regression diagnostics plot base R - Linear Relationship
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:fig12"></span>
<img src="MEM5220_R_files/figure-html/fig12-4.png" alt="Regression diagnostics plot base R - Linear Relationship" width="80%" />
<p class="caption">
Figure 2.13: Regression diagnostics plot base R - Linear Relationship
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">autoplot</span>(lm_wage, <span class="dt">which =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">colour =</span> <span class="st">&#39;dodgerblue3&#39;</span>,
         <span class="dt">smooth.colour =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">smooth.linetype =</span> <span class="st">&#39;dashed&#39;</span>,
         <span class="dt">ad.colour =</span> <span class="st">&#39;blue&#39;</span>,
         <span class="dt">label =</span> <span class="ot">FALSE</span>,
         <span class="dt">label.size =</span> <span class="dv">3</span>, <span class="dt">label.n =</span> <span class="dv">5</span>, <span class="dt">label.colour =</span> <span class="st">&#39;blue&#39;</span>,
         <span class="dt">ncol =</span> <span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig13"></span>
<img src="MEM5220_R_files/figure-html/fig13-1.png" alt="Regression diagnostics autoplot(ggplot) - Linear Relationship" width="80%" />
<p class="caption">
Figure 2.14: Regression diagnostics autoplot(ggplot) - Linear Relationship
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">autoplot</span>(lm_wage1, <span class="dt">which =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">colour =</span> <span class="st">&#39;dodgerblue3&#39;</span>,
         <span class="dt">smooth.colour =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">smooth.linetype =</span> <span class="st">&#39;dashed&#39;</span>,
         <span class="dt">ad.colour =</span> <span class="st">&#39;blue&#39;</span>,
         <span class="dt">label =</span> <span class="ot">FALSE</span>,
         <span class="dt">label.size =</span> <span class="dv">3</span>, <span class="dt">label.n =</span> <span class="dv">5</span>, <span class="dt">label.colour =</span> <span class="st">&#39;blue&#39;</span>,
         <span class="dt">ncol =</span> <span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig14"></span>
<img src="MEM5220_R_files/figure-html/fig14-1.png" alt="Regression diagnostics - Non-Linear Relationship" width="80%" />
<p class="caption">
Figure 2.15: Regression diagnostics - Non-Linear Relationship
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">p1_nonlinearities &lt;-<span class="st"> </span><span class="kw">ggplot</span>(wage1, <span class="kw">aes</span>(<span class="dt">x =</span> educ, <span class="dt">y =</span> wage )) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()   <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">trans=</span><span class="st">&#39;log2&#39;</span>, <span class="st">&quot;Log Wage&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="kw">aes</span>(<span class="dt">fill=</span><span class="st">&quot;Linear Model&quot;</span>),<span class="dt">size=</span><span class="dv">1</span>,<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span> ,<span class="dt">span =</span><span class="fl">0.3</span>, <span class="dt">se=</span>F) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">guides</span>(<span class="dt">fill =</span> <span class="kw">guide_legend</span>(<span class="st">&quot;Model Type&quot;</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<p>Note that if we re-scale the model from a log scale back to the original scale of the data, we now have</p>
<p><span class="math display">\[\begin{equation}
Y_{i} = exp(\beta_{0} + \beta_{1} \times x_{i})  \times exp(\epsilon_{i})
\end{equation}\]</span></p>
<p>which has errors entering in a multiplicative fashion.</p>
<pre class="sourceCode r"><code class="sourceCode r">log.model.df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> wage1<span class="op">$</span>educ,
                           <span class="dt">y =</span> <span class="kw">exp</span>(<span class="kw">fitted</span>(lm_wage1))) <span class="co"># This is essentially exp(b0_wage1 + b1_wage1 * wage1$educ) </span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">p2_nonlinearities &lt;-<span class="st"> </span><span class="kw">ggplot</span>(wage1, <span class="kw">aes</span>(<span class="dt">x =</span> educ, <span class="dt">y =</span> wage))  <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()   <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> log.model.df, <span class="kw">aes</span>(x, y, <span class="dt">color =</span> <span class="st">&quot;Log Model&quot;</span>), <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="dv">2</span>)  <span class="op">+</span>
<span class="st">  </span><span class="kw">guides</span>(<span class="dt">color =</span> <span class="kw">guide_legend</span>(<span class="st">&quot;Model Type&quot;</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggarrange</span>(p1_nonlinearities, p2_nonlinearities,  
          <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>),
          <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">nrow =</span> <span class="dv">1</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:fig15"></span>
<img src="MEM5220_R_files/figure-html/fig15-1.png" alt="Wages by Education - Different transformations" width="80%" />
<p class="caption">
Figure 2.16: Wages by Education - Different transformations
</p>
</div>
<p>A: Plotting the data on the transformed log scale and adding the fitted line, the relationship again appears linear, and the variation about the fitted line looks more constant.</p>
<p>B: By plotting the data on the original scale, and adding the fitted regression, we see an exponential relationship. However, this is still a <em>linear</em> model, since the new transformed response, <span class="math inline">\(log(Y_{i}\)</span>, is still a <em>linear</em> combination of the predictors. In other words, only <span class="math inline">\(\beta\)</span> needs to be linear, not the <span class="math inline">\(x\)</span> values.</p>
<p><em>NOTE:</em></p>
<p>The example comes from the Wooldrige book but the variable educ looks more like count data. A Poisson GLM might seems like a better choice.</p>
<p><strong>Quadratic Model</strong></p>
<p><span class="math display">\[\begin{equation}
Y_{i} = \beta_{0} + \beta_{1} \times x^2_{i})  \times \epsilon_{i}
\end{equation}\]</span></p>
<p>New dataset from Wooldrige: Collected from the real estate pages of the Boston Globe during 1990. These are homes that sold in the Boston, MA area.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;hprice1&quot;</span>)
<span class="kw">attach</span>(hprice1)</code></pre>
<p>In R, independent variables involving mathematical operators can be included in regression equation with the function <code>I()</code></p>
<pre class="sourceCode r"><code class="sourceCode r">lm_hprice &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>sqrft, <span class="dt">data  =</span> hprice1)
lm_hprice1 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>sqrft <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(sqrft<span class="op">^</span><span class="dv">2</span>), <span class="dt">data  =</span> hprice1)</code></pre>
<p>Alternatively use the <code>poly()</code> function. Be careful of the additional argument <code>raw</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm_hprice2 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(sqrft, <span class="dt">degree =</span> <span class="dv">2</span>),  <span class="dt">data  =</span> hprice1) 
lm_hprice3 &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(sqrft, <span class="dt">degree =</span> <span class="dv">2</span>, <span class="dt">raw =</span> <span class="ot">TRUE</span>),  <span class="dt">data  =</span> hprice1) <span class="co"># if true, use raw and not orthogonal polynomials.</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice1))</code></pre>
<pre><code>## [1]  1.849453e+02 -1.710855e-02  3.262809e-05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice2))</code></pre>
<pre><code>## [1] 293.5460 754.8517 135.6051</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice3))</code></pre>
<pre><code>## [1]  1.849453e+02 -1.710855e-02  3.262809e-05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">all.equal</span>(<span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice1)), <span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice2)))</code></pre>
<pre><code>## [1] &quot;Mean relative difference: 5.401501&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">all.equal</span>(<span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice1)), <span class="kw">unname</span>(<span class="kw">coef</span>(lm_hprice3)))</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">all.equal</span>(<span class="kw">fitted</span>(lm_hprice1), <span class="kw">fitted</span>(lm_hprice2))</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">all.equal</span>(<span class="kw">fitted</span>(lm_hprice1), <span class="kw">fitted</span>(lm_hprice3))</code></pre>
<pre><code>## [1] TRUE</code></pre>
</div>
</div>
<div id="inference-for-simple-linear-regression" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Inference for Simple Linear Regression</h3>
<blockquote>
<p>“There are three types of lies: lies, damn lies, and statistics”
<em>Benjamin Disraeli</em></p>
</blockquote>
</div>
</div>
<div id="multiple-linear-regression" class="section level2">
<h2><span class="header-section-number">2.2</span> Multiple Linear Regression</h2>
<hr />
<p><strong>Note</strong></p>
<p>A <strong>(general) linear model</strong> is similar to the simple variant, but with a multivariate <span class="math inline">\(x \epsilon \!R^{\rho}\)</span> and a mean given by a hyperplane in place of a single line.</p>
<ul>
<li>General principles are the same as the simple case</li>
<li>Math is more difficult because we need to use matrices</li>
<li>Interpretation is more difficult because the <span class="math inline">\(\beta_{j}\)</span> are effects conditional on the other variables</li>
</ul>
<p>Many would retain the same signs as the simple linear regression, but the magnitudes would be smaller. In some cases, it is possible for
the relationship to flip directions when a second (highly correlated) variable is added.</p>
<hr />
<p>The file was creating using <code>R</code> version <code>3.5.1</code>.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-wooldridge2015introductory">
<p>Wooldridge, Jeffrey M. 2015. <em>Introductory Econometrics: A Modern Approach</em>. Nelson Education.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="binarymodels.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["MEM5220_R.pdf", "MEM5220_R.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
